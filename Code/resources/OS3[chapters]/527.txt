File-System Interface


File -System                                                             11C H A P T E R
Interface
      For most users, the file system is the most visible aspect of an operating
      system. It provides the mechanism for on-line storage of and access to both
      data and programs of the operating system and all the users of the computer
      system. The file system consists of two distinct parts: a collection of files, each
      storing related data, and a directory structure, which organizes and provides
      information about all the files in the system. File systems live on devices,
      which we described in the preceding chapter and will continue to discuss in
      the following one. In this chapter, we consider the various aspects of files and
      the major directory structures. We also discuss the semantics of sharing files
      among multiple processes, users, and computers. Finally, we discuss ways to
      handle file protection, necessary when we have multiple users and we want to
      control who may access files and how files may be accessed.
          CHAPTER OBJECTIVES
          · To explain the function of file systems.
          · To describe the interfaces to file systems.
          · To discuss file-system design tradeoffs, including  access   methods,   file
          sharing, file locking, and directory structures.
          · To explore file-system protection.
11.1  File Concept
      Computers can store information on various storage media, such as magnetic
      disks, magnetic tapes, and optical disks. So that the computer system will
      be convenient to use, the operating system provides a uniform logical view
      of  stored  information.  The  operating        system  abstracts  from  the  physical
      properties of its storage devices to define a logical storage unit, the file. Files are
      mapped by the operating system onto physical devices. These storage devices
      are usually nonvolatile, so the contents are persistent between system reboots.
                                                                                               503



504  Chapter 11    File-System Interface
        A file is a named collection of related information that is recorded on
     secondary storage. From a user's perspective, a file is the smallest allotment
     of logical secondary storage; that is, data cannot be written to secondary
     storage unless they are within a file. Commonly, files represent programs (both
     source and object forms) and data. Data files may be numeric, alphabetic,
     alphanumeric, or binary. Files may be free form, such as text files, or may be
     formatted rigidly. In general, a file is a sequence of bits, bytes, lines, or records,
     the meaning of which is defined by the file's creator and user. The concept of
     a file is thus extremely general.
        The information in a file is defined by its creator. Many different types of
     information may be stored in a file --source or executable programs, numeric or
     text data, photos, music, video, and so on. A file has a certain defined structure,
     which depends on its type. A text file is a sequence of characters organized
     into lines (and possibly pages). A source file is a sequence of functions, each of
     which is further organized as declarations followed by executable statements.
     An executable file is a series of code sections that the loader can bring into
     memory and execute.
     11.1.1  File Attributes
     A file is named, for the convenience of its human users, and is referred to by
     its name. A name is usually a string of characters, such as example.c. Some
     systems differentiate between uppercase and lowercase characters in names,
     whereas other systems do not. When a file is named, it becomes independent
     of the process, the user, and even the system that created it. For instance, one
     user might create the file example.c, and another user might edit that file by
     specifying its name. The file's owner might write the file to a USB disk, send it
     as an e-mail attachment, or copy it across a network, and it could still be called
     example.c on the destination system.
        A file's attributes vary from one operating system to another but typically
     consist of these:
     ·  Name. The symbolic file name is the only information kept in human-
        readable form.
     ·  Identifier. This unique tag, usually a number, identifies the file within the
        file system; it is the non-human-readable name for the file.
     ·  Type. This information is needed for systems that support different types
        of files.
     ·  Location. This information is a pointer to a device and to the location of
        the file on that device.
     ·  Size. The current size of the file (in bytes, words, or blocks) and possibly
        the maximum allowed size are included in this attribute.
     ·  Protection. Access-control information determines who can do reading,
        writing, executing, and so on.
     ·  Time, date, and user identification. This information may be kept for
        creation, last modification, and last use. These data can be useful for
        protection, security, and usage monitoring.



                          11.1                             File Concept          505
             Figure 11.1  A file info window on Mac OS X.
Some newer file systems also support extended file attributes, including
character encoding of the file and security features such as a file checksum.
Figure 11.1 illustrates a file info window on Mac OS X, which displays a file's
attributes.
The information about all files is kept in the directory structure, which
also resides on secondary storage. Typically, a directory entry consists of the
file's name and its unique identifier. The identifier in turn locates the other



506  Chapter 11    File-System Interface
     file attributes. It may take more than a kilobyte to record this information for
     each file. In a system with many files, the size of the directory itself may be
     megabytes. Because directories, like files, must be nonvolatile, they must be
     stored on the device and brought into memory piecemeal, as needed.
     11.1.2  File Operations
     A file is an abstract data type. To define a file properly, we need to consider the
     operations that can be performed on files. The operating system can provide
     system calls to create, write, read, reposition, delete, and truncate files. Let's
     examine what the operating system must do to perform each of these six basic
     file operations. It should then be easy to see how other similar operations, such
     as renaming a file, can be implemented.
     ·  Creating a file. Two steps are necessary to create a file. First, space in the
        file system must be found for the file. We discuss how to allocate space for
        the file in Chapter 12. Second, an entry for the new file must be made in
        the directory.
     ·  Writing a file. To write a file, we make a system call specifying both the
        name of the file and the information to be written to the file. Given the
        name of the file, the system searches the directory to find the file's location.
        The system must keep a write pointer to the location in the file where the
        next write is to take place. The write pointer must be updated whenever a
        write occurs.
     ·  Reading a file. To read from a file, we use a system call that specifies the
        name of the file and where (in memory) the next block of the file should
        be put. Again, the directory is searched for the associated entry, and the
        system needs to keep a read pointer to the location in the file where the
        next read is to take place. Once the read has taken place, the read pointer
        is updated. Because a process is usually either reading from or writing to
        a file, the current operation location can be kept as a per-process current-
        file-position pointer. Both the read and write operations use this same
        pointer, saving space and reducing system complexity.
     ·  Repositioning within a file. The directory is searched for the appropriate
        entry, and the current-file-position pointer is repositioned to a given value.
        Repositioning within a file need not involve any actual I/O. This file
        operation is also known as a file seek.
     ·  Deleting a file. To delete a file, we search the directory for the named file.
        Having found the associated directory entry, we release all file space, so
        that it can be reused by other files, and erase the directory entry.
     ·  Truncating a file. The user may want to erase the contents of a file but
        keep its attributes. Rather than forcing the user to delete the file and then
        recreate it, this function allows all attributes to remain unchanged --except
        for file length--but lets the file be reset to length zero and its file space
        released.
        These    six  basic  operations   comprise  the  minimal  set  of  required       file
     operations. Other common operations include appending new information



                                                11.1           File Concept          507
to the end of an existing file and renaming an existing file. These primitive
operations can then be combined to perform other file operations. For instance,
we can create a copy of a file --or copy the file to another I/O device, such as
a printer or a display--by creating a new file and then reading from the old
and writing to the new. We also want to have operations that allow a user to
get and set the various attributes of a file. For example, we may want to have
operations that allow a user to determine the status of a file, such as the file's
length, and to set file attributes, such as the file's owner.
Most of the file operations mentioned involve searching the directory for
the entry associated with the named file. To avoid this constant searching,
many systems require that an open() system call be made before a file is first
used. The operating system keeps a table, called the open-file table, containing
information about all open files. When a file operation is requested, the file is
specified via an index into this table, so no searching is required. When the file
is no longer being actively used, it is closed by the process, and the operating
system removes its entry from the open-file table. create() and delete() are
system calls that work with closed rather than open files.
Some systems implicitly open a file when the first reference to it is made.
The file is automatically closed when the job or program that opened the
file terminates. Most systems, however, require that the programmer open a
file explicitly with the open() system call before that file can be used. The
open() operation takes a file name and searches the directory, copying the
directory entry into the open-file table. The open() call can also accept access-
mode information--create, read-only, read ­write, append-only, and so on.
This mode is checked against the file's permissions. If the request mode is
allowed, the file is opened for the process. The open() system call typically
returns a pointer to the entry in the open-file table. This pointer, not the actual
file name, is used in all I/O operations, avoiding any further searching and
simplifying the system-call interface.
The  implementation  of  the       open()  and  close()        operations    is  more
complicated in an environment where several processes may open the file
simultaneously. This may occur in a system where several different applications
open the same file at the same time. Typically, the operating system uses two
levels of internal tables: a per-process table and a system-wide table. The per-
process table tracks all files that a process has open. Stored in this table is
information regarding the process's use of the file. For instance, the current
file pointer for each file is found here. Access rights to the file and accounting
information can also be included.
Each entry in the per-process table in turn points to a system-wide open-file
table. The system-wide table contains process-independent information, such
as the location of the file on disk, access dates, and file size. Once a file has
been opened by one process, the system-wide table includes an entry for the
file. When another process executes an open() call, a new entry is simply
added to the process's open-file table pointing to the appropriate entry in
the system-wide table. Typically, the open-file table also has an open count
associated with each file to indicate how many processes have the file open.
Each close() decreases this open count, and when the open count reaches
zero, the file is no longer in use, and the file's entry is removed from the
open-file table.



508  Chapter 11  File-System Interface
        In summary, several pieces of information are associated with an open file.
     ·  File pointer. On systems that do not include a file offset as part of the
        read() and write() system calls, the system must track the last read­
        write location as a current-file-position pointer. This pointer is unique to
        each process operating on the file and therefore must be kept separate from
        the on-disk file attributes.
     ·  File-open count. As files are closed, the operating system must reuse its
        open-file table entries, or it could run out of space in the table. Multiple
        processes may have opened a file, and the system must wait for the last
        file to close before removing the open-file table entry. The file-open count
        tracks the number of opens and closes and reaches zero on the last close.
        The system can then remove the entry.
     ·  Disk location of the file. Most file operations require the system to modify
        data within the file. The information needed to locate the file on disk is
        kept in memory so that the system does not have to read it from disk for
        each operation.
     ·  Access rights. Each process opens a file in an access mode. This information
        is stored on the per-process table so the operating system can allow or deny
        subsequent I/O requests.
        Some operating systems provide facilities for locking an open file (or
     sections of a file). File locks allow one process to lock a file and prevent other
     processes from gaining access to it. File locks are useful for files that are shared
     by several processes--for example, a system log file that can be accessed and
     modified by a number of processes in the system.
        File locks provide functionality similar to reader­writer locks, covered in
     Section 5.7.2. A shared lock is akin to a reader lock in that several processes
     can acquire the lock concurrently. An exclusive lock behaves like a writer lock;
     only one process at a time can acquire such a lock. It is important to note
     that not all operating systems provide both types of locks: some systems only
     provide exclusive file locking.
                         FILE LOCKING IN JAVA
     In the Java API, acquiring a lock requires first obtaining the FileChannel
     for the file to be locked. The lock() method of the FileChannel is used to
     acquire the lock. The API of the lock() method is
        FileLock  lock(long           begin,  long  end,  boolean  shared)
     where begin and end are the beginning and ending positions of the region
     being locked. Setting shared to true is for shared locks; setting shared
     to false acquires the lock exclusively. The lock is released by invoking the
     release() of the FileLock returned by the lock() operation.
        The program in Figure 11.2 illustrates file locking in Java. This program
     acquires two locks on the file file.txt. The first half of the file is acquired
     as an exclusive lock; the lock for the second half is a shared lock.



                                                                              11.1      File Concept     509
                             FILE LOCKING IN JAVA (Continued)
import        java.io.*;
import        java.nio.channels.*;
public        class   LockingExample                {
   public       static    final         boolean        EXCLUSIVE         =  false;
   public       static    final         boolean        SHARED       =  true;
   public       static    void         main(String          args[])         throws      IOException   {
      FileLock        sharedLock         =   null;
      FileLock        exclusiveLock           =     null;
      try    {
         RandomAccessFile               raf   =     new     RandomAccessFile("file.txt","rw");
         //   get    the  channel         for       the     file
         FileChannel         ch     =   raf.getChannel();
         //   this    locks      the     first      half       of   the  file     -     exclusive
         exclusiveLock           =     ch.lock(0,           raf.length()/2,             EXCLUSIVE);
         /**    Now   modify        the   data      .    .  .   */
         //   release     the       lock
         exclusiveLock.release();
         //   this    locks      the     second        half     of  the     file     -  shared
         sharedLock       =  ch.lock(raf.length()/2+1,raf.length(),SHARED);
         /**    Now   read   the        data     .  .    .  */
         //   release     the       lock
         sharedLock.release();
      }  catch     (java.io.IOException                     ioe)    {
         System.err.println(ioe);
      }
      finally      {
         if   (exclusiveLock             !=   null)
                   exclusiveLock.release();
         if   (sharedLock           !=   null)
                   sharedLock.release();
      }
   }
}
                             Figure 11.2         File-locking example       in  Java.
      Furthermore, operating systems may provide either mandatory or advi-
sory file-locking mechanisms. If a lock is mandatory, then once a process
acquires an exclusive lock, the operating system will prevent any other process



510  Chapter 11  File-System Interface
     from accessing the locked file. For example, assume a process acquires an
     exclusive lock on the file system.log. If we attempt to open system.log
     from another process--for example, a text editor--the operating system will
     prevent access until the exclusive lock is released. This occurs even if the text
     editor is not written explicitly to acquire the lock. Alternatively, if the lock
     is advisory, then the operating system will not prevent the text editor from
     acquiring access to system.log. Rather, the text editor must be written so that
     it manually acquires the lock before accessing the file. In other words, if the
     locking scheme is mandatory, the operating system ensures locking integrity.
     For advisory locking, it is up to software developers to ensure that locks are
     appropriately acquired and released. As a general rule, Windows operating
     systems adopt mandatory locking, and UNIX systems employ advisory locks.
     The use of file locks requires the same precautions as ordinary process
     synchronization.  For   example,    programmers  developing  on  systems  with
     mandatory locking must be careful to hold exclusive file locks only while
     they are accessing the file. Otherwise, they will prevent other processes from
     accessing the file as well. Furthermore, some measures must be taken to ensure
     that two or more processes do not become involved in a deadlock while trying
     to acquire file locks.
     11.1.3  File Types
     When we design a file system--indeed, an entire operating system--we
     always consider whether the operating system should recognize and support
     file types. If an operating system recognizes the type of a file, it can then operate
     on the file in reasonable ways. For example, a common mistake occurs when a
     user tries to output the binary-object form of a program. This attempt normally
     produces garbage; however, the attempt can succeed if the operating system
     has been told that the file is a binary-object program.
     A common technique for implementing file types is to include the type
     as part of the file name. The name is split into two parts--a name and an
     extension, usually separated by a period (Figure 11.3). In this way, the user
     and the operating system can tell from the name alone what the type of a file
     is. Most operating systems allow users to specify a file name as a sequence
     of characters followed by a period and terminated by an extension made
     up of additional characters. Examples include resume.docx, server.c, and
     ReaderThread.cpp.
     The system uses the extension to indicate the type of the file and the type
     of operations that can be done on that file. Only a file with a .com, .exe, or .sh
     extension can be executed, for instance. The .com and .exe files are two forms
     of binary executable files, whereas the .sh file is a shell script containing, in
     ASCII format, commands to the operating system. Application programs also
     use extensions to indicate file types in which they are interested. For example,
     Java compilers expect source files to have a .java extension, and the Microsoft
     Word word processor expects its files to end with a .doc or .docx extension.
     These extensions are not always required, so a user may specify a file without
     the extension (to save typing), and the application will look for a file with
     the given name and the extension it expects. Because these extensions are
     not supported by the operating system, they can be considered "hints" to the
     applications that operate on them.



                                                         11.1  File Concept        511
        file type       usual extension              function
        executable      exe, com, bin       ready-to-run machine-
                        or none             language program
        object          obj, o              compiled, machine
                                            language, not linked
        source code     c, cc, java, perl,  source code in various
                        asm                 languages
        batch           bat, sh             commands to the command
                                            interpreter
        markup          xml, html, tex      textual data, documents
        word processor  xml, rtf,           various word-processor
                        docx                formats
        library         lib, a, so, dll     libraries of routines for
                                            programmers
        print or view   gif, pdf, jpg       ASCII or binary file in a
                                            format for printing or
                                            viewing
        archive         rar, zip, tar       related files grouped into
                                            one file, sometimes com-
                                            pressed, for archiving
                                            or storage
        multimedia      mpeg, mov, mp3,     binary file containing
                        mp4, avi            audio or A/V information
                        Figure 11.3      Common file types.
Consider, too, the Mac OS X operating system. In this system, each file has
a type, such as .app (for application). Each file also has a creator attribute
containing the name of the program that created it. This attribute is set by
the operating system during the create() call, so its use is enforced and
supported by the system. For instance, a file produced by a word processor
has the word processor's name as its creator. When the user opens that file, by
double-clicking the mouse on the icon representing the file, the word processor
is invoked automatically and the file is loaded, ready to be edited.
The UNIX system uses a crude magic number stored at the beginning of
some files to indicate roughly the type of the file --executable program, shell
script, PDF file, and so on. Not all files have magic numbers, so system features
cannot be based solely on this information. UNIX does not record the name of
the creating program, either. UNIX does allow file-name-extension hints, but
these extensions are neither enforced nor depended on by the operating system;
they are meant mostly to aid users in determining what type of contents the
file contains. Extensions can be used or ignored by a given application, but that
is up to the application's programmer.
11.1.4  File Structure
File types also can be used to indicate the internal structure of the file. As
mentioned in Section 11.1.3, source and object files have structures that match
the expectations of the programs that read them. Further, certain files must



512  Chapter 11     File-System Interface
     conform to a required structure that is understood by the operating system. For
     example, the operating system requires that an executable file have a specific
     structure so that it can determine where in memory to load the file and what
     the location of the first instruction is. Some operating systems extend this idea
     into a set of system-supported file structures, with sets of special operations
     for manipulating files with those structures.
         This point brings us to one of the disadvantages of having the operating
     system support multiple file structures: the resulting size of the operating
     system  is   cumbersome.      If  the  operating  system  defines    five  different    file
     structures,  it  needs    to  contain  the  code  to    support  these   file  structures.
     In  addition,    it  may  be  necessary     to  define  every  file  as  one   of  the  file
     types supported by the operating system. When new applications require
     information structured in ways not supported by the operating system, severe
     problems may result.
         For example, assume that a system supports two types of files: text files
     (composed of ASCII characters separated by a carriage return and line feed)
     and executable binary files. Now, if we (as users) want to define an encrypted
     file to protect the contents from being read by unauthorized people, we may
     find neither file type to be appropriate. The encrypted file is not ASCII text lines
     but rather is (apparently) random bits. Although it may appear to be a binary
     file, it is not executable. As a result, we may have to circumvent or misuse the
     operating system's file-type mechanism or abandon our encryption scheme.
         Some operating systems impose (and support) a minimal number of file
     structures. This approach has been adopted in UNIX, Windows, and others.
     UNIX considers each file to be a sequence of 8-bit bytes; no interpretation of
     these bits is made by the operating system. This scheme provides maximum
     flexibility but little support. Each application program must include its own
     code to interpret an input file as to the appropriate structure. However, all
     operating systems must support at least one structure--that of an executable
     file --so that the system is able to load and run programs.
     11.1.5  Internal File Structure
     Internally, locating an offset within a file can be complicated for the operating
     system. Disk systems typically have a well-defined block size determined by
     the size of a sector. All disk I/O is performed in units of one block (physical
     record), and all blocks are the same size. It is unlikely that the physical record
     size will exactly match the length of the desired logical record. Logical records
     may even vary in length. Packing a number of logical records into physical
     blocks is a common solution to this problem.
         For example, the UNIX operating system defines all files to be simply
     streams of bytes. Each byte is individually addressable by its offset from the
     beginning (or end) of the file. In this case, the logical record size is 1 byte. The
     file system automatically packs and unpacks bytes into physical disk blocks--
     say, 512 bytes per block--as necessary.
         The logical record size, physical block size, and packing technique deter-
     mine how many logical records are in each physical block. The packing can be
     done either by the user's application program or by the operating system. In
     either case, the file may be considered a sequence of blocks. All the basic I/O



                                                           11.2  Access Methods           513
                beginning               current position         end
                           rewind       read or write
                           Figure 11.4  Sequential-access file.
      functions operate in terms of blocks. The conversion from logical records to
      physical blocks is a relatively simple software problem.
      Because disk space is always allocated in blocks, some portion of the last
      block of each file is generally wasted. If each block were 512 bytes, for example,
      then a file of 1,949 bytes would be allocated four blocks (2,048 bytes); the last
      99 bytes would be wasted. The waste incurred to keep everything in units
      of blocks (instead of bytes) is internal fragmentation. All file systems suffer
      from internal fragmentation; the larger the block size, the greater the internal
      fragmentation.
11.2  Access Methods
      Files store information. When it is used, this information must be accessed
      and read into computer memory. The information in the file can be accessed
      in several ways. Some systems provide only one access method for files.
      while others support many access methods, and choosing the right one for
      a particular application is a major design problem.
      11.2.1    Sequential Access
      The simplest access method is sequential access. Information in the file is
      processed in order, one record after the other. This mode of access is by far the
      most common; for example, editors and compilers usually access files in this
      fashion.
      Reads and writes make up the bulk of the operations on a file. A read
      operation--read next()--reads the next portion of the file and automatically
      advances a file pointer, which tracks the I/O location. Similarly, the write
      operation--write next()--appends to the end of the file and advances to the
      end of the newly written material (the new end of file). Such a file can be reset
      to the beginning, and on some systems, a program may be able to skip forward
      or backward n records for some integer n--perhaps only for n = 1. Sequential
      access, which is depicted in Figure 11.4, is based on a tape model of a file and
      works as well on sequential-access devices as it does on random-access ones.
      11.2.2    Direct Access
      Another method is direct access (or relative access). Here, a file is made up
      of fixed-length logical records that allow programs to read and write records
      rapidly in no particular order. The direct-access method is based on a disk
      model of a file, since disks allow random access to any file block. For direct



514  Chapter 11  File-System Interface
     access, the file is viewed as a numbered sequence of blocks or records. Thus,
     we may read block 14, then read block 53, and then write block 7. There are no
     restrictions on the order of reading or writing for a direct-access file.
        Direct-access files are of great use for immediate access to large amounts
     of information. Databases are often of this type. When a query concerning a
     particular subject arrives, we compute which block contains the answer and
     then read that block directly to provide the desired information.
        As a simple example, on an airline-reservation system, we might store all
     the information about a particular flight (for example, flight 713) in the block
     identified by the flight number. Thus, the number of available seats for flight
     713 is stored in block 713 of the reservation file. To store information about a
     larger set, such as people, we might compute a hash function on the people's
     names or search a small in-memory index to determine a block to read and
     search.
        For the direct-access method, the file operations must be modified to
     include the block number as a parameter. Thus, we have read(n), where
     n  is  the  block  number,  rather    than  read next(),  and        write(n)  rather
     than write next(). An alternative approach is to retain read next() and
     write next(), as with sequential access, and to add an operation posi-
     tion file(n) where n is the block number. Then, to effect a read(n), we
     would position file(n) and then read next().
        The block number provided by the user to the operating system is normally
     a relative block number. A relative block number is an index relative to the
     beginning of the file. Thus, the first relative block of the file is 0, the next is
     1, and so on, even though the absolute disk address may be 14703 for the
     first block and 3192 for the second. The use of relative block numbers allows
     the operating system to decide where the file should be placed (called the
     allocation problem, as we discuss in Chapter 12) and helps to prevent the user
     from accessing portions of the file system that may not be part of her file. Some
     systems start their relative block numbers at 0; others start at 1.
        How, then, does the system satisfy a request for record N in a file? Assuming
     we have a logical record length L, the request for record N is turned into an
     I/O request for L bytes starting at location L  (N) within the file (assuming the
     first record is N = 0). Since logical records are of a fixed size, it is also easy to
     read, write, or delete a record.
        Not all operating systems support both sequential and direct access for
     files. Some systems allow only sequential file access; others allow only direct
     access. Some systems require that a file be defined as sequential or direct when
     it is created. Such a file can be accessed only in a manner consistent with its
     declaration. We can easily simulate sequential access on a direct-access file by
     simply keeping a variable cp that defines our current position, as shown in
     Figure 11.5. Simulating a direct-access file on a sequential-access file, however,
     is extremely inefficient and clumsy.
     11.2.3      Other Access Methods
     Other access methods can be built on top of a direct-access method. These
     methods generally involve the construction of an index for the file. The index,
     like an index in the back of a book, contains pointers to the various blocks. To



                                      11.3  Directory and Disk Structure                    515
                   sequential access  implementation for direct access
                   reset                             cp  0;
                   read_next                         read cp ;
                                                     cp  cp     1;
                   write_next                        write cp;
                                                     cp  cp     1;
      Figure 11.5         Simulation of sequential access on a direct-access file.
      find a record in the file, we first search the index and then use the pointer to
      access the file directly and to find the desired record.
      For example, a retail-price file might list the universal product codes (UPCs)
      for items, with the associated prices. Each record consists of a 10-digit UPC and
      a 6-digit price, for a 16-byte record. If our disk has 1,024 bytes per block, we
      can store 64 records per block. A file of 120,000 records would occupy about
      2,000 blocks (2 million bytes). By keeping the file sorted by UPC, we can define
      an index consisting of the first UPC in each block. This index would have 2,000
      entries of 10 digits each, or 20,000 bytes, and thus could be kept in memory. To
      find the price of a particular item, we can make a binary search of the index.
      From this search, we learn exactly which block contains the desired record and
      access that block. This structure allows us to search a large file doing little I/O.
      With large files, the index file itself may become too large to be kept in
      memory. One solution is to create an index for the index file. The primary
      index file contains pointers to secondary index files, which point to the actual
      data items.
      For example, IBM's indexed sequential-access method (ISAM) uses a small
      master index that points to disk blocks of a secondary index. The secondary
      index blocks point to the actual file blocks. The file is kept sorted on a defined
      key. To find a particular item, we first make a binary search of the master index,
      which provides the block number of the secondary index. This block is read
      in, and again a binary search is used to find the block containing the desired
      record. Finally, this block is searched sequentially. In this way, any record can
      be located from its key by at most two direct-access reads. Figure 11.6 shows a
      similar situation as implemented by VMS index and relative files.
11.3  Directory and Disk Structure
      Next, we consider how to store files. Certainly, no general-purpose computer
      stores just one file. There are typically thousands, millions, even billions of
      files within a computer. Files are stored on random-access storage devices,
      including hard disks, optical disks, and solid-state (memory-based) disks.
      A storage device can be used in its entirety for a file system. It can also be
      subdivided for finer-grained control. For example, a disk can be partitioned
      into quarters, and each quarter can hold a separate file system. Storage devices
      can also be collected together into RAID sets that provide protection from the
      failure of a single disk (as described in Section 10.7). Sometimes, disks are
      subdivided and also collected into RAID sets.



516  Chapter  11  File-System Interface
                          logical record
              last name   number
                  Adams
                  Arthur
                  Asher                           smith, john social-security age
                  ·
                  ·
                  ·
                  Smith
                     index file                                relative file
                          Figure 11.6     Example of index and relative files.
     Partitioning is useful for limiting the sizes of individual file systems,
     putting multiple file-system types on the same device, or leaving part of the
     device available for other uses, such as swap space or unformatted (raw) disk
     space. A file system can be created on each of these parts of the disk. Any entity
     containing a file system is generally known as a volume. The volume may be
     a subset of a device, a whole device, or multiple devices linked together into
     a RAID set. Each volume can be thought of as a virtual disk. Volumes can also
     store multiple operating systems, allowing a system to boot and run more than
     one operating system.
     Each volume that contains a file system must also contain information
     about the files in the system. This information is kept in entries in a device
     directory or volume table of contents. The device directory (more commonly
     known simply as the directory) records information--such as name, location,
     size, and type--for all files on that volume. Figure 11.7 shows a typical
     file-system organization.
                          directory                            directory
     partition A                 files                                          disk 2
                                          disk 1
                          directory               partition C
                                                               files
     partition B                 files
                                                                                disk 3
                          Figure 11.7     A typical file-system organization.



                                  11.3     Directory and Disk Structure           517
                  /                        ufs
                  /devices                 devfs
                  /dev                     dev
                  /system/contract         ctfs
                  /proc                    proc
                  /etc/mnttab              mntfs
                  /etc/svc/volatile        tmpfs
                  /system/object           objfs
                  /lib/libc.so.1           lofs
                  /dev/fd                  fd
                  /var                     ufs
                  /tmp                     tmpfs
                  /var/run                 tmpfs
                  /opt                     ufs
                  /zpbge                   zfs
                  /zpbge/backup            zfs
                  /export/home             zfs
                  /var/mail                zfs
                  /var/spool/mqueue        zfs
                  /zpbg                    zfs
                  /zpbg/zones              zfs
                     Figure 11.8  Solaris file systems.
11.3.1  Storage Structure
As we have just seen, a general-purpose computer system has multiple storage
devices, and those devices can be sliced up into volumes that hold file systems.
Computer systems may have zero or more file systems, and the file systems
may be of varying types. For example, a typical Solaris system may have dozens
of file systems of a dozen different types, as shown in the file system list in
Figure 11.8.
   In this book, we consider only general-purpose file systems. It is worth
noting, though, that there are many special-purpose file systems. Consider the
types of file systems in the Solaris example mentioned above:
·  tmpfs--a "temporary" file system that is created in volatile main memory
   and has its contents erased if the system reboots or crashes
·  objfs--a "virtual" file system (essentially an interface to the kernel that
   looks like a file system) that gives debuggers access to kernel symbols
·  ctfs--a virtual file system that maintains "contract" information to manage
   which processes start when the system boots and must continue to run
   during operation
·  lofs--a "loop back" file system that allows one file system to be accessed
   in place of another one
·  procfs--a virtual file system that presents information on all processes as
   a file system
·  ufs, zfs--general-purpose file systems



518  Chapter 11      File-System Interface
        The file systems of computers, then, can be extensive. Even within a file
     system, it is useful to segregate files into groups and manage and act on those
     groups. This organization involves the use of directories. In the remainder of
     this section, we explore the topic of directory structure.
     11.3.2  Directory Overview
     The directory can be viewed as a symbol table that translates file names into
     their directory entries. If we take such a view, we see that the directory itself can
     be organized in many ways. The organization must allow us to insert entries,
     to delete entries, to search for a named entry, and to list all the entries in the
     directory. In this section, we examine several schemes for defining the logical
     structure of the directory system.
        When considering a particular directory structure, we need to keep in mind
     the operations that are to be performed on a directory:
     ·  Search for a file. We need to be able to search a directory structure to find
        the entry for a particular file. Since files have symbolic names, and similar
        names may indicate a relationship among files, we may want to be able to
        find all files whose names match a particular pattern.
     ·  Create a file. New files need to be created and added to the directory.
     ·  Delete a file. When a file is no longer needed, we want to be able to remove
        it from the directory.
     ·  List a directory. We need to be able to list the files in a directory and the
        contents of the directory entry for each file in the list.
     ·  Rename a file. Because the name of a file represents its contents to its users,
        we must be able to change the name when the contents or use of the file
        changes. Renaming a file may also allow its position within the directory
        structure to be changed.
     ·  Traverse the file system. We may wish to access every directory and every
        file within a directory structure. For reliability, it is a good idea to save the
        contents and structure of the entire file system at regular intervals. Often,
        we do this by copying all files to magnetic tape. This technique provides a
        backup copy in case of system failure. In addition, if a file is no longer in
        use, the file can be copied to tape and the disk space of that file released
        for reuse by another file.
     In the following sections, we describe the most common schemes for defining
     the logical structure of a directory.
     11.3.3  Single-Level Directory
     The simplest directory structure is the single-level directory. All files are
     contained in the same directory, which is easy to support and understand
     (Figure 11.9).
        A single-level directory has significant limitations, however, when the
     number of files increases or when the system has more than one user. Since all
     files are in the same directory, they must have unique names. If two users call



                                                11.3    Directory and Disk Structure                 519
directory           cat      bo           a     test    data          mail  cont       hex  records
        files
                                 Figure 11.9    Single-level directory.
their data file test.txt, then the unique-name rule is violated. For example,
in one programming class, 23 students called the program for their second
assignment prog2.c; another 11 called it assign2.c. Fortunately, most file
systems support file names of up to 255 characters, so it is relatively easy to
select unique file names.
Even a single user on a single-level directory may find it difficult to
remember the names of all the files as the number of files increases. It is not
uncommon for a user to have hundreds of files on one computer system and an
equal number of additional files on another system. Keeping track of so many
files is a daunting task.
11.3.4     Two-Level Directory
As we have seen, a single-level directory often leads to confusion of file names
among different users. The standard solution is to create a separate directory
for each user.
In      the    two-level     directory          structure,      each  user  has   his  own  user     file
directory (UFD). The UFDs have similar structures, but each lists only the
files of a single user. When a user job starts or a user logs in, the system's
master file directory (MFD) is searched. The MFD is indexed by user name or
account number, and each entry points to the UFD for that user (Figure 11.10).
When a user refers to a particular file, only his own UFD is searched. Thus,
different users may have files with the same name, as long as all the file names
within each UFD are unique. To create a file for a user, the operating system
searches only that user's UFD to ascertain whether another file of that name
exists. To delete a file, the operating system confines its search to the local UFD;
thus, it cannot accidentally delete another user's file that has the same name.
                             master file     user 1     user 2  user 3   user 4
                             directory
user file      cat       bo      a        test       a  data          a     test  x         data  a
directory
                             Figure 11.10       Two-level directory structure.



520  Chapter 11  File-System Interface
        The user directories themselves must be created and deleted as necessary.
     A special system program is run with the appropriate user name and account
     information. The program creates a new UFD and adds an entry for it to the MFD.
     The execution of this program might be restricted to system administrators. The
     allocation of disk space for user directories can be handled with the techniques
     discussed in Chapter 12 for files themselves.
        Although the two-level directory structure solves the name-collision prob-
     lem, it still has disadvantages. This structure effectively isolates one user from
     another. Isolation is an advantage when the users are completely independent
     but is a disadvantage when the users want to cooperate on some task and to
     access one another's files. Some systems simply do not allow local user files to
     be accessed by other users.
        If access is to be permitted, one user must have the ability to name a file
     in another user's directory. To name a particular file uniquely in a two-level
     directory, we must give both the user name and the file name. A two-level
     directory can be thought of as a tree, or an inverted tree, of height 2. The root
     of the tree is the MFD. Its direct descendants are the UFDs. The descendants of
     the UFDs are the files themselves. The files are the leaves of the tree. Specifying
     a user name and a file name defines a path in the tree from the root (the MFD)
     to a leaf (the specified file). Thus, a user name and a file name define a path
     name. Every file in the system has a path name. To name a file uniquely, a user
     must know the path name of the file desired.
        For example, if user A wishes to access her own test file named test.txt,
     she can simply refer to test.txt. To access the file named test.txt of
     user B (with directory-entry name userb), however, she might have to refer
     to /userb/test.txt. Every system has its own syntax for naming files in
     directories other than the user's own.
        Additional syntax is needed to specify the volume of a file. For instance,
     in Windows a volume is specified by a letter followed by a colon. Thus,
     a  file  specification  might  be  C:\userb\test.  Some  systems  go  even           fur-
     ther and separate the volume, directory name, and file name parts of the
     specification. In VMS, for instance, the file login.com might be specified as:
     u:[sst.jdeck]login.com;1, where u is the name of the volume, sst is the
     name of the directory, jdeck is the name of the subdirectory, and 1 is the
     version number. Other systems--such as UNIX and Linux--simply treat the
     volume name as part of the directory name. The first name given is that of the
     volume, and the rest is the directory and file. For instance, /u/pbg/test might
     specify volume u, directory pbg, and file test.
        A special instance of this situation occurs with the system files. Programs
     provided as part of the system--loaders, assemblers, compilers, utility rou-
     tines, libraries, and so on--are generally defined as files. When the appropriate
     commands are given to the operating system, these files are read by the loader
     and executed. Many command interpreters simply treat such a command as
     the name of a file to load and execute. In the directory system as we defined it
     above, this file name would be searched for in the current UFD. One solution
     would be to copy the system files into each UFD. However, copying all the
     system files would waste an enormous amount of space. (If the system files
     require 5 MB, then supporting 12 users would require 5 × 12 = 60 MB just for
     copies of the system files.)



                                               11.3        Directory and Disk Structure          521
The standard solution is to complicate the search procedure slightly. A
special user directory is defined to contain the system files (for example, user
0). Whenever a file name is given to be loaded, the operating system first
searches the local UFD. If the file is found, it is used. If it is not found, the system
automatically searches the special user directory that contains the system files.
The sequence of directories searched when a file is named is called the search
path. The search path can be extended to contain an unlimited list of directories
to search when a command name is given. This method is the one most used
in UNIX and Windows. Systems can also be designed so that each user has his
own search path.
11.3.5  Tree-Structured Directories
Once we have seen how to view a two-level directory as a two-level tree,
the natural generalization is to extend the directory structure to a tree of
arbitrary height (Figure 11.11). This generalization allows users to create their
own subdirectories and to organize their files accordingly. A tree is the most
common directory structure. The tree has a root directory, and every file in the
system has a unique path name.
A directory (or subdirectory) contains a set of files or subdirectories. A
directory is simply another file, but it is treated in a special way. All directories
have the same internal format. One bit in each directory entry defines the entry
as a file (0) or as a subdirectory (1). Special system calls are used to create and
delete directories.
In normal use, each process has a current directory. The current directory
should contain most of the files that are of current interest to the process.
When reference is made to a file, the current directory is searched. If a file
is needed that is not in the current directory, then the user usually must
                             root       spell         bin    programs
        stat  mail   dist          find        count       hex  reorder        p     e    mail
        prog  copy   prt     exp                      reorder   list     find        hex  count
        list  obj    spell         all         last   first
                     Figure  11.11      Tree-structured directory        structure.



522  Chapter 11  File-System Interface
     either specify a path name or change the current directory to be the directory
     holding that file. To change directories, a system call is provided that takes a
     directory name as a parameter and uses it to redefine the current directory.
     Thus, the user can change her current directory whenever she wants. From one
     change directory() system call to the next, all open() system calls search
     the current directory for the specified file. Note that the search path may or
     may not contain a special entry that stands for "the current directory."
     The initial current directory of a user's login shell is designated when
     the user job starts or the user logs in. The operating system searches the
     accounting file (or some other predefined location) to find an entry for this
     user (for accounting purposes). In the accounting file is a pointer to (or the
     name of) the user's initial directory. This pointer is copied to a local variable
     for this user that specifies the user's initial current directory. From that shell,
     other processes can be spawned. The current directory of any subprocess is
     usually the current directory of the parent when it was spawned.
     Path names can be of two types: absolute and relative. An absolute path
     name begins at the root and follows a path down to the specified file, giving
     the directory names on the path. A relative path name defines a path from the
     current directory. For example, in the tree-structured file system of Figure
     11.11, if the current directory is root/spell/mail, then the relative path
     name prt/first refers to the same file as does the absolute path name
     root/spell/mail/prt/first.
     Allowing a user to define her own subdirectories permits her to impose
     a structure on her files. This structure might result in separate directories for
     files associated with different topics (for example, a subdirectory was created
     to hold the text of this book) or different forms of information (for example,
     the directory programs may contain source programs; the directory bin may
     store all the binaries).
     An interesting policy decision in a tree-structured directory concerns how
     to handle the deletion of a directory. If a directory is empty, its entry in the
     directory that contains it can simply be deleted. However, suppose the directory
     to be deleted is not empty but contains several files or subdirectories. One of
     two approaches can be taken. Some systems will not delete a directory unless
     it is empty. Thus, to delete a directory, the user must first delete all the files
     in that directory. If any subdirectories exist, this procedure must be applied
     recursively to them, so that they can be deleted also. This approach can result
     in a substantial amount of work. An alternative approach, such as that taken
     by the UNIX rm command, is to provide an option: when a request is made
     to delete a directory, all that directory's files and subdirectories are also to be
     deleted. Either approach is fairly easy to implement; the choice is one of policy.
     The latter policy is more convenient, but it is also more dangerous, because an
     entire directory structure can be removed with one command. If that command
     is issued in error, a large number of files and directories will need to be restored
     (assuming a backup exists).
     With a tree-structured directory system, users can be allowed to access, in
     addition to their files, the files of other users. For example, user B can access a
     file of user A by specifying its path names. User B can specify either an absolute
     or a relative path name. Alternatively, user B can change her current directory
     to be user A's directory and access the file by its file names.



                                       11.3   Directory and Disk Structure             523
11.3.6  Acyclic-Graph Directories
Consider two programmers who are working on a joint project. The files asso-
ciated with that project can be stored in a subdirectory, separating them from
other projects and files of the two programmers. But since both programmers
are equally responsible for the project, both want the subdirectory to be in their
own directories. In this situation, the common subdirectory should be shared.
A shared directory or file exists in the file system in two (or more) places at
once.
A tree structure prohibits the sharing of files or directories. An acyclic graph
--that is, a graph with no cycles--allows directories to share subdirectories
and files (Figure 11.12). The same file or subdirectory may be in two different
directories. The acyclic graph is a natural generalization of the tree-structured
directory scheme.
It is important to note that a shared file (or directory) is not the same as two
copies of the file. With two copies, each programmer can view the copy rather
than the original, but if one programmer changes the file, the changes will not
appear in the other's copy. With a shared file, only one actual file exists, so any
changes made by one person are immediately visible to the other. Sharing is
particularly important for subdirectories; a new file created by one person will
automatically appear in all the shared subdirectories.
When people are working as a team, all the files they want to share can be
put into one directory. The UFD of each team member will contain this directory
of shared files as a subdirectory. Even in the case of a single user, the user's file
organization may require that some file be placed in different subdirectories.
For example, a program written for a particular project should be both in the
directory of all programs and in the directory for that project.
Shared files and subdirectories can be implemented in several ways. A
common way, exemplified by many of the UNIX systems, is to create a new
directory entry called a link. A link is effectively a pointer to another file
                                 root   dict  spell
        list       all  w        count               count words     list
                                       list   rade  w7
                   Figure 11.12  Acyclic-graph directory structure.



524  Chapter 11  File-System Interface
     or subdirectory. For example, a link may be implemented as an absolute or a
     relative path name. When a reference to a file is made, we search the directory. If
     the directory entry is marked as a link, then the name of the real file is included
     in the link information. We resolve the link by using that path name to locate
     the real file. Links are easily identified by their format in the directory entry
     (or by having a special type on systems that support types) and are effectively
     indirect pointers. The operating system ignores these links when traversing
     directory trees to preserve the acyclic structure of the system.
     Another common approach to implementing shared files is simply to
     duplicate all information about them in both sharing directories. Thus, both
     entries are identical and equal. Consider the difference between this approach
     and the creation of a link. The link is clearly different from the original directory
     entry; thus, the two are not equal. Duplicate directory entries, however, make
     the original and the copy indistinguishable. A major problem with duplicate
     directory entries is maintaining consistency when a file is modified.
     An acyclic-graph directory structure is more flexible than a simple tree
     structure, but it is also more complex. Several problems must be considered
     carefully. A file may now have multiple absolute path names. Consequently,
     distinct file names may refer to the same file. This situation is similar to the
     aliasing problem for programming languages. If we are trying to traverse the
     entire file system--to find a file, to accumulate statistics on all files, or to copy
     all files to backup storage --this problem becomes significant, since we do not
     want to traverse shared structures more than once.
     Another problem involves deletion. When can the space allocated to a
     shared file be deallocated and reused? One possibility is to remove the file
     whenever anyone deletes it, but this action may leave dangling pointers to the
     now-nonexistent file. Worse, if the remaining file pointers contain actual disk
     addresses, and the space is subsequently reused for other files, these dangling
     pointers may point into the middle of other files.
     In a system where sharing is implemented by symbolic links, this situation
     is somewhat easier to handle. The deletion of a link need not affect the original
     file; only the link is removed. If the file entry itself is deleted, the space for
     the file is deallocated, leaving the links dangling. We can search for these links
     and remove them as well, but unless a list of the associated links is kept with
     each file, this search can be expensive. Alternatively, we can leave the links
     until an attempt is made to use them. At that time, we can determine that the
     file of the name given by the link does not exist and can fail to resolve the
     link name; the access is treated just as with any other illegal file name. (In this
     case, the system designer should consider carefully what to do when a file is
     deleted and another file of the same name is created, before a symbolic link to
     the original file is used.) In the case of UNIX, symbolic links are left when a file
     is deleted, and it is up to the user to realize that the original file is gone or has
     been replaced. Microsoft Windows uses the same approach.
     Another approach to deletion is to preserve the file until all references to
     it are deleted. To implement this approach, we must have some mechanism
     for determining that the last reference to the file has been deleted. We could
     keep a list of all references to a file (directory entries or symbolic links). When
     a link or a copy of the directory entry is established, a new entry is added to
     the file-reference list. When a link or directory entry is deleted, we remove its
     entry on the list. The file is deleted when its file-reference list is empty.



                                     11.3        Directory and Disk Structure          525
The trouble with this approach is the variable and potentially large size
of the file-reference list. However, we really do not need to keep the entire
list--we need to keep only a count of the number of references. Adding a
new link or directory entry increments the reference count. Deleting a link
or entry decrements the count. When the count is 0, the file can be deleted;
there are no remaining references to it. The UNIX operating system uses this
approach for nonsymbolic links (or hard links), keeping a reference count in the
file information block (or inode; see Section A.7.2). By effectively prohibiting
multiple references to directories, we maintain an acyclic-graph structure.
To avoid problems such as the ones just discussed, some systems simply
do not allow shared directories or links.
11.3.7   General Graph Directory
A serious problem with using an acyclic-graph structure is ensuring that there
are no cycles. If we start with a two-level directory and allow users to create
subdirectories, a tree-structured directory results. It should be fairly easy to see
that simply adding new files and subdirectories to an existing tree-structured
directory preserves the tree-structured nature. However, when we add links,
the tree structure is destroyed, resulting in a simple graph structure (Figure
11.13).
The primary advantage of an acyclic graph is the relative simplicity of the
algorithms to traverse the graph and to determine when there are no more
references to a file. We want to avoid traversing shared sections of an acyclic
graph twice, mainly for performance reasons. If we have just searched a major
shared subdirectory for a particular file without finding it, we want to avoid
searching that subdirectory again; the second search would be a waste of time.
If       cycles  are   allowed  to   exist  in   the  directory,  we  likewise   want  to
avoid searching any component twice, for reasons of correctness as well as
performance. A poorly designed algorithm might result in an infinite loop
continually searching through the cycle and never terminating. One solution
                       root     avi  tc          jim
         text    mail  count  book               book   mail  unhex   hyp
                                            avi  count               unhex  hex
                       Figure 11.13  General graph directory.



526   Chapter 11  File-System Interface
      is to limit arbitrarily the number of directories that will be accessed during a
      search.
      A similar problem exists when we are trying to determine when a file
      can be deleted. With acyclic-graph directory structures, a value of 0 in the
      reference count means that there are no more references to the file or directory,
      and the file can be deleted. However, when cycles exist, the reference count
      may not be 0 even when it is no longer possible to refer to a directory or file.
      This anomaly results from the possibility of self-referencing (or a cycle) in the
      directory structure. In this case, we generally need to use a garbage collection
      scheme to determine when the last reference has been deleted and the disk
      space can be reallocated. Garbage collection involves traversing the entire file
      system, marking everything that can be accessed. Then, a second pass collects
      everything that is not marked onto a list of free space. (A similar marking
      procedure can be used to ensure that a traversal or search will cover everything
      in the file system once and only once.) Garbage collection for a disk-based file
      system, however, is extremely time consuming and is thus seldom attempted.
      Garbage collection is necessary only because of possible cycles in the graph.
      Thus, an acyclic-graph structure is much easier to work with. The difficulty
      is to avoid cycles as new links are added to the structure. How do we know
      when a new link will complete a cycle? There are algorithms to detect cycles
      in graphs; however, they are computationally expensive, especially when the
      graph is on disk storage. A simpler algorithm in the special case of directories
      and links is to bypass links during directory traversal. Cycles are avoided, and
      no extra overhead is incurred.
11.4  File-System Mounting
      Just as a file must be opened before it is used, a file system must be mounted
      before it can be available to processes on the system. More specifically, the
      directory structure may be built out of multiple volumes, which must be
      mounted to make them available within the file-system name space.
      The mount procedure is straightforward. The operating system is given the
      name of the device and the mount point--the location within the file structure
      where the file system is to be attached. Some operating systems require that a
      file system type be provided, while others inspect the structures of the device
      and determine the type of file system. Typically, a mount point is an empty
      directory. For instance, on a UNIX system, a file system containing a user's home
      directories might be mounted as /home; then, to access the directory structure
      within that file system, we could precede the directory names with /home, as
      in /home/jane. Mounting that file system under /users would result in the
      path name /users/jane, which we could use to reach the same directory.
      Next, the operating system verifies that the device contains a valid file
      system. It does so by asking the device driver to read the device directory
      and verifying that the directory has the expected format. Finally, the operating
      system notes in its directory structure that a file system is mounted at the
      specified mount point. This scheme enables the operating system to traverse
      its directory structure, switching among file systems, and even file systems of
      varying types, as appropriate.



                                        11.4   File-System Mounting                 527
      /
              users
bill                 fred               sue                    jane
                           help                          prog          doc
              (a)                                   (b)
Figure 11.14  File system. (a) Existing system. (b) Unmounted volume.
To illustrate file mounting, consider the file system depicted in Figure
11.14, where the triangles represent subtrees of directories that are of interest.
Figure 11.14(a) shows an existing file system, while Figure 11.14(b) shows an
unmounted volume residing on /device/dsk. At this point, only the files
on the existing file system can be accessed. Figure 11.15 shows the effects of
mounting the volume residing on /device/dsk over /users. If the volume is
unmounted, the file system is restored to the situation depicted in Figure 11.14.
Systems impose semantics to clarify functionality. For example, a system
may disallow a mount over a directory that contains files; or it may make the
mounted file system available at that directory and obscure the directory's
existing files until the file system is unmounted, terminating the use of the file
system and allowing access to the original files in that directory. As another
example, a system may allow the same file system to be mounted repeatedly,
at different mount points; or it may only allow one mount per file system.
                           /
                                 users
                     sue                 jane
                                   prog        doc
                     Figure 11.15  Mount point.



528   Chapter 11  File-System Interface
      Consider the actions of the Mac OS X operating system. Whenever the
      system encounters a disk for the first time (either at boot time or while the
      system is running), the Mac OS X operating system searches for a file system
      on the device. If it finds one, it automatically mounts the file system under
      the /Volumes directory, adding a folder icon labeled with the name of the file
      system (as stored in the device directory). The user is then able to click on the
      icon and thus display the newly mounted file system.
      The Microsoft Windows family of operating systems maintains an extended
      two-level directory structure, with devices and volumes assigned drive letters.
      Volumes have a general graph directory structure associated with the drive let-
      ter. The path to a specific file takes the form of drive-letter:\path\to\file.
      The more recent versions of Windows allow a file system to be mounted
      anywhere in the directory tree, just as UNIX does. Windows operating systems
      automatically discover all devices and mount all located file systems at boot
      time. In some systems, like UNIX, the mount commands are explicit. A system
      configuration file contains a list of devices and mount points for automatic
      mounting at boot time, but other mounts may be executed manually.
      Issues concerning file system mounting are further discussed in Section
      12.2.2 and in Section A.7.5.
11.5  File Sharing
      In the previous sections, we explored the motivation for file sharing and some of
      the difficulties involved in allowing users to share files. Such file sharing is very
      desirable for users who want to collaborate and to reduce the effort required
      to achieve a computing goal. Therefore, user-oriented operating systems must
      accommodate the need to share files in spite of the inherent difficulties.
      In this section, we examine more aspects of file sharing. We begin by
      discussing general issues that arise when multiple users share files. Once
      multiple users are allowed to share files, the challenge is to extend sharing to
      multiple file systems, including remote file systems; we discuss that challenge
      as well. Finally, we consider what to do about conflicting actions occurring on
      shared files. For instance, if multiple users are writing to a file, should all the
      writes be allowed to occur, or should the operating system protect the users'
      actions from one another?
      11.5.1  Multiple Users
      When an operating system accommodates multiple users, the issues of file
      sharing, file naming, and file protection become preeminent. Given a directory
      structure that allows files to be shared by users, the system must mediate the
      file sharing. The system can either allow a user to access the files of other users
      by default or require that a user specifically grant access to the files. These are
      the issues of access control and protection, which are covered in Section 11.6.
      To implement sharing and protection, the system must maintain more
      file and directory attributes than are needed on a single-user system. Although
      many approaches have been taken to meet this requirement, most systems have
      evolved to use the concepts of file (or directory) owner (or user) and group.
      The owner is the user who can change attributes and grant access and who has



                                                     11.5      File Sharing          529
the most control over the file. The group attribute defines a subset of users who
can share access to the file. For example, the owner of a file on a UNIX system
can issue all operations on a file, while members of the file's group can execute
one subset of those operations, and all other users can execute another subset
of operations. Exactly which operations can be executed by group members
and other users is definable by the file's owner. More details on permission
attributes are included in the next section.
The owner and group IDs of a given file (or directory) are stored with the
other file attributes. When a user requests an operation on a file, the user ID can
be compared with the owner attribute to determine if the requesting user is the
owner of the file. Likewise, the group IDs can be compared. The result indicates
which permissions are applicable. The system then applies those permissions
to the requested operation and allows or denies it.
Many systems have multiple local file systems, including volumes of a
single disk or multiple volumes on multiple attached disks. In these cases,
the ID checking and permission matching are straightforward, once the file
systems are mounted.
11.5.2    Remote File Systems
With the advent of networks (Chapter 17), communication among remote
computers became possible. Networking allows the sharing of resources spread
across a campus or even around the world. One obvious resource to share is
data in the form of files.
Through the evolution of network and file technology, remote file-sharing
methods have changed. The first implemented method involves manually
transferring files between machines via programs like ftp. The second major
method uses a distributed file system (DFS) in which remote directories are
visible from a local machine. In some ways, the third method, the World Wide
Web, is a reversion to the first. A browser is needed to gain access to the
remote files, and separate operations (essentially a wrapper for ftp) are used
to transfer files. Increasingly, cloud computing (Section 1.11.7) is being used
for file sharing as well.
ftp is used for both anonymous and authenticated access. Anonymous
access allows a user to transfer files without having an account on the remote
system. The World Wide Web uses anonymous file exchange almost exclusively.
DFS involves a much tighter integration between the machine that is accessing
the remote files and the machine providing the files. This integration adds
complexity, as we describe in this section.
11.5.2.1  The Client­Server Model
Remote file systems allow a computer to mount one or more file systems from
one or more remote machines. In this case, the machine containing the files
is the server, and the machine seeking access to the files is the client. The
client­server relationship is common with networked machines. Generally,
the server declares that a resource is available to clients and specifies exactly
which resource (in this case, which files) and exactly which clients. A server
can serve multiple clients, and a client can use multiple servers, depending on
the implementation details of a given client­server facility.



530  Chapter 11      File-System Interface
         The server usually specifies the available files on a volume or directory
     level.  Client  identification  is  more  difficult.  A  client   can  be  specified  by
     a network name or other identifier, such as an IP address, but these can
     be  spoofed,    or  imitated.   As  a  result  of  spoofing,  an  unauthorized  client
     could be allowed access to the server. More secure solutions include secure
     authentication of the client via encrypted keys. Unfortunately, with security
     come many challenges, including ensuring compatibility of the client and
     server (they must use the same encryption algorithms) and security of key
     exchanges (intercepted keys could again allow unauthorized access). Because
     of the difficulty of solving these problems, unsecure authentication methods
     are most commonly used.
         In the case of UNIX and its network file system (NFS), authentication takes
     place via the client networking information, by default. In this scheme, the
     user's IDs on the client and server must match. If they do not, the server will
     be unable to determine access rights to files. Consider the example of a user
     who has an ID of 1000 on the client and 2000 on the server. A request from
     the client to the server for a specific file will not be handled appropriately, as
     the server will determine if user 1000 has access to the file rather than basing
     the determination on the real user ID of 2000. Access is thus granted or denied
     based on incorrect authentication information. The server must trust the client
     to present the correct user ID. Note that the NFS protocols allow many-to-many
     relationships. That is, many servers can provide files to many clients. In fact,
     a given machine can be both a server to some NFS clients and a client of other
     NFS servers.
         Once the remote file system is mounted, file operation requests are sent
     on behalf of the user across the network to the server via the DFS protocol.
     Typically, a file-open request is sent along with the ID of the requesting user.
     The server then applies the standard access checks to determine if the user has
     credentials to access the file in the mode requested. The request is either allowed
     or denied. If it is allowed, a file handle is returned to the client application,
     and the application then can perform read, write, and other operations on the
     file. The client closes the file when access is completed. The operating system
     may apply semantics similar to those for a local file-system mount or may use
     different semantics.
     11.5.2.2  Distributed Information Systems
     To make client­server systems easier to manage, distributed information
     systems, also known as distributed naming services, provide unified access
     to the information needed for remote computing. The domain name system
     (DNS) provides host-name-to-network-address translations for the entire Inter-
     net. Before DNS became widespread, files containing the same information
     were sent via e-mail or ftp between all networked hosts. Obviously, this
     methodology was not scalable! DNS is further discussed in Section 17.4.1.
         Other distributed information systems provide user name/password/user
     ID/group ID space for a distributed facility. UNIX systems have employed a
     wide variety of distributed information methods. Sun Microsystems (now
     part of Oracle Corporation) introduced yellow pages (since renamed network
     information service, or NIS), and most of the industry adopted its use. It
     centralizes storage of user names, host names, printer information, and the like.



                                                           11.5    File Sharing       531
Unfortunately, it uses unsecure authentication methods, including sending
user passwords unencrypted (in clear text) and identifying hosts by IP address.
Sun's NIS+ was a much more secure replacement for NIS but was much more
complicated and was not widely adopted.
     In the case of Microsoft's common Internet file system (CIFS), network
information is used in conjunction with user authentication (user name and
password) to create a network login that the server uses to decide whether
to allow or deny access to a requested file system. For this authentication to
be valid, the user names must match from machine to machine (as with NFS).
Microsoft uses active directory as a distributed naming structure to provide a
single name space for users. Once established, the distributed naming facility
is used by all clients and servers to authenticate users.
     The industry is moving toward use of the lightweight directory-access
protocol (LDAP) as a secure distributed naming mechanism. In fact, active
directory is based on LDAP. Oracle Solaris and most other major operating
systems include LDAP and allow it to be employed for user authentication as
well as system-wide retrieval of information, such as availability of printers.
Conceivably, one distributed LDAP directory could be used by an organization
to store all user and resource information for all the organization's computers.
The  result  would  be  secure    single  sign-on  for     users,  who  would    enter
their authentication information once for access to all computers within the
organization. It would also ease system-administration efforts by combining,
in one location, information that is currently scattered in various files on each
system or in different distributed information services.
11.5.2.3  Failure Modes
Local file systems can fail for a variety of reasons, including failure of the
disk containing the file system, corruption of the directory structure or other
disk-management information (collectively called metadata), disk-controller
failure, cable failure, and host-adapter failure. User or system-administrator
failure can also cause files to be lost or entire directories or volumes to be
deleted. Many of these failures will cause a host to crash and an error condition
to be displayed, and human intervention will be required to repair the damage.
     Remote  file  systems  have  even    more  failure    modes.  Because       of   the
complexity of network systems and the required interactions between remote
machines, many more problems can interfere with the proper operation of
remote file systems. In the case of networks, the network can be interrupted
between two hosts. Such interruptions can result from hardware failure, poor
hardware configuration, or networking implementation issues. Although some
networks have built-in resiliency, including multiple paths between hosts,
many do not. Any single failure can thus interrupt the flow of DFS commands.
     Consider a client in the midst of using a remote file system. It has files open
from the remote host; among other activities, it may be performing directory
lookups to open files, reading or writing data to files, and closing files. Now
consider a partitioning of the network, a crash of the server, or even a scheduled
shutdown of the server. Suddenly, the remote file system is no longer reachable.
This scenario is rather common, so it would not be appropriate for the client
system to act as it would if a local file system were lost. Rather, the system can
either terminate all operations to the lost server or delay operations until the



532  Chapter 11      File-System Interface
     server is again reachable. These failure semantics are defined and implemented
     as part of the remote-file-system protocol. Termination of all operations can
     result in users' losing data--and patience. Thus, most DFS protocols either
     enforce or allow delaying of file-system operations to remote hosts, with the
     hope that the remote host will become available again.
        To     implement  this  kind  of    recovery  from  failure,  some  kind  of  state
     information may be maintained on both the client and the server. If both server
     and client maintain knowledge of their current activities and open files, then
     they can seamlessly recover from a failure. In the situation where the server
     crashes but must recognize that it has remotely mounted exported file systems
     and opened files, NFS takes a simple approach, implementing a stateless DFS.
     In essence, it assumes that a client request for a file read or write would not
     have occurred unless the file system had been remotely mounted and the file
     had been previously open. The NFS protocol carries all the information needed
     to locate the appropriate file and perform the requested operation. Similarly,
     it does not track which clients have the exported volumes mounted, again
     assuming that if a request comes in, it must be legitimate. While this stateless
     approach makes NFS resilient and rather easy to implement, it also makes it
     unsecure. For example, forged read or write requests could be allowed by an
     NFS server. These issues are addressed in the industry standard NFS Version
     4, in which NFS is made stateful to improve its security, performance, and
     functionality.
     11.5.3    Consistency Semantics
     Consistency semantics represent an important criterion for evaluating any
     file system that supports file sharing. These semantics specify how multiple
     users of a system are to access a shared file simultaneously. In particular, they
     specify when modifications of data by one user will be observable by other
     users. These semantics are typically implemented as code with the file system.
        Consistency semantics are directly related to the process synchronization
     algorithms of Chapter 5. However, the complex algorithms of that chapter tend
     not to be implemented in the case of file I/O because of the great latencies and
     slow transfer rates of disks and networks. For example, performing an atomic
     transaction to a remote disk could involve several network communications,
     several disk reads and writes, or both. Systems that attempt such a full set of
     functionalities tend to perform poorly. A successful implementation of complex
     sharing semantics can be found in the Andrew file system.
        For the following discussion, we assume that a series of file accesses (that
     is, reads and writes) attempted by a user to the same file is always enclosed
     between the open() and close() operations. The series of accesses between
     the open() and close() operations makes up a file session. To illustrate the
     concept, we sketch several prominent examples of consistency semantics.
     11.5.3.1  UNIX Semantics
     The UNIX file system (Chapter 17) uses the following consistency semantics:
     ·  Writes to an open file by a user are visible immediately to other users who
        have this file open.



                                                   11.6               Protection           533
      ·  One mode of sharing allows users to share the pointer of current location
         into the file. Thus, the advancing of the pointer by one user affects all
         sharing users. Here, a file has a single image that interleaves all accesses,
         regardless of their origin.
      In the UNIX semantics, a file is associated with a single physical image that
      is accessed as an exclusive resource. Contention for this single image causes
      delays in user processes.
      11.5.3.2   Session Semantics
      The Andrew file system (OpenAFS) uses the following consistency semantics:
      ·  Writes to an open file by a user are not visible immediately to other users
         that have the same file open.
      ·  Once a file is closed, the changes made to it are visible only in sessions
         starting later. Already open instances of the file do not reflect these changes.
      According to these semantics, a file may be associated temporarily with several
      (possibly different) images at the same time. Consequently, multiple users are
      allowed to perform both read and write accesses concurrently on their images
      of the file, without delay. Almost no constraints are enforced on scheduling
      accesses.
      11.5.3.3   Immutable-Shared-Files Semantics
      A unique approach is that of immutable shared files. Once a file is declared
      as shared by its creator, it cannot be modified. An immutable file has two key
      properties: its name may not be reused, and its contents may not be altered.
      Thus, the name of an immutable file signifies that the contents of the file are
      fixed. The implementation of these semantics in a distributed system (Chapter
      17) is simple, because the sharing is disciplined (read-only).
11.6  Protection
      When information is stored in a computer system, we want to keep it safe
      from physical damage (the issue of reliability) and improper access (the issue
      of protection).
         Reliability is generally provided by duplicate copies of files. Many comput-
      ers have systems programs that automatically (or through computer-operator
      intervention) copy disk files to tape at regular intervals (once per day or week
      or month) to maintain a copy should a file system be accidentally destroyed.
      File systems can be damaged by hardware problems (such as errors in reading
      or writing), power surges or failures, head crashes, dirt, temperature extremes,
      and vandalism. Files may be deleted accidentally. Bugs in the file-system soft-
      ware can also cause file contents to be lost. Reliability is covered in more detail
      in Chapter 10.



534  Chapter 11  File-System Interface
        Protection can be provided in many ways. For a single-user laptop system,
     we might provide protection by locking the computer in a desk drawer or file
     cabinet. In a larger multiuser system, however, other mechanisms are needed.
     11.6.1  Types of Access
     The need to protect files is a direct result of the ability to access files. Systems
     that do not permit access to the files of other users do not need protection. Thus,
     we could provide complete protection by prohibiting access. Alternatively, we
     could provide free access with no protection. Both approaches are too extreme
     for general use. What is needed is controlled access.
        Protection mechanisms provide controlled access by limiting the types of
     file access that can be made. Access is permitted or denied depending on
     several factors, one of which is the type of access requested. Several different
     types of operations may be controlled:
     ·  Read. Read from the file.
     ·  Write. Write or rewrite the file.
     ·  Execute. Load the file into memory and execute it.
     ·  Append. Write new information at the end of the file.
     ·  Delete. Delete the file and free its space for possible reuse.
     ·  List. List the name and attributes of the file.
        Other operations, such as renaming, copying, and editing the file, may also
     be controlled. For many systems, however, these higher-level functions may
     be implemented by a system program that makes lower-level system calls.
     Protection is provided at only the lower level. For instance, copying a file may
     be implemented simply by a sequence of read requests. In this case, a user with
     read access can also cause the file to be copied, printed, and so on.
        Many protection mechanisms have been proposed. Each has advantages
     and disadvantages and must be appropriate for its intended application. A
     small computer system that is used by only a few members of a research group,
     for example, may not need the same types of protection as a large corporate
     computer that is used for research, finance, and personnel operations. We
     discuss some approaches to protection in the following sections and present a
     more complete treatment in Chapter 14.
     11.6.2  Access Control
     The most common approach to the protection problem is to make access
     dependent on the identity of the user. Different users may need different types
     of access to a file or directory. The most general scheme to implement identity-
     dependent access is to associate with each file and directory an access-control
     list (ACL) specifying user names and the types of access allowed for each user.
     When a user requests access to a particular file, the operating system checks
     the access list associated with that file. If that user is listed for the requested
     access, the access is allowed. Otherwise, a protection violation occurs, and the
     user job is denied access to the file.



                                                              11.6  Protection       535
       This approach has the advantage of enabling complex access methodolo-
gies. The main problem with access lists is their length. If we want to allow
everyone to read a file, we must list all users with read access. This technique
has two undesirable consequences:
·      Constructing such a list may be a tedious and unrewarding task, especially
       if we do not know in advance the list of users in the system.
·      The directory entry, previously of fixed size, now must be of variable size,
       resulting in more complicated space management.
These problems can be resolved by use of a condensed version of the access
list.
       To condense the length of the access-control list, many systems recognize
three classifications of users in connection with each file:
·      Owner. The user who created the file is the owner.
·      Group. A set of users who are sharing the file and need similar access is a
       group, or work group.
·      Universe. All other users in the system constitute the universe.
       The most common recent approach is to combine access-control lists with
the more general (and easier to implement) owner, group, and universe access-
control scheme just described. For example, Solaris uses the three categories
of access by default but allows access-control lists to be added to specific files
and directories when more fine-grained access control is desired.
       To illustrate, consider a person, Sara, who is writing a new book. She has
hired three graduate students (Jim, Dawn, and Jill) to help with the project. The
text of the book is kept in a file named book.tex. The protection associated
with this file is as follows:
·      Sara should be able to invoke all operations on the file.
·      Jim, Dawn, and Jill should be able only to read and write the file; they
       should not be allowed to delete the file.
·      All other users should be able to read, but not write, the file. (Sara is
       interested in letting as many people as possible read the text so that she
       can obtain feedback.)
       To achieve such protection, we must create a new group--say, text--
with members Jim, Dawn, and Jill. The name of the group, text, must then
be associated with the file book.tex, and the access rights must be set in
accordance with the policy we have outlined.
       Now consider a visitor to whom Sara would like to grant temporary access
to Chapter 1. The visitor cannot be added to the text group because that would
give him access to all chapters. Because a file can be in only one group, Sara
cannot add another group to Chapter 1. With the addition of access-control-list
functionality, though, the visitor can be added to the access control list of
Chapter 1.



536  Chapter 11   File-System Interface
                             PERMISSIONS IN A UNIX SYSTEM
     In the UNIX system, directory protection and file protection are handled
     similarly. Associated with each subdirectory are three fields -- owner, group,
     and universe -- each consisting of the three bits rwx. Thus, a user can list
     the content of a subdirectory only if the r bit is set in the appropriate field.
     Similarly, a user can change his current directory to another current directory
     (say, foo) only if the x bit associated with the foo subdirectory is set in the
     appropriate field.
     A sample directory listing from a UNIX environment is shown in below:
                 -rw-rw-r--  1 pbg     staff       31200  Sep 3 08:30   intro.ps
                 drwx------  5 pbg     staff       512    Jul 8 09.33   private/
                 drwxrwxr-x  2 pbg     staff       512    Jul 8 09:35   doc/
                 drwxrwx---  2 jwg     student     512    Aug 3 14:13   student-proj/
                 -rw-r--r--  1 pbg     staff       9423   Feb 24 2012   program.c
                 -rwxr-xr-x  1 pbg     staff       20471  Feb 24 2012   program
                 drwx--x--x  4 tag     faculty     512    Jul 31 10:31  lib/
                 drwx------  3 pbg     staff       1024   Aug 29 06:52  mail/
                 drwxrwxrwx  3 pbg     staff       512    Jul 8 09:35   test/
     The first field describes the protection of the file or directory. A d as the first
     character indicates a subdirectory. Also shown are the number of links to the
     file, the owner's name, the group's name, the size of the file in bytes, the date
     of last modification, and finally the file's name (with optional extension).
     For this scheme to work properly, permissions and access lists must be
     controlled   tightly.   This  control    can  be  accomplished     in    several  ways.  For
     example, in the UNIX system, groups can be created and modified only by
     the manager of the facility (or by any superuser). Thus, control is achieved
     through human interaction. Access lists are discussed further in Section 14.5.2.
     With the more limited protection classification, only three fields are needed
     to define protection. Often, each field is a collection of bits, and each bit either
     allows or prevents the access associated with it. For example, the UNIX system
     defines three fields of 3 bits each--rwx, where r controls read access, w controls
     write access, and x controls execution. A separate field is kept for the file owner,
     for the file's group, and for all other users. In this scheme, 9 bits per file are
     needed to record protection information. Thus, for our example, the protection
     fields for the file book.tex are as follows: for the owner Sara, all bits are set;
     for the group text, the r and w bits are set; and for the universe, only the r bit
     is set.
     One difficulty in combining approaches comes in the user interface. Users
     must be able to tell when the optional ACL permissions are set on a file. In the
     Solaris example, a "+" is appended to the regular permissions, as in:
              19  -rw-r--r--+       1  jim      staff     130  May  25  22:13     file1
     A separate set of commands, setfacl and getfacl, is used to manage the
     ACLs.



                                                          11.6  Protection         537
             Figure 11.16      Windows 7 access-control list management.
Windows users typically manage access-control lists via the GUI. Figure
11.16 shows a file-permission window on Windows 7 NTFS file system. In this
example, user "guest" is specifically denied access to the file ListPanel.java.
Another difficulty is assigning precedence when permission and ACLs
conflict. For example, if Joe is in a file's group, which has read permission,
but the file has an ACL granting Joe read and write permission, should a write
by Joe be granted or denied? Solaris gives ACLs precedence (as they are more
fine-grained and are not assigned by default). This follows the general rule that
specificity should have priority.
11.6.3  Other Protection Approaches
Another approach to the protection problem is to associate a password with
each  file.  Just  as  access  to  the  computer  system  is  often  controlled  by  a



538   Chapter 11    File-System Interface
      password, access to each file can be controlled in the same way. If the passwords
      are chosen randomly and changed often, this scheme may be effective in
      limiting  access  to  a  file.  The  use  of  passwords  has  a  few  disadvantages,
      however. First, the number of passwords that a user needs to remember may
      become large, making the scheme impractical. Second, if only one password is
      used for all the files, then once it is discovered, all files are accessible; protection
      is on an all-or-none basis. Some systems allow a user to associate a password
      with a subdirectory, rather than with an individual file, to address this problem.
          In a multilevel directory structure, we need to protect not only individual
      files but also collections of files in subdirectories; that is, we need to provide
      a mechanism for directory protection. The directory operations that must be
      protected are somewhat different from the file operations. We want to control
      the creation and deletion of files in a directory. In addition, we probably want
      to control whether a user can determine the existence of a file in a directory.
      Sometimes, knowledge of the existence and name of a file is significant in itself.
      Thus, listing the contents of a directory must be a protected operation. Similarly,
      if a path name refers to a file in a directory, the user must be allowed access to
      both the directory and the file. In systems where files may have numerous path
      names (such as acyclic and general graphs), a given user may have different
      access rights to a particular file, depending on the path name used.
11.7  Summary
      A file is an abstract data type defined and implemented by the operating
      system. It is a sequence of logical records. A logical record may be a byte, a line
      (of fixed or variable length), or a more complex data item. The operating system
      may specifically support various record types or may leave that support to the
      application program.
          The major task for the operating system is to map the logical file concept
      onto physical storage devices such as magnetic disk or tape. Since the physical
      record size of the device may not be the same as the logical record size, it may
      be necessary to order logical records into physical records. Again, this task may
      be supported by the operating system or left for the application program.
          Each device in a file system keeps a volume table of contents or a device
      directory listing the location of the files on the device. In addition, it is useful
      to create directories to allow files to be organized. A single-level directory
      in a multiuser system causes naming problems, since each file must have a
      unique name. A two-level directory solves this problem by creating a separate
      directory for each user's files. The directory lists the files by name and includes
      the file's location on the disk, length, type, owner, time of creation, time of last
      use, and so on.
          The natural generalization of a two-level directory is a tree-structured
      directory. A tree-structured directory allows a user to create subdirectories
      to  organize  files.  Acyclic-graph  directory  structures    enable  users  to  share
      subdirectories and files but complicate searching and deletion. A general graph
      structure allows complete flexibility in the sharing of files and directories but
      sometimes requires garbage collection to recover unused disk space.
          Disks are segmented into one or more volumes, each containing a file
      system or left "raw." File systems may be mounted into the system's naming



                                                       Practice Exercises         539
structures to make them available. The naming scheme varies by operating
system. Once mounted, the files within the volume are available for use. File
systems may be unmounted to disable access or for maintenance.
File sharing depends on the semantics provided by the system. Files may
have multiple readers, multiple writers, or limits on sharing. Distributed file
systems allow client hosts to mount volumes or directories from servers, as long
as they can access each other across a network. Remote file systems present
challenges in reliability, performance, and security. Distributed information
systems maintain user, host, and access information so that clients and servers
can share state information to manage use and access.
Since files are the main information-storage mechanism in most computer
systems, file protection is needed. Access to files can be controlled separately
for each type of access--read, write, execute, append, delete, list directory,
and so on. File protection can be provided by access lists, passwords, or other
techniques.
Practice Exercises
11.1  Some systems automatically delete all user files when a user logs off or
      a job terminates, unless the user explicitly requests that they be kept.
      Other systems keep all files unless the user explicitly deletes them.
      Discuss the relative merits of each approach.
11.2  Why do some systems keep track of the type of a file, while others leave
      it to the user and others simply do not implement multiple file types?
      Which system is "better"?
11.3  Similarly, some systems support many types of structures for a file's
      data, while others simply support a stream of bytes. What are the
      advantages and disadvantages of each approach?
11.4  Could you simulate a multilevel directory structure with a single-level
      directory structure in which arbitrarily long names can be used? If your
      answer is yes, explain how you can do so, and contrast this scheme with
      the multilevel directory scheme. If your answer is no, explain what
      prevents your simulation's success. How would your answer change
      if file names were limited to seven characters?
11.5  Explain the purpose of the open() and close() operations.
11.6  In     some  systems,  a  subdirectory  can  be  read  and  written  by     an
      authorized user, just as ordinary files can be.
      a.     Describe the protection problems that could arise.
      b.     Suggest  a  scheme  for  dealing  with    each  of  these  protection
             problems.
11.7  Consider a system that supports 5,000 users. Suppose that you want to
      allow 4,990 of these users to be able to access one file.
      a.     How would you specify this protection scheme in UNIX?



540  Chapter 11  File-System Interface
            b.   Can you suggest another protection scheme that can be used more
                 effectively for this purpose than the scheme provided by UNIX?
     11.8   Researchers  have  suggested  that,       instead  of  having  an  access        list
            associated with each file (specifying which users can access the file,
            and how), we should have a user control list associated with each user
            (specifying which files a user can access, and how). Discuss the relative
            merits of these two schemes.
Exercises
     11.9   Consider a file system in which a file can be deleted and its disk space
            reclaimed while links to that file still exist. What problems may occur if
            a new file is created in the same storage area or with the same absolute
            path name? How can these problems be avoided?
     11.10  The open-file table is used to maintain information about files that are
            currently open. Should the operating system maintain a separate table
            for each user or maintain just one table that contains references to files
            that are currently being accessed by all users? If the same file is being
            accessed by two different programs or users, should there be separate
            entries in the open-file table? Explain.
     11.11  What are the advantages and disadvantages of providing mandatory
            locks instead of advisory locks whose use is left to users' discretion?
     11.12  Provide examples of applications that typically access files according
            to the following methods:
            ·    Sequential
            ·    Random
     11.13  Some systems automatically open a file when it is referenced for the first
            time and close the file when the job terminates. Discuss the advantages
            and disadvantages of this scheme compared with the more traditional
            one, where the user has to open and close the file explicitly.
     11.14  If the operating system knew that a certain application was going
            to access file data in a sequential manner, how could it exploit this
            information to improve performance?
     11.15  Give an example of an application that could benefit from operating-
            system support for random access to indexed files.
     11.16  Discuss the advantages and disadvantages of supporting links to files
            that cross mount points (that is, the file link refers to a file that is stored
            in a different volume).
     11.17  Some systems provide file sharing by maintaining a single copy of a
            file. Other systems maintain several copies, one for each of the users
            sharing the file. Discuss the relative merits of each approach.



                                                                 Bibliography          541
11.18  Discuss the advantages and disadvantages of associating with remote
       file systems (stored on file servers) a set of failure semantics different
       from that associated with local file systems.
11.19  What are the implications of supporting UNIX consistency semantics
       for shared access to files stored on remote file systems?
Bibliographical Notes
Database systems and their file structures are described in full in [Silberschatz
et al. (2010)].
A multilevel directory structure was first implemented on the MULTICS
system ([Organick (1972)]). Most operating systems now implement multilevel
directory structures. These include Linux ([Love (2010)]), Mac OS X ([Singh
(2007)]), Solaris ([McDougall and Mauro (2007)]), and all versions of Windows
([Russinovich and Solomon (2005)]).
The network file system (NFS), designed by Sun Microsystems, allows
directory structures to be spread across networked computer systems. NFS
Version 4 is described in RFC3505 (http://www.ietf.org/rfc/rfc3530.txt). A gen-
eral discussion of Solaris file systems is found in the Sun System Administration
Guide: Devices and File Systems (http://docs.sun.com/app/docs/doc/817-5093).
DNS was first proposed by [Su (1982)] and has gone through several
revisions since. LDAP, also known as X.509, is a derivative subset of the X.500
distributed directory protocol. It was defined by [Yeong et al. (1995)] and has
been implemented on many operating systems.
Bibliography
[Love (2010)]    R. Love, Linux Kernel Development, Third Edition, Developer's
Library (2010).
[McDougall and Mauro (2007)]       R. McDougall and J. Mauro, Solaris Internals,
Second Edition, Prentice Hall (2007).
[Organick (1972)]      E.  I.  Organick,  The  Multics  System:  An   Examination  of  Its
Structure, MIT Press (1972).
[Russinovich and Solomon (2005)]          M.   E.  Russinovich   and  D.  A.  Solomon,
Microsoft Windows Internals, Fourth Edition, Microsoft Press (2005).
[Silberschatz et al. (2010)]   A.  Silberschatz,   H.   F.  Korth,  and   S.  Sudarshan,
Database System Concepts, Sixth Edition, McGraw-Hill (2010).
[Singh (2007)]     A. Singh, Mac OS X Internals: A Systems Approach, Addison-
Wesley (2007).
[Su (1982)]      Z. Su, "A Distributed System for Internet Name Service", Network
Working Group, Request for Comments: 830 (1982).
[Yeong et al. (1995)]      W. Yeong, T. Howes, and S. Kille, "Lightweight Directory
Access Protocol", Network Working Group, Request for Comments: 1777 (1995).



