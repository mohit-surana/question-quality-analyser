["List and briefly define the four main elements of a computer.", "Define the two main categories of processor registers.", "In general terms, what are the four distinct actions that a machine instruction can specify?", "What is an interrupt?", "How are multiple interrupts dealt with?", "What characteristics distinguish the various elements of a memory hierarchy?", "What is cache memory?", "What is the difference between a multiprocessor and a multicore system?", "What is the distinction between spatial locality and temporal locality?", "In general, what are the strategies for exploiting spatial locality and temporal locality?", "What are three objectives of an OS design?", "What is the kernel of an OS?", "What is multiprogramming?", "What is a process?", "How is the execution context of a process used by the OS?", "List and briefly explain five storage management responsibilities of a typical OS.", "Explain the distinction between a real address and a virtual address.", "Describe the round-robin scheduling technique.", "Explain the difference between a monolithic kernel and a microkernel.", "What is multithreading?", "List the key design issues for an SMP operating system.", "What is an instruction trace?", "What common events lead to the creation of a process?", "For the processing model of Figure 3.6, briefly define each state.", "What does it mean to preempt a process?", "What is swapping and what is its purpose?", "Why does Figure 3.9b have two blocked states?", "List four characteristics of a suspended process.", "For what types of entities does the OS maintain tables of information for management purposes?", "List three general categories of information in a process control block.", "Why are two modes (user and kernel) needed?", "What are the steps performed by an OS to create a new process?", "What is the difference between an interrupt and a trap?", "Give three examples of an interrupt.", "What is the difference between a mode switch and a process switch?", "Table 3.5 lists typical elements found in a process control block for an unthreaded OS. Of these, which should belong to a thread control block and which should belong to a process control block for a multithreaded system?", "List reasons why a mode switch between threads may be cheaper than a mode switch between processes.", "What are the two separate and potentially independent characteristics embodied in the concept of process?", "Give four general examples of the use of threads in a single-user multiprocessing system.", "What resources are typically shared by all of the threads of a process?", "List three advantages of ULTs over KLTs.", "List two disadvantages of ULTs compared to KLTs.", "Define jacketing.", "List four design issues for which the concept of concurrency is relevant.", "What are three contexts in which concurrency arises?", "What is the basic requirement for the execution of concurrent processes?", "List three degrees of awareness between processes and briefly define each.", "What is the distinction between competing processes and cooperating processes?", "List the three control problems associated with competing processes and briefly de- fine each.", "List the requirements for mutual exclusion.", "What operations can be performed on a semaphore?", "Give examples of reusable and consumable resources.", "What are the three conditions that must be present for deadlock to be possible?", "What are the four conditions that create deadlock?", "How can the hold-and-wait condition be prevented?", "List two ways in which the no-preemption condition can be prevented.", "How can the circular wait condition be prevented?", "What is the difference among deadlock avoidance, detection, and prevention?", "What requirements is memory management intended to satisfy?", "Why is the capability to relocate processes desirable?", "Why is it not possible to enforce memory protection at compile time?", "What are some reasons to allow two or more processes to all have access to a particular region of memory?", "In a fixed-partitioning scheme, what are the advantages of using unequal-size partitions?", "What is the difference between internal and external fragmentation?", "What are the distinctions among logical, relative, and physical addresses?", "What is the difference between a page and a frame?", "What is the difference between a page and a segment?", "What is the difference between simple paging and virtual memory paging?", "Explain thrashing.", "Why is the principle of locality crucial to the use of virtual memory?", "What elements are typically found in a page table entry? Briefly define each element.", "What is the purpose of a translation lookaside buffer?", "Briefly define the alternative page fetch policies.", "What is the difference between resident set management and page replacement policy?", "What is the relationship between FIFO and clock page replacement algorithms?", "What is accomplished by page buffering?", "Why is it not possible to combine a global replacement policy and a fixed allocation policy?", "What is the difference between a resident set and a working set?", "What is the difference between demand cleaning and precleaning?", "Briefly describe the three types of processor scheduling.", "What is usually the critical performance requirement in an interactive operating system?", "What is the difference between turnaround time and response time?", "For process scheduling, does a low-priority value represent a low priority or a high priority?", "What is the difference between preemptive and nonpreemptive scheduling?", "Briefly define FCFS scheduling.", "Briefly define round-robin scheduling.", "Briefly define shortest-process-next scheduling.", "Briefly define shortest-remaining-time scheduling.", "Briefly define highest-response-ratio-next scheduling.", "Briefly define feedback scheduling.", "List and briefly define five different categories of synchronization granularity.", "List and briefly define four techniques for thread scheduling.", "List and briefly define three versions of load sharing.", "What is the difference between hard and soft real-time tasks?", "What is the difference between periodic and aperiodic real-time tasks?", "List and briefly define five general areas of requirements for a real-time operating system.", "List and briefly define four classes of real-time scheduling algorithms.", "What items of information about a task might be useful in real-time scheduling?", "List and briefly define three techniques for performing I/O.", "What is the difference between logical I/O and device I/O?", "What is the difference between block-oriented devices and stream-oriented devices? Give a few examples of each.", "Why would you expect improved performance using a double buffer rather than a single buffer for I/O?", "What delay elements are involved in a disk read or write?", "Briefly define the disk scheduling policies illustrated in Figure 11.7.", "Briefly define the seven RAID levels.", "What is the typical disk sector size?", "What is the difference between a field and a record?", "What is the difference between a file and a database?", "What is a file management system?", "What criteria are important in choosing a file organization?", "List and briefly define five file organizations.", "Why is the average search time to find a record in a file less for an indexed sequential file than for a sequential file?", "What are typical operations that may be performed on a directory?", "What is the relationship between a pathname and a working directory?", "What are typical access rights that may be granted or denied to a particular user for a particular file?", "List and briefly define three blocking methods.", "List and briefly define three file allocation methods.", "What is an embedded system?", "What are some typical requirements or constraints on embedded systems?", "What is an embedded OS?", "What are some of the key characteristics of an embedded OS?", "Explain the relative advantages and disadvantages of an embedded OS based on an existing commercial OS compared to a purpose-built embedded OS.", "What are the principal objectives that guided the design of the eCos kernel?", "In eCos, what is the difference between an interrupt service routine and a deferred service routine?", "What concurrency mechanisms are available in eCos?", "What is the target application for TinyOS?", "What are the design goals for TinyOS?", "What is a TinyOS component?", "What software comprises the TinyOS operating system?", "What is the default scheduling discipline for TinyOS?", "Define computer security.", "What are the fundamental requirements addressed by computer security?", "What is the difference between passive and active security threats?", "List and briefly define three classes of intruders.", "List and briefly define three intruder behavior patterns.", "What is the role of compression in the operation of a virus?", "What is the role of encryption in the operation of a virus?", "What are typical phases of operation of a virus or worm?", "In general terms, how does a worm propagate?", "What is the difference between a bot and a rootkit?", "In general terms, what are four means of authenticating a user\u2019s identity?", "Explain the purpose of the salt in Figure 15.1.", "Explain the difference between a simple memory card and a smart card.", "List and briefly describe the principal physical characteristics used for biometric identification.", "Briefly describe the difference between DAC and RBAC.", "Explain the difference between anomaly intrusion detection and signature intrusion detection.", "What is a digital immune system?", "How does behavior-blocking software work?", "Describe some worm countermeasures.", "What types of programming languages are vulnerable to buffer overflows?", "What are the two broad categories of defenses against buffer overflows?", "List and briefly describe some of the defenses against buffer overflows that can be used when compiling new programs.", "List and briefly describe some of the defenses against buffer overflows that can be implemented when running existing, vulnerable programs.", "What is client/server computing?", "What distinguishes client/server computing from any other form of distributed data processing?", "What is the role of a communications architecture such as TCP/IP in a client/server environment?", "Discuss the rationale for locating applications on the client, the server, or split between client and server.", "What are fat clients and thin clients, and what are the differences in philosophy of the two approaches?", "Suggest pros and cons for fat client and thin client strategies.", "Explain the rationale behind the three-tier client/server architecture.", "What is middleware?", "Because we have standards such as TCP/IP, why is middleware needed?", "List some benefits and disadvantages of blocking and nonblocking primitives for message passing.", "List some benefits and disadvantages of nonpersistent and persistent binding for RPCs.", "List some benefits and disadvantages of synchronous and asynchronous RPCs.", "List and briefly define four different clustering methods.", "", "Suppose the hypothetical processor of Figure 1.3 also has two I/O instructions: 0011 Load AC from I/O and 0111 Store AC to I/O. In these cases, the 12-bit address identifies a particular external device. Show the program execution for the following program", "The program execution is described in the text using six steps. Expand this description to show the use of the MAR and MBR.", "Consider a hypothetical 32-bit microprocessor having 32-bit instructions composed of two fields. The first byte contains the opcode and the remainder an immediate operand or an operand address. What is the maximum directly addressable memory capacity (in bytes)?", "Discuss the impact on the system speed if the microprocessor bus has - 1. a 32-bit local address bus and a 16-bit local data bus, or 2. a 16-bit local address bus and a 16-bit local data bus.", "Consider a hypothetical 32-bit microprocessor having 32-bit instructions composed of two fields. How many bits are needed for the program counter and the instruction register?", "Consider a hypothetical microprocessor generating a 16-bit address and having a 16-bit data bus. What is the maximum memory address space that the processor can access directly if it is connected to a \u201c16-bit memory\u201d?", "Consider a hypothetical microprocessor generating a 16-bit address and having a 16-bit data bus. What is the maximum memory address space that the processor can access directly if it is connected to an \u201c8-bit memory\u201d?", "Consider a hypothetical microprocessor generating a 16-bit address and having a 16-bit data bus. What architectural features will allow this microprocessor to access a separate \u201cI/O space\u201d?", "Consider a hypothetical microprocessor generating a 16-bit address and having a 16-bit data bus. If an input and an output instruction can specify an 8-bit I/O port number, how many 8-bit I/O ports can the microprocessor support? How many 16-bit I/O ports? Explain.", "Consider a 32-bit microprocessor, with a 16-bit external data bus, driven by an 8-MHz input clock. What is the maximum data transfer rate across the bus that this microprocessor can sustain in bytes/s?", "Consider a 32-bit microprocessor, with a 16-bit external data bus, driven by an 8-MHz input clock. To increase its performance, would it be better to make its external data bus 32 bits or to double the external clock frequency supplied to the microprocessor?", "Consider a computer system that contains an I/O module controlling a simple keyboard/printer Teletype. The following registers are contained in the CPU and connected directly to the system bus: Input Register(8), Output Register(8), Input Flag(1), Output Flag(1), and Interrupt Enable(1). The Teletype is able to encode an alphanumeric symbol to an 8-bit word and decode an 8-bit word into an alphanumeric symbol. The Input flag is set when an 8-bit word enters the input register from the Teletype. The Output flag is set when a word is printed. Describe how the CPU, using the first four registers listed in this problem, can achieve I/O with the Teletype. Describe how the function can be performed more efficiently by also employing IEN.", "In virtually all systems that include DMA modules, DMA access to main memory is given higher priority than processor access to main memory. Why?", "A DMA module is transferring characters to main memory from an external device transmitting at 9600 bits per second (bps). The processor can fetch instructions at the rate of 1 million instructions per second. By how much will the processor be slowed down due to the DMA activity?", "A computer consists of a CPU and an I/O device D connected to main memory M via a shared bus with a data bus width of one word. The CPU can execute a maximum of 106 instructions per second. An average instruction requires five processor cycles, three of which use the memory bus. A memory read or write operation uses one processor cycle. Suppose that the CPU is continuously executing \u201cbackground\u201d programs that require 95% of its instruction execution rate but not any I/O instructions. Assume that one processor cycle equals one bus cycle. Now suppose that very large blocks of data are to be transferred between M and D. a. If programmed I/O is used and each one-word I/O transfer requires the CPU to execute two instructions, estimate the maximum I/O data transfer rate, in words per second, possible through D. b. Estimate the same rate if DMA transfer is used.", "Consider the following code <CODE> a. Give one example of the spatial locality in the code. b. Give one example of the temporal locality in the code.", "Consider a memory system with the following parameters: Tc   100 ns Cc   0.01 cents/bit Tm   1,200 ns Cm   0.001 cents/bit a. What is the cost of 1 MByte of main memory? b. What is the cost of 1 MByte of main memory using cache memory technology?", "Consider a memory system with the following parameters: Tc   100 ns Cc   0.01 cents/bit Tm   1,200 ns Cm   0.001 cents/bit. If the effective access time is 10% greater than the cache access time, what is the hit ratio H?", "A computer has a cache, main memory, and a disk used for virtual memory. If a referenced word is in the cache, 20 ns are required to access it. If it is in main memory but not in the cache, 60 ns are needed to load it into the cache (this includes the time to originally check the cache), and then the reference is started again. If the word is not in main memory, 12 ms are required to fetch the word from disk, followed by 60 ns to copy it to the cache, and then the reference is started again. The cache hit ratio is 0.9 and the main-memory hit ratio is 0.6. What is the average time in ns required to access a referenced word on this system?", "Suppose a stack is to be used by the processor to manage procedure calls and returns. Can the program counter be eliminated by using the top of the stack as a program counter?", "Suppose that we have a multiprogrammed computer in which each job has identical characteristics. In one computation period, T, for a job, half the time is spent in I/O and the other half in processor activity. Each job runs for a total of N periods. Assume that a simple round-robin scheduling is used, and that I/O operations can overlap with processor operation. Define the following quantities: \u2022 Turnaround time = actual time to complete a job \u2022 Throughput = average number of jobs completed per time period T \u2022 Processor utilization = percentage of time that the processor is active (not waiting) Compute these quantities for one, two, and four simultaneous jobs, assuming that the period T is distributed in each of the following ways: a. I/O first half, processor second half b. I/O first and fourth quarters, processor second and third quarter", "An I/O-bound program is one that, if run alone, would spend more time waiting for I/O than using the processor. A processor-bound program is the opposite. Suppose a short-term scheduling algorithm favors those programs that have used little processor time in the recent past. Explain why this algorithm favors I/O-bound programs and yet does not permanently deny processor time to processor-bound programs.", "Contrast the scheduling policies you might use when trying to optimize a time-sharing system with those you would use to optimize a multiprogrammed batch system.", "What is the purpose of system calls, and how do system calls relate to the OS and to the concept of dual-mode (kernel-mode and user-mode) operation?", "In IBM\u2019s mainframe OS, OS/390, one of the major modules in the kernel is the System Resource Manager. This module is responsible for the allocation of resources among address spaces (processes). This problem concerns one example of SRM activity. Real memory is divided into equal-sized blocks called frames, of which there may be many thousands. Each frame can hold a block of virtual memory referred to as a page. SRM receives control approximately 20 times per second and inspects each and every page frame. If the page has not been referenced or changed, a counter is incremented by 1. Over time, SRM averages these numbers to determine the average number of seconds that a page frame in the system goes untouched. What might be the purpose of this and what action might SRM take?", "A multiprocessor with eight processors has 20 attached tape drives. There is a large number of jobs submitted to the system that each require a maximum of four tape drives to complete execution. Assume that each job starts running with only three tape drives for a long period before requiring the fourth tape drive for a short period toward the end of its operation. Also assume an endless supply of such jobs. Assume the scheduler in the OS will not start a job unless there are four tape drives available. When a job is started, four drives are assigned immediately and are not released until the job finishes. What is the maximum number of jobs that can be in progress at once? What are the maximum and minimum number of tape drives that may be left idle as a result of this policy?", "A multiprocessor with eight processors has 20 attached tape drives. There is a large number of jobs submitted to the system that each require a maximum of four tape drives to complete execution. Assume that each job starts running with only three tape drives for a long period before requiring the fourth tape drive for a short period toward the end of its operation. Also assume an endless supply of such jobs. Suggest an alternative policy to improve tape drive utilization and at the same time avoid system deadlock. What is the maximum number of jobs that can be in progress at once? What are the bounds on the number of idling tape drives?", "The following state transition table is a simplified model of process management, with the labels representing transitions between states of READY, RUN, BLOCKED, and NONRESIDENT. Give an example of an event that can cause each of the above transitions. Draw a diagram if that helps.", "Assume that at time 5 no system resources are being used except for the processor and memory. Now consider the following events: At time 5: P1 executes a command to read from disk unit 3. At time 15: P5\u2019s time slice expires. At time 18: P7 executes a command to write to disk unit 3. At time 20: P3 executes a command to read from disk unit 2. At time 24: P5 executes a command to write to disk unit 3. At time 28: P5 is swapped out. At time 33: An interrupt occurs from disk unit 2: P3\u2019s read is complete. At time 36: An interrupt occurs from disk unit 3: P1\u2019s read is complete. At time 38: P8 terminates. At time 40: An interrupt occurs from disk unit 3: P5\u2019s write is complete. At time 44: P5 is swapped back in. At time 48: An interrupt occurs from disk unit 3: P7\u2019s write is complete. For each time 22, 37, and 47, identify which state each process is in. If a process is blocked, further identify the event on which is it blocked.", "Figure 3.9b contains seven states. In principle, one could draw a transition between any two states, for a total of 42 different transitions. List all of the possible transitions and give an example of what could cause each transition.", "Figure 3.9b contains seven states. In principle, one could draw a transition between any two states, for a total of 42 different transitions. List all of the impossible transitions and explain why.", "Figure 3.9b contains seven states. In principle, one could draw a transition between any two states, for a total of 42 different transitions. For the seven-state process model of Figure 3.9b, draw a queueing diagram similar to that of Figure 3.8b.", "Consider the state transition diagram of Figure 3.9b. Suppose that it is time for the OS to dispatch a process and that there are processes in both the Ready state and the Ready/Suspend state, and that at least one process in the Ready/Suspend state has higher scheduling priority than any of the processes in the Ready state. Two extreme policies are as follows: (1) Always dispatch from a process in the Ready state, to minimize swapping, and (2) always give preference to the highest-priority process, even though that may mean swapping when swapping is not necessary. Suggest an intermediate policy that tries to balance the concerns of priority and performance.", "Table 3.13 shows the process states for the VAX/VMS operating system. Can you provide a justification for the existence of so many distinct wait states?", "Table 3.13 shows the process states for the VAX/VMS operating system. Why do the following states not have resident and swapped-out versions: Page Fault Wait, Collided Page Wait, Common Event Wait, Free Page Wait, and Resource Wait?", "Table 3.13 shows the process states for the VAX/VMS operating system. Draw the state transition diagram and indicate the action or occurrence that causes each transition.", "The VAX/VMS operating system makes use of four processor access modes to facilitate the protection and sharing of system resources among processes. The access mode determines \u2022 Instruction execution privileges: What instructions the processor may execute \u2022 Memory access privileges: Which locations in virtual memory the current instruction may access. The four modes are as follows: \u2022 Kernel: Executes the kernel of the VMS operating system, which includes memory management, interrupt handling, and I/O operations \u2022 Executive: Executes many of the OS service calls, including file and record (disk and tape) management routines \u2022 Supervisor: Executes other OS services, such as responses to user commands \u2022 User: Executes user programs, plus utilities such as compilers, editors, linkers, and debuggers. A process executing in a less-privileged mode often needs to call a procedure that executes in a more-privileged mode; for example, a user program requires an operating system service. This call is achieved by using a change-mode (CHM) instruction, which causes an interrupt that transfers control to a routine at the new access mode. A return is made by executing the REI (return from exception or interrupt) instruction. A number of operating systems have two modes, kernel and user. What are the advantages and disadvantages of providing four modes instead of two?", "The VAX/VMS operating system makes use of four processor access modes to facilitate the protection and sharing of system resources among processes. The access mode determines \u2022 Instruction execution privileges: What instructions the processor may execute \u2022 Memory access privileges: Which locations in virtual memory the current instruction may access. The four modes are as follows: \u2022 Kernel: Executes the kernel of the VMS operating system, which includes memory management, interrupt handling, and I/O operations \u2022 Executive: Executes many of the OS service calls, including file and record (disk and tape) management routines \u2022 Supervisor: Executes other OS services, such as responses to user commands \u2022 User: Executes user programs, plus utilities such as compilers, editors, linkers, and debuggers. A process executing in a less-privileged mode often needs to call a procedure that executes in a more-privileged mode; for example, a user program requires an operating system service. This call is achieved by using a change-mode (CHM) instruction, which causes an interrupt that transfers control to a routine at the new access mode. A return is made by executing the REI (return from exception or interrupt) instruction. Can you make a case for even more than four modes?", "The VMS scheme discussed in the preceding problem is often referred to as a ring protection structure, as illustrated in Figure 3.18. Indeed, the simple kernel/user scheme, as described in Section 3.3, is a two-ring structure. [SILB04] points out a problem with this approach: The main disadvantage of the ring (hierarchical) structure is that it does not allow us to enforce the need-to-know principle. In particular, if an object must be accessible in domain Dj but not accessible in domain Di, then we must have j 6 i. But this means that every segment accessible in Di is also accessible in Dj. Explain clearly what the problem is that is referred to in the preceding quote.", "Figure 3.8b suggests that a process can only be in one event queue at a time. Is it possible that you would want to allow a process to wait on more than one event at the same time? Provide an example.", "Figure 3.8b suggests that a process can only be in one event queue at a time. In that case, how would you modify the queueing structure of the figure to support this new feature?", "In a number of early computers, an interrupt caused the register values to be stored in fixed locations associated with the given interrupt signal. Under what circumstances is this a practical technique? Explain why it is inconvenient in general.", "In Section 3.4, it was stated that UNIX is unsuitable for real-time applications because a process executing in kernel mode may not be preempted. Elaborate.", "You have executed the following C program: <CODE> What are the possible outputs, assuming the fork succeeded?", "It was pointed out that two advantages of using multiple threads within a process are that (1) less work is involved in creating a new thread within an existing process than in creating a new process, and (2) communication among threads within the same process is simplified. Is it also the case that a mode switch between two threads within the same process involves less work than a mode switch between two threads in different processes?", "In the discussion of ULTs versus KLTs, it was pointed out that a disadvantage of ULTs is that when a ULT executes a system call, not only is that thread blocked, but also all of the threads within the process are blocked. Why is that so?", "OS/2 is an obsolete OS for PCs from IBM. In OS/2, what is commonly embodied in the concept of process in other operating systems is split into three separate types of entities: session, processes, and threads. A session is a collection of one or more processes associated with a user interface (keyboard, display, and mouse). The session represents an interactive user application, such as a word processing program or a spreadsheet. This concept allows the personal-computer user to open more than one application, giving each one or more windows on the screen. The OS must keep track of which window, and therefore which session, is active, so that keyboard and mouse input are routed to the appropriate session. At any time, one session is in foreground mode, with other sessions in background mode. When a session is in foreground mode, a process performing video output sends it directly to the hardware video buffer and thence to the user\u2019s screen. When the session is moved to the background, the hardware video buffer is saved to a logical video buffer for that session. While a session is in background, if any of the threads of any of the processes of that session executes and produces screen output, that output is directed to the logical video buffer. When the session returns to foreground, the screen is updated to reflect the current contents of the logical video buffer for the new foreground session. There is a way to reduce the number of process-related concepts in OS/2 from three to two. Eliminate sessions, and associate the user interface (keyboard, mouse, and screen) with processes. Thus, one process at a time is in foreground mode. For further structuring, processes can be broken up into threads. a. What benefits are lost with this approach? b. If you go ahead with this modification, where do you assign resources (memory, files, etc.): at the process or thread level?", "Consider an environment in which there is a one-to-one mapping between user-level", "threads and kernel-level threads that allows one or more threads within a process to issue blocking system calls while other threads continue to run. Explain why this model can make multithreaded programs run faster than their single-threaded counterparts on a uniprocessor computer.", "If a process exits and there are still threads of that process running, will they continue to run?", "The OS/390 mainframe operating system is structured around the concepts of address space and task. Roughly speaking, a single address space corresponds to a single application and corresponds more or less to a process in other operating systems. Within an address space, a number of tasks may be generated and execute concurrently; this corresponds roughly to the concept of multithreading. Two data structures are key to managing this task structure. An address space control block (ASCB) contains information about an address space needed by OS/390 whether or not that address space is executing. Information in the ASCB includes dispatching priority, real and virtual memory allocated to this address space, the number of ready tasks in this address space, and whether each is swapped out. A task control block (TCB) represents a user program in execution. It contains information needed for managing a task within an address space, including processor status information, pointers to programs that are part of this task, and task execution state. ASCBs are global structures maintained in system memory, while TCBs are local structures maintained within their address space. What is the advantage of splitting the control information into global and local portions?", "Many current language specifications, such as for C and C++, are inadequate for multithreaded programs. This can have an impact on compilers and the correctness of code, as this problem illustrates. Consider the following declarations and function definition: <CODE> Now consider the case in which thread A performs <CODE> while thread B performs <CODE> What does the function do?", "Many current language specifications, such as for C and C++, are inadequate for multithreaded programs. This can have an impact on compilers and the correctness of code, as this problem illustrates. Consider the following declarations and function definition: <CODE> Now consider the case in which thread A performs <CODE> while thread B performs <CODE> The C language only addresses single-threaded execution. Does the use of two parallel threads create any problems or potential problems?", "But some existing optimizing compilers (including gcc, which tends to be relatively conservative) will \u201coptimize\u201d count_positives to something similar to <CODE> What problem or potential problem occurs with this compiled version of the program if threads A and B are executed concurrently?", "Consider the following code using the POSIX Pthreads API: <CODE>", "In main() we first declare a variable called mythread, which has a type of pthread_t. This is essentially an ID for a thread. Next, the if statement creates a thread associated with mythread. The call pthread_create() returns zero on success and a nonzero value on failure. The third argument of pthread_ create() is the name of a function that the new thread will execute when it starts. When this thread_function() returns, the thread terminates. Meanwhile, the main program itself defines a thread, so that there are two threads executing. The pthread_join function enables the main thread to wait until the new thread completes. What does this program accomplish?", "Consider the following code using the POSIX Pthreads API: <CODE>", "In main() we first declare a variable called mythread, which has a type of pthread_t. This is essentially an ID for a thread. Next, the if statement creates a thread associated with mythread. The call pthread_create() returns zero on success and a nonzero value on failure. The third argument of pthread_ create() is the name of a function that the new thread will execute when it starts. When this thread_function() returns, the thread terminates. Meanwhile, the main program itself defines a thread, so that there are two threads executing. The pthread_join function enables the main thread to wait until the new thread completes. Here is the output from the executed program: Is this the output you would expect? If not, what has gone wrong?", "The Solaris documentation states that a ULT may yield to another thread of the same priority. Isn\u2019t it possible that there will be a runnable thread of higher priority and that therefore the yield function should result in yielding to a thread of the same or higher priority?", "In Solaris 9 and Solaris 10, there is a one-to-one mapping between ULTs and LWPs.  What is the possible benefit of allowing a many-to-one mapping of ULTs to", "LWPs?", "In Solaris 8, a single LWP supports one or more ULTs. In Solaris 8, the thread execution state of a ULT is distinct from that of its LWP. Explain why.", "Figure 4.17 shows the state transition diagrams for a ULT and its associated LWP in Solaris 8 and 9. Explain the operation of the two diagrams and their relationships.", "Explain the rationale for the Uninterruptible state in Linux.", "At the beginning of Section 5.1, it is stated that multiprogramming and multiprocessing present the same problems, with respect to concurrency. This is true as far as it goes. However, cite two differences in terms of concurrency between multiprogramming and multiprocessing.", "Processes and threads provide a powerful structuring tool for implementing programs that would be much more complex as simple sequential programs. An earlier construct that is instructive to examine is the coroutine. The purpose of this problem is to introduce coroutines and compare them to processes. Consider this simple problem from [CONW63]: Read 80-column cards and print them on 125-character lines, with the following changes. After every card image an extra blank is inserted, and every adjacent pair of asterisks (**) on a card is replaced by the character. Develop a solution to this problem as an ordinary sequential program. You will find that the program is tricky to write. The interactions among the various elements of the program are uneven because of the conversion from a length of 80 to 125; furthermore, the length of the card image, after conversion, will vary depending on the number of double asterisk occurrences. One way to improve clarity, and to minimize the potential for bugs, is to write the application as three separate procedures. The first procedure reads in card images, pads each image with a blank, and writes a stream of characters to a temporary file. After all of the cards have been read, the second procedure reads the temporary file, does the character substitution, and writes out a second temporary file. The third procedure reads the stream of characters from the second temporary file and prints lines of 125 characters each.", "Processes and threads provide a powerful structuring tool for implementing programs that would be much more complex as simple sequential programs. An earlier construct that is instructive to examine is the coroutine. The purpose of this problem is to introduce coroutines and compare them to processes. Consider this simple problem from [CONW63]: Read 80-column cards and print them on 125-character lines, with the following changes. After every card image an extra blank is inserted, and every adjacent pair of asterisks (**) on a card is replaced by the character. The sequential solution is unattractive because of the overhead of I/O and temporary files. Conway proposed a new form of program structure, the coroutine, that allows the application to be written as three programs connected by one-character buffers (Figure 5.25). In a traditional procedure, there is a master/slave relationship between the called and calling procedure. The calling procedure may execute a call from any point in the procedure; the called procedure is begun at its entry point and returns to the calling procedure at the point of call. The coroutine exhibits a more symmetric relationship. As each call is made, execution takes up from the last active point in the called procedure. Because there is no sense in which a calling procedure is \u201chigher\u201d than the called, there is no return. Rather, any coroutine can pass control to any other coroutine with a resume command. The first time a coroutine is invoked, it is \u201cresumed\u201d at its entry point. Subsequently, the coroutine is reactivated at the point of its own last resume command. Note that only one coroutine in a program can be in execution at one time and that the transition points are explicitly defined in the code, so this is not an example of concurrent processing. Explain the operation of the program in Figure 5.25.", "Processes and threads provide a powerful structuring tool for implementing programs that would be much more complex as simple sequential programs. An earlier construct that is instructive to examine is the coroutine. The purpose of this problem is to introduce coroutines and compare them to processes. Consider this simple problem from [CONW63]: Read 80-column cards and print them on 125-character lines, with the following changes. After every card image an extra blank is inserted, and every adjacent pair of asterisks (**) on a card is replaced by the character. The program does not address the termination condition. Assume that the I/O routine READCARD returns the value true if it has placed an 80-character image in inbuf; otherwise it returns false. Modify the program to include this contingency. Note that the last printed line may therefore contain less than 125 characters.", "Processes and threads provide a powerful structuring tool for implementing programs that would be much more complex as simple sequential programs. An earlier construct that is instructive to examine is the coroutine. The purpose of this problem is to introduce coroutines and compare them to processes. Consider this simple problem from [CONW63]: Read 80-column cards and print them on 125-character lines, with the following changes. After every card image an extra blank is inserted, and every adjacent pair of asterisks (**) on a card is replaced by the character. Rewrite the solution as a set of three processes using semaphores.", "Consider the following program: <CODE> Note that the scheduler in a uniprocessor system would implement pseudo-parallel execution of these two concurrent processes by interleaving their instructions, without restriction on the order of the interleaving. Show a sequence (i.e., trace the sequence of interleavings of statements) such that the statement \u201cx is 10\u201d is printed.", "Consider the following program: <CODE> Note that the scheduler in a uniprocessor system would implement pseudo-parallel execution of these two concurrent processes by interleaving their instructions, without restriction on the order of the interleaving. Show a sequence such that the statement \u201cx is 8\u201d is printed. You should remember that the increment/decrements at the source language level are not done atomically, that is, the assembly language code: <CODE> implements the single C increment instruction (x = x + 1).", "Consider the following program: <CODE> Determine the proper lower bound and upper bound on the final value of the shared variable tally output by this concurrent program. Assume processes can execute at any relative speed and that a value can only be incremented after it has been loaded into a register by a separate machine instruction.", "Consider the following program: <CODE> Suppose that an arbitrary number of these processes are permitted to execute in parallel under the assumptions of part (a). What effect will this modification have on the range of final values of tally?", "Is busy waiting always less efficient (in terms of using processor time) than a blocking wait? Explain.", "Consider the following program: <CODE> This software solution to the mutual exclusion problem for two processes is proposed in [HYMA66]. Find a counterexample that demonstrates that this solution is incorrect. It is interesting to note that even the Communications of the ACM was fooled on this one.", "A software approach to mutual exclusion is Lamport\u2019s bakery algorithm [LAMP74], so called because it is based on the practice in bakeries and other shops in which every customer receives a numbered ticket on arrival, allowing each to be served in turn. The algorithm is as follows: <CODE> The arrays choosing and number are initialized to false and 0, respectively. The ith element of each array may be read and written by process i but only read by other processes. The notation (a, b) < (c, d) is defined as: ( a < c ) or ( a = c and b < d ) Describe the algorithm in words.", "A software approach to mutual exclusion is Lamport\u2019s bakery algorithm [LAMP74], so called because it is based on the practice in bakeries and other shops in which every customer receives a numbered ticket on arrival, allowing each to be served in turn. The algorithm is as follows: <CODE> Show that this algorithm avoids deadlock.", "A software approach to mutual exclusion is Lamport\u2019s bakery algorithm [LAMP74], so called because it is based on the practice in bakeries and other shops in which every customer receives a numbered ticket on arrival, allowing each to be served in turn. The algorithm is as follows: <CODE> Show that it enforces mutual exclusion.", "Now consider a version of the bakery algorithm without the variable choosing. Then we have <CODE> Does this version violate mutual exclusion? Explain why or why not.", "Consider the following program which provides a software approach to mutual exclusion: integer array control [1 :N]; integer k where 1 \u2264 k \u2264 N, and each element of \u201ccontrol\u201d is either 0, 1, or 2. All elements of \u201ccontrol\u201d are initially zero; the initial value of k is immaterial. The program of the ith process (1 \u2264 i \u2264 N) is begin integer j; <CODE> This is referred to as the Eisenberg-McGuire algorithm. Explain its operation and its key features.", "Consider the first instance of the statement bolt = 0 in Figure 5.2b. Achieve the same result using the exchange instruction.", "Consider the first instance of the statement bolt = 0 in Figure 5.2b. Which method is preferable?", "When a special machine instruction is used to provide mutual exclusion in the fashion of Figure 5.2, there is no control over how long a process must wait before being granted access to its critical section. Devise an algorithm that uses the compare&swap instruction but that guarantees that any process waiting to enter its critical section will do so within n \u2013 1 turns, where n is the number of processes that may require access to the critical section and a \u201cturn\u201d is an event consisting of one process leaving the critical section and another process being granted access.", "Consider the following definition of semaphores: <CODE> Compare this set of definitions with that of Figure 5.3. Note one difference: With the preceding definition, a semaphore can never take on a negative value. Is there any difference in the effect of the two sets of definitions when used in programs? That is, could you substitute one set for the other without altering the meaning of the program?", "Consider a sharable resource with the following characteristics: (1) As long as there are fewer than three processes using the resource, new processes can start using it right away. (2) Once there are three process using the resource, all three must leave before any new processes can begin using it. We realize that counters are needed to keep track of how many processes are waiting and active, and that these counters are themselves shared resources that must be protected with mutual exclusion. So we might create the following solution: <CODE> The program is nevertheless incorrect. Explain why.", "Consider a sharable resource with the following characteristics: (1) As long as there are fewer than three processes using the resource, new processes can start using it right away. (2) Once there are three process using the resource, all three must leave before any new processes can begin using it. We realize that counters are needed to keep track of how many processes are waiting and active, and that these counters are themselves shared resources that must be protected with mutual exclusion. So we might create the following solution: <CODE> Suppose we change the if in line 6 to a while. Does this solve any problem in the program? Do any difficulties remain?", "Now consider this correct solution to the preceding problem: <CODE> Explain how this program works and why it is correct.", "Now consider this correct solution to the preceding problem: <CODE> This solution does not completely prevent newly arriving processes from cutting in line but it does make it less likely. Give an example of cutting in line.", "Now consider this correct solution to the preceding problem: <CODE> This program is an example of a general design pattern that is a uniform way to implement solutions to many concurrency problems using semaphores. It has been referred to as the I\u2019ll Do It For You pattern. Describe the pattern.", "Now consider another correct solution to the preceding problem: <CODE> Explain how this program works and why it is correct.", "Now consider another correct solution to the preceding problem: <CODE> Does this solution differ from the preceding one in terms of the number of processes that can be unblocked at a time? Explain.", "This program is an example of a general design pattern that is a uniform way to implement solutions to many concurrency problems using semaphores. It has been referred to as the Pass The Baton pattern. Describe the pattern.", "It should be possible to implement general semaphores using binary semaphores. We can use the operations semWaitB and semSignalB and two binary semaphores, delay and mutex. Consider the following: <CODE> Initially, s is set to the desired semaphore value. Each semWait operation decrements s, and each semSignal operation increments s. The binary semaphore mutex, which is initialized to 1, assures that there is mutual exclusion for the updating of s. The binary semaphore delay, which is initialized to 0, is used to block processes. There is a flaw in the preceding program. Demonstrate the flaw and propose a change that will fix it. Hint: Suppose two processes each call semWait(s) when s is initially 0, and after the first has just performed semSignalB(mutex) but not performed semWaitB(delay), the second call to semWait(s) proceeds to the same point. All that you need to do is move a single line of the program.", "In 1978, Dijkstra put forward the conjecture that there was no solution to the mutual exclusion problem avoiding starvation, applicable to an unknown but finite number of processes, using a finite number of weak semaphores. In 1979, J. M. Morris refuted this conjecture by publishing an algorithm using three weak semaphores. The behavior of the algorithm can be described as follows: If one or several process are waiting in a semWait(S) operation and another process is executing semSignal(S), the value of the semaphore S is not modified and one of the waiting processes is unblocked independently of semWait(S). Apart from the three semaphores, the algorithm uses two nonnegative integer variables as counters of the number of processes in certain sections of the algorithm. Thus, semaphores A and B are initialized to 1, while semaphore M and counters NA and NM are initialized to 0. The mutual exclusion semaphore B protects access to the shared variable NA. A process attempting to enter its critical section must cross two barriers represented by semaphores A and M. Counters NA and NM, respectively, contain the number of processes ready to cross barrier A and those having already crossed barrier A but not yet barrier M. In the second part of the protocol, the NM processes blocked at M will enter their critical sections one by one, using a cascade technique similar to that used in the first part. Define an algorithm that conforms to this description.", "5.18 The following problem was once used on an exam: Jurassic Park consists of a dinosaur museum and a park for safari riding. There are m passengers and n single-passenger cars. Passengers wander around the museum for a while, then line up to take a ride in a safari car. When a car is available, it loads the one passenger it can hold and rides around the park for a random amount of time. If the n cars are all out riding passengers around, then a passenger who wants to ride waits; if a car is ready to load but there are no waiting passengers, then the car waits. Use semaphores to synchronize the m passenger processes and the n car processes. The following skeleton code was found on a scrap of paper on the floor of the exam room. Grade it for correctness. Ignore syntax and missing variable declarations. Remember that P and V correspond to semWait and semSignal. <CODE>", "In the commentary on Figure 5.9 and Table 5.4, it was stated that \u201cit would not do simply to move the conditional statement inside the critical section (controlled by s) of the consumer because this could lead to deadlock.\u201d Demonstrate this with a table similar to Table 5.4.", "Consider the solution to the infinite-buffer producer/consumer problem defined in Figure 5.10. Suppose we have the (common) case in which the producer and consumer are running at roughly the same speed. The scenario could be: Producer: append; semSignal; produce; ... ; append; semSignal; produce; ... Consumer: consume; ... ; take; semWait; consume; ... ; take; semWait; ... The producer always manages to append a new element to the buffer and signal during the consumption of the previous element by the consumer. The producer is always appending to an empty buffer and the consumer is always taking the sole item in the buffer. Although the consumer never blocks on the semaphore, a large number of calls to the semaphore mechanism is made, creating considerable overhead. Construct a new program that will be more efficient under these circumstances. Hints: Allow n to have the value \u20131, which is to mean that not only is the buffer empty but that the consumer has detected this fact and is going to block until the producer supplies fresh data.", "Consider Figure 5.13. Would the meaning of the program change if the following were interchanged? a. semWait(e);semWait(s) b. semSignal(s);semSignal(n) c. semWait(n);semWait(s) d. semSignal(s);semSignal(e)", "The following pseudocode is a correct implementation of the producer/consumer problem with a bounded buffer: Labels p1, p2, p3 and c1, c2, c3 refer to the lines of code shown above (p2 and c2 each cover three lines of code). Semaphores empty and full are linear semaphores that can take unbounded negative and positive values. There are multiple producer processes, referred to as Pa, Pb, Pc, etc., and multiple consumer processes, referred to as Ca, Cb, Cc, etc. Each semaphore maintains a FIFO (first-in-first-out) queue of blocked processes. In the scheduling chart below, each line represents the state of the buffer and semaphores after the scheduled execution has occurred. To simplify, we assume that scheduling is such that processes are never interrupted while executing a given portion of code p1, or p2, ..., or c3. Your task is to complete the following chart.", "This problem demonstrates the use of semaphores to coordinate three types of processes. Santa Claus sleeps in his shop at the North Pole and can only be wakened by either (1) all nine reindeer being back from their vacation in the South Pacific, or (2) some of the elves having difficulties making toys; to allow Santa to get some sleep, the elves can only wake him when three of them have problems. When three elves are having their problems solved, any other elves wishing to visit Santa must wait for those elves to return. If Santa wakes up to find three elves waiting at his shop\u2019s door, along with the last reindeer having come back from the tropics, Santa has decided that the elves can wait until after Christmas, because it is more important to get his sleigh ready. (It is assumed that the reindeer do not want to leave the tropics, and therefore they stay there until the last possible moment.) The last reindeer to arrive must get Santa while the others wait in a warming hut before being harnessed to the sleigh. Solve this problem using semaphores.", "Show that message passing and semaphores have equivalent functionality by Implementing message passing using semaphores. Hint: Make use of a shared buffer area to hold mailboxes, each one consisting of an array of message slots.", "Show that message passing and semaphores have equivalent functionality by b. Implementing a semaphore using message passing. Hint: Introduce a separate synchronization process.", "Explain what is the problem with this implementation of the one-writer many-readers problem? <CODE>", "Show that the four conditions of deadlock apply to Figure 6.1a.", "Show how each of the techniques of prevention, avoidance, and detection can be applied to Figure 6.1.", "For Figure 6.3, provide a narrative description of each of the six depicted paths, similar to the description of the paths of Figure 6.2 provided in Section 6.1.", "It was stated that deadlock cannot occur for the situation reflected in Figure 6.3. Justify that statement.", "Given the following state for the Banker\u2019s Algorithm. 6 processes P0 through P5 4 resource types: A (15 instances); B (6 instances) C (9 instances); D (10 instances) Snapshot at time T0: Verify that the Available array has been calculated correctly.", "Given the following state for the Banker\u2019s Algorithm. 6 processes P0 through P5 4 resource types: A (15 instances); B (6 instances) C (9 instances); D (10 instances) Snapshot at time T0: Calculate the Need matrix.", "Given the following state for the Banker\u2019s Algorithm. 6 processes P0 through P5 4 resource types: A (15 instances); B (6 instances) C (9 instances); D (10 instances) Snapshot at time T0: Show that the current state is safe, that is, show a safe sequence of processes. In addition, to the sequence show how the Available (working array) changes as each process terminates.", "Given the following state for the Banker\u2019s Algorithm. 6 processes P0 through P5 4 resource types: A (15 instances); B (6 instances) C (9 instances); D (10 instances) Snapshot at time T0: Given the request (3,2,3,3) from Process P5. Should this request be granted? Why or why not?", "In the code below, three processes are competing for six resources labeled A to F. Using a resource allocation graph (Figures 6.5 and 6.6), show the possibility of a deadlock in this implementation.", "In the code below, three processes are competing for six resources labeled A to F. Modify the order of some of the get requests to prevent the possibility of any deadlock. You cannot move requests across procedures, only change the order inside each procedure. Use a resource allocation graph to justify your answer.", "A spooling system (Figure 6.16) consists of an input process I, a user process P, and an output process O connected by two buffers. The processes exchange data in blocks of equal size. These blocks are buffered on a disk using a floating boundary between the input and the output buffers, depending on the speed of the processes. The communication primitives used ensure that the following resource constraint is satisfied: <CONDITIONS> Show that this system can become deadlocked.", "Suggest an additional resource constraint that will prevent the deadlock in Problem 6.7 but still permit the boundary between input and output buffers to vary in accordance with the present needs of the processes.", "In the THE multiprogramming system [DIJK68], a drum (precursor to the disk for secondary storage) is divided into input buffers, processing areas, and output buffers, with floating boundaries, depending on the speed of the processes involved. The current state of the drum can be characterized by the following parameters: max = maximum number of pages on drum i = number of input pages on drum p = number of processing pages on drum o = number of output pages on drum reso = minimum number of pages reserved for output resp = minimum number of pages reserved for processing Formulate the necessary resource constraints that guarantee that the drum capacity is not exceeded and that a minimum number of pages is reserved permanently for output and processing.", "In the THE multiprogramming system, a page can make the following state transitions: <CONDITIONS> Define the effect of these", "In the THE multiprogramming system, a page can make the following state transitions: <CONDITIONS> Can any of them lead to a buffer transitions in terms of the quantities i, o, and p. deadlock if the assumptions made in Problem 6.6 about input processes, user processes, and output processes hold?", "Consider a system with a total of 150 units of memory, allocated to three processes as shown: Apply the banker\u2019s algorithm to determine whether it would be safe to grant each of the following requests. If yes, indicate a sequence of terminations that could be guaranteed possible. If no, show the reduction of the resulting allocation table. a. A fourth process arrives, with a maximum memory need of 60 and an initial need of 25 units. b. A fourth process arrives, with a maximum memory need of 60 and an initial need of 35 units.", "Evaluate the banker\u2019s algorithm for its usefulness in an OS.", "A pipeline algorithm is implemented so that a stream of data elements of type T produced by a process P0 passes through a sequence of processes P1, P2, ..., Pn \u2013 1, which operates on the elements in that order. a. Define a generalized message buffer that contains all the partially consumed data elements and write an algorithm for process Pi (0   i   n \u2013 1), of the form repeat receive from predecessor; consume element; send to successor: forever Assume P0 receives input elements sent by Pn \u2013 1. The algorithm should enable the processes to operate directly on messages stored in the buffer so that copying is unnecessary.", "A pipeline algorithm is implemented so that a stream of data elements of type T produced by a process P0 passes through a sequence of processes P1, P2, ..., Pn \u2013 1, which operates on the elements in that order. a. Define a generalized message buffer that contains all the partially consumed data elements and write an algorithm for process Pi (0   i   n \u2013 1), of the form repeat receive from predecessor; consume element; send to successor: forever. Show that the processes cannot be deadlocked with respect to the common buffer.", "Suppose the following two processes, foo and bar are executed concurrently and share the semaphore variables S and R (each initialized to 1) and the integer variable x (initialized to 0). Can the concurrent execution of these two processes result in one or both being blocked forever? If yes, give an execution sequence in which one or both are blocked forever.", "Suppose the following two processes, foo and bar are executed concurrently and share the semaphore variables S and R (each initialized to 1) and the integer variable x (initialized to 0). Can the concurrent execution of these two processes result in the indefinite postponement of one of them? If yes, give an execution sequence in which one is indefinitely postponed.", "Consider a system consisting of four processes and a single resource. The current state of the claim and allocation matrices are: What is the minimum number of units of the resource needed to be available for this state to be safe?", "Consider the following ways of handling deadlock: (1) banker\u2019s algorithm, (2) detect deadlock and kill thread, releasing all resources, (3) reserve all resources in advance, (4) restart thread and release all resources if thread needs to wait, (5) resource ordering, and (6) detect deadlock and roll back thread\u2019s actions. a. One criterion to use in evaluating different approaches to deadlock is which approach permits the greatest concurrency. In other words, which approach allows the most threads to make progress without waiting when there is no deadlock? Give a rank order from 1 to 6 for each of the ways of handling deadlock just listed, where 1 allows the greatest degree of concurrency. Comment on your ordering.", "Consider the following ways of handling deadlock: (1) banker\u2019s algorithm, (2) detect deadlock and kill thread, releasing all resources, (3) reserve all resources in advance, (4) restart thread and release all resources if thread needs to wait, (5) resource ordering, and (6) detect deadlock and roll back thread\u2019s actions. Another criterion is efficiency; in other words, which requires the least processor overhead. Rank order the approaches from 1 to 6, with 1 being the most efficient, assuming that deadlock is a very rare event. Comment on your ordering. Does your ordering change if deadlocks occur frequently?", "Comment on the following solution to the dining philosophers problem. A hungry philosopher first picks up his left fork; if his right fork is also available, he picks up his right fork and starts eating; otherwise he puts down his left fork again and repeats the cycle.", "Suppose that there are two types of philosophers. One type always picks up his left fork first (a \u201clefty\u201d), and the other type always picks up his right fork first (a \u201crighty\u201d). The behavior of a lefty is defined in Figure 6.12. The behavior of a righty is as follows: <CODE> Prove the following: Any seating arrangement of lefties and righties with at least one of each avoids deadlock.", "Suppose that there are two types of philosophers. One type always picks up his left fork first (a \u201clefty\u201d), and the other type always picks up his right fork first (a \u201crighty\u201d). The behavior of a lefty is defined in Figure 6.12. The behavior of a righty is as follows: <CODE> Prove the following: Any seating arrangement of lefties and righties with at least one of each prevents starvation.", "Figure 6.17 shows another solution to the dining philosophers problem using monitors. Compare to Figure 6.14 and report your conclusions.", "In Table 6.3, some of the Linux atomic operations do not involve two accesses to a variable, such as atomic_read(atomic_t *v). A simple read operation is obviously atomic in any architecture. Therefore, why is this operation added to the repertoire of atomic operations?", "Consider the following fragment of code on a Linux system. read_lock(&mr_rwlock); write_lock(&mr_rwlock); Where mr_rwlock is a reader\u2013writer lock. What is the effect of this code?", "The two variables a and b have initial values of 1 and 2, respectively. The following code is for a Linux system: <CODE> What possible errors are avoided by the use of the memory barriers?", "In Section 2.3, we listed five objectives of memory management, and in Section 7.1, we listed five requirements. Argue that each list encompasses all of the concerns addressed in the other.", "Consider a fixed partitioning scheme with equal-size partitions of 216 bytes and a total main memory size of 224 bytes. A process table is maintained that includes a pointer to a partition for each resident process. How many bits are required for the pointer?", "Consider a dynamic partitioning scheme. Show that, on average, the memory contains half as many holes as segments.", "To implement the various placement algorithms discussed for dynamic partitioning (Section 7.2), a list of the free blocks of memory must be kept. For each of the three methods discussed (best-fit, first-fit, next-fit), what is the average length of the search?", "Another placement algorithm for dynamic partitioning is referred to as worst-fit. In this case, the largest free block of memory is used for bringing in a process. Discuss the pros and cons of this method compared to first-, next-, and best-fit.", "Another placement algorithm for dynamic partitioning is referred to as worst-fit. In this case, the largest free block of memory is used for bringing in a process. What is the average length of the search for worst-fit?", "This diagram shows an example of memory configuration under dynamic partitioning, after a number of placement and swapping-out operations have been carried out. Addresses go from left to right; gray areas indicate blocks occupied by processes; white areas indicate free memory blocks. The last process placed is 2-Mbyte and is marked with an X. Only one process was swapped out after that. What was the maximum size of the swapped out process? What was the size of the free block just before it was partitioned by X?", "This diagram shows an example of memory configuration under dynamic partitioning, after a number of placement and swapping-out operations have been carried out. Addresses go from left to right; gray areas indicate blocks occupied by processes; white areas indicate free memory blocks. The last process placed is 2-Mbyte and is marked with an X. Only one process was swapped out after that. A new 3-Mbyte allocation request must be satisfied next. Indicate the intervals of memory where a partition will be created for the new process under the following four placement algorithms: best-fit, first-fit, next-fit, worst-fit. For each algorithm, draw a horizontal segment under the memory strip and label it clearly.", "A 1-Mbyte block of memory is allocated using the buddy system. Show the results of the following sequence in a figure similar to Figure 7.6: Request 70; Request 35; Request 80; Return A; Request 60; Return B; Return D; Return C.", "A 1-Mbyte block of memory is allocated using the buddy system. Show the binary tree representation following Return B.", "Consider a buddy system in which a particular block under the current allocation has an address of 011011110000. If the block is of size 4, what is the binary address of its buddy? If the block is of size 16, what is the binary address of its buddy?", "Let buddyk(x)   address of the buddy of the block of size 2k whose address is x. Write a general expression for buddyk(x).", "The Fibonacci sequence is defined as follows: F0   0, F1   1, Fn+2   Fn+1 + Fn, n   0. Could this sequence be used to establish a buddy system?", "The Fibonacci sequence is defined as follows: F0   0, F1   1, Fn+2   Fn+1 + Fn, n   0. IF this sequence is used to establish a buddy system, what would be its advantage over the binary buddy system described in this chapter?", "During the course of execution of a program, the processor will increment the contents of the instruction register (program counter) by one word after each instruction fetch, but will alter the contents of that register if it encounters a branch or call instruction that causes execution to continue elsewhere in the program. Now consider Figure 7.8. There are two alternatives with respect to instruction addresses: \u2022 Maintain a relative address in the instruction register and do the dynamic address translation using the instruction register as input. When a successful branch or call is encountered, the relative address generated by that branch or call is loaded into the instruction register. \u2022 Maintain an absolute address in the instruction register. When a successful branch or call is encountered, dynamic address translation is employed, with the results stored in the instruction register. Which approach is preferable?", "Consider a simple paging system with the following parameters: 232 bytes of physical memory; page size of 210 bytes; 216 pages of logical address space. How many bits are in a logical address? How many bytes in a frame? How many bits in the physical address specify the frame? How many entries in the page table? How many bits in each page table entry? Assume each page table entry contains a valid/invalid bit.", "Write the binary translation of the logical address 0001010010111010 under the following hypothetical memory management schemes, and explain your answer: a paging system with a 256-address page size, using a page table in which the frame number happens to be four times smaller than the page number", "Write the binary translation of the logical address 0001010010111010 under the following hypothetical memory management schemes, and explain your answer: a segmentation system with a 1K-address maximum segment size, using a segment table in which bases happen to be regularly placed at real addresses: 22   4,096 segment #", "Consider a simple segmentation system that has the following segment table: <TABLE> For each of the following logical addresses, determine the physical address or indicate if a segment fault occurs", "Consider a memory in which contiguous segments S1, S2,...,Sn are placed in their order of creation from one end of the store to the other, as suggested by the following figure: When segment Sn+1 is being created, it is placed immediately after segment Sn even though some of the segments S1, S2,...,Sn may already have been deleted. When the boundary between segments (in use or deleted) and the hole reaches the other end of the memory, the segments in use are compacted. Show that the fraction of time F spent on compacting obeys the following inequality: FU\u03011-f wherek=t-1 1 + kf 2s where, s   average length of a segment, in words, t   average lifetime of a segment, in memory references, f   fraction of the memory that is unused under equilibrium conditions Hint: Find the average speed at which the boundary crosses the memory and assume that the copying of a single word requires at least two memory references.", "Consider a memory in which contiguous segments S1, S2,...,Sn are placed in their order of creation from one end of the store to the other, as suggested by the following figure: When segment Sn+1 is being created, it is placed immediately after segment Sn even though some of the segments S1, S2,...,Sn may already have been deleted. When the boundary between segments (in use or deleted) and the hole reaches the other end of the memory, the segments in use are compacted. The fraction of time F spent on compacting obeys the following inequality: FU\u03011-f wherek=t-1 1 + kf 2s where, s   average length of a segment, in words, t   average lifetime of a segment, in memory references, f   fraction of the memory that is unused under equilibrium conditions. Find F for f 0.2,t 1,000, and s 50.", "Suppose the page table for the process currently executing on the processor looks like the following. All numbers are decimal, everything is numbered starting from zero, and all addresses are memory byte addresses. The page size is 1,024 bytes. Describe exactly how, in general, a virtual address generated by the CPU is translated into a physical main memory address.", "Suppose the page table for the process currently executing on the processor looks like the following. All numbers are decimal, everything is numbered starting from zero, and all addresses are memory byte addresses. The page size is 1,024 bytes. What physical address, if any, would each of the following virtual addresses correspond to?", "Consider the following program. <CODE> Assume that the program is running on a system using demand paging and the page size is 1 Kilobyte. Each integer is 4 bytes long. It is clear that each array requires a 16-page space. As an example, A[0, 0]-A[0, 63], A[1, 0]-A[1, 63], A[2, 0]-A[2, 63], and A[3, 0]-A[3, 63] will be stored in the first data page. A similar storage pattern can be derived for the rest of array A and for arrays B and C. Assume that the system allocates a 4-page working set for this process. One of the pages will be used by the program and three pages can be used for the data. Also, two index registers are assigned for i and j (so, no memory accesses are needed for references to these two variables). Discuss how frequently the page fault would occur (in terms of number of times C[i, j]   A[i, j]   B[i, j] are executed).", "Consider the following program. <CODE> Assume that the program is running on a system using demand paging and the page size is 1 Kilobyte. Each integer is 4 bytes long. It is clear that each array requires a 16-page space. As an example, A[0, 0]-A[0, 63], A[1, 0]-A[1, 63], A[2, 0]-A[2, 63], and A[3, 0]-A[3, 63] will be stored in the first data page. A similar storage pattern can be derived for the rest of array A and for arrays B and C. Assume that the system allocates a 4-page working set for this process. One of the pages will be used by the program and three pages can be used for the data. Also, two index registers are assigned for i and j (so, no memory accesses are needed for references to these two variables). Can you modify the program to minimize the page fault frequency? What will be the frequency of page faults after your modification?", "Assume you want to implement a hashed inverted page table for the same. How much memory space is needed for the user page table of Figure 8.4?", "The addressing scheme as depicted in Figure 8.4, using a hash function that maps the 20-bit page number into a 6-bit hash value. The table entry contains the page number, the frame number, and a chain pointer. If the page table allocates space for up to 3 overflow entries per hashed entry, how much memory space does the hashed inverted page table take?", "Consider the following string of page references 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2. Complete a figure similar to Figure 8.15, showing the frame allocation for: FIFO (first-in-first-out), LRU (least recently used), Clock and Optimal (assume the page reference string continues with 1, 2, 0, 1, 7, 0, 1)", "Consider the following string of page references 7, 0, 1, 2, 0, 3, 0, 4, 2, 3, 0, 3, 2 and the policies: FIFO (first-in-first-out), LRU (least recently used), Clock and Optimal. List the total number of page faults and the miss rate for each policy. Count page faults only after all frames have been initialized.", "A process references five pages, A, B, C, D, and E, in the following order: A; B; C; D; A; B; E; A; B; C; D; E Assume that the replacement algorithm is first-in-first-out and find the number of page transfers during this sequence of references starting with an empty main memory with three page frames. Repeat for four page frames.", "A process contains eight virtual pages on disk and is assigned a fixed allocation of four page frames in main memory. The following page trace occurs: 1, 0, 2, 2, 1, 7, 6, 7, 0, 1, 2, 0, 3, 0, 4, 5, 1, 5, 2, 4, 5, 6, 7, 6, 7, 2, 4, 2, 7, 3, 3, 2, 3", "a. Show the successive pages residing in the four frames using the LRU replacement policy. Compute the hit ratio in main memory. Assume that the frames are initially empty.", "A process contains eight virtual pages on disk and is assigned a fixed allocation of four page frames in main memory. The following page trace occurs: 1, 0, 2, 2, 1, 7, 6, 7, 0, 1, 2, 0, 3, 0, 4, 5, 1, 5, 2, 4, 5, 6, 7, 6, 7, 2, 4, 2, 7, 3, 3, 2, 3", "a. Show the successive pages residing in the four frames using the FIFO replacement policy. Compute the hit ratio in main memory. Assume that the frames are initially empty.", "A process contains eight virtual pages on disk and is assigned a fixed allocation of four page frames in main memory. The following page trace occurs: 1, 0, 2, 2, 1, 7, 6, 7, 0, 1, 2, 0, 3, 0, 4, 5, 1, 5, 2, 4, 5, 6, 7, 6, 7, 2, 4, 2, 7, 3, 3, 2, 3 Compare the two hit ratios and comment on the effectiveness of using FIFO to approximate LRU with respect to this particular trace.", "In the VAX, user page tables are located at virtual addresses in the system space. What is the advantage of having user page tables in virtual rather than main memory? What is the disadvantage?", "Suppose the program statement <CODE> is executed in a memory with page size of 1,000 words. Let n   1,000. Using a machine that has a full range of register-to-register instructions and employs index registers, write a hypothetical program to implement the foregoing statement. Then show the sequence of page references during execution.", "The IBM System/370 architecture uses a two-level memory structure and refers to the two levels as segments and pages, although the segmentation approach lacks many of the features described earlier in this chapter. For the basic 370 architecture, the page size may be either 2 Kbytes or 4 Kbytes, and the segment size is fixed at either 64 Kbytes or 1 Mbyte. For the 370/XA and 370/ESA architectures, the page size is 4 Kbytes and the segment size is 1 Mbyte. Which advantages of segmentation does this scheme lack? What is the benefit of segmentation for the 370?", "Assuming a page size of 4 Kbytes and that a page table entry takes 4 bytes, how many levels of page tables would be required to map a 64-bit address space, if the top level page table fits into a single page?", "Consider a system with memory mapping done on a page basis and using a single level page table. Assume that the necessary page table is always in memory. If a memory reference takes 200 ns, how long does a paged memory reference take?", "Consider a system with memory mapping done on a page basis and using a single level page table. Assume that the necessary page table is always in memory. Now we add an MMU that imposes an overhead of 20 ns on a hit or a miss. If we assume that 85% of all memory references hit in the MMU TLB, what is the Effective Memory Access Time (EMAT)?", "Consider a system with memory mapping done on a page basis and using a single level page table. Assume that the necessary page table is always in memory. Explain how the TLB hit rate affects the EMAT.", "Consider a page reference string for a process with a working set of M frames, initially all empty. The page reference string is of length P with N distinct page numbers in it. For any page replacement algorithm, What is a lower bound on the number of page faults? What is an upper bound on the number of page faults?", "In discussing a page replacement algorithm, one author makes an analogy with a snowplow moving around a circular track. Snow is falling uniformly on the track and a lone snowplow continually circles the track at constant speed. The snow that is plowed off the track disappears from the system. For which of the page replacement algorithms discussed in Section 8.2 is this a useful analogy?", "In discussing a page replacement algorithm, one author makes an analogy with a snowplow moving around a circular track. Snow is falling uniformly on the track and a lone snowplow continually circles the track at constant speed. The snow that is plowed off the track disappears from the system. What does this analogy suggest about the behavior of the page replacement algorithm in question?", "In the S/370 architecture, a storage key is a control field associated with each page-sized frame of real memory. Two bits of that key that are relevant for page replacement are the reference bit and the change bit. The reference bit is set to 1 when any address within the frame is accessed for read or write, and is set to 0 when a new page is loaded into the frame. The change bit is set to 1 when a write operation is performed on any location within the frame. Suggest an approach for determining which page frames are least-recently-used, making use of only the reference bit.", "Consider the following sequence of page references (each element in the sequence represents a page number): 12345213323454511325 1<<k Define the mean working set size after the kth reference as sk( ) = k a 0 W(t, ) 0 t=1 1k and define the missing page probability after the kth reference as mk( ) = k a F(t, ) t=1 where F(t,  )   1 if a page fault occurs at virtual time t and 0 otherwise. Draw a diagram similar to that of Figure 8.19 for the reference sequence just defined for the values     1, 2, 3, 4, 5, 6. Plot s20( ) as a function of  . Plot m20( ) as a function of  .", "A key to the performance of the VSWS resident set management policy is the value of Q. Experience has shown that, with a fixed value of Q for a process, there are considerable differences in page fault frequencies at various stages of execution. Furthermore, if a single value of Q is used for different processes, dramatically different frequencies of page faults occur. These differences strongly indicate that a mechanism that would dynamically adjust the value of Q during the lifetime of a process would improve the behavior of the algorithm. Suggest a simple mechanism for this purpose.", "Assume that a task is divided into four equal-sized segments and that the system builds an eight-entry page descriptor table for each segment. Thus, the system has a combination of segmentation and paging. Assume also that the page size is 2 Kbytes. What is the maximum size of each segment? What is the maximum logical address space for the task?", "Assume that a task is divided into four equal-sized segments and that the system builds an eight-entry page descriptor table for each segment. Thus, the system has a combination of segmentation and paging. Assume also that the page size is 2 Kbytes. Assume that an element in physical location 00021ABC is accessed by this task. What is the format of the logical address that the task generates for it? What is the maximum physical address space for the system?", "Consider a paged logical address space (composed of 32 pages of 2 Kbytes each) mapped into a 1-Mbyte physical memory space. What is the format of the processor\u2019s logical address?", "Consider a paged logical address space (composed of 32 pages of 2 Kbytes each) mapped into a 1-Mbyte physical memory space. What is the length and width of the page table (disregarding the \u201caccess rights\u201d bits)?", "Consider a paged logical address space (composed of 32 pages of 2 Kbytes each) mapped into a 1-Mbyte physical memory space. What is the effect on the page table if the physical memory space is reduced by half?", "The UNIX kernel will dynamically grow a process\u2019s stack in virtual memory as needed, but it will never try to shrink it. Consider the case in which a program calls a C subroutine that allocates a local array on the stack that consumes 10 K. The kernel will expand the stack segment to accommodate it. When the subroutine returns, the stack pointer is adjusted and this space could be released by the kernel, but it is not released. Explain why it would be possible to shrink the stack at this point and why the UNIX kernel does not shrink it.", "Consider the following workload: Show the schedule using shortest remaining time, nonpreemptive priority (a smaller priority number implies higher priority) and round robin with quantum 30 ms. Use time scale diagram as shown below for the FCFS example to show the schedule for each requested scheduling policy. What is the average waiting time of the above scheduling policies?", "Consider the following set of processes: <TABLE> Perform the same analysis as depicted in Table 9.5 and Figure 9.5 for this set.", "Prove that, among nonpreemptive scheduling algorithms, SPN provides the minimum average waiting time for a batch of jobs that arrive at the same time. Assume that the scheduler must always execute a task if one is available.", "Assume the following burst-time pattern for a process: 6, 4, 6, 4, 13, 13, 13, and assume that the initial guess is 10. Produce a plot similar to those of Figure 9.9.", "Consider the following pair of equations as an alternative to Equation (9.3): Sn+1 =aTn +(1-a)Sn and Xn+1 = min[Ubound,max[Lbound,(bSn+1)]] where Ubound and Lbound are prechosen upper and lower bounds on the estimated value of T. The value of Xn + 1 is used in the shortest-process-next algorithm, instead of the value of Sn + 1. What functions do a and b perform, and what is the effect of higher and lower values on each?", "In the bottom example in Figure 9.5, process A runs for two time units before control is passed to process B. Another plausible scenario would be that A runs for three time units before control is passed to process B. What policy differences in the feedback scheduling algorithm would account for the two different scenarios?", "In a nonpreemptive uniprocessor system, the ready queue contains three jobs at time t immediately after the completion of a job. These jobs arrived at times t1, t2, and t3 with estimated execution times of r1, r2, and r3, respectively. Figure 9.18 shows the linear increase of their response ratios over time. Use this example to find a variant of response ratio scheduling, known as minimax response ratio scheduling, that minimizes the maximum response ratio for a given batch of jobs ignoring further arrivals. (Hint: Decide, first, which job to schedule as the last one.)", "Prove that the minimax response ratio algorithm of the preceding problem minimizes the maximum response ratio for a given batch of jobs. (Hint: Focus attention on the job that will achieve the highest response ratio and all jobs executed before it. Consider the same subset of jobs scheduled in any other order and observe the response ratio of the job that is executed as the last one among them. Notice that this subset may now be mixed with other jobs from the total set.)", "Define residence time Tr as the average total time a process spends waiting and being served. Show that for FIFO, with mean service time Ts, we have Tr = Ts/(1 \u2013 r), where r is utilization.", "9.10 A processor is multiplexed at infinite speed among all processes present in a ready queue with no overhead. (This is an idealized model of round-robin scheduling among ready processes using time slices that are very small compared to the mean service time.) Show that for Poisson input from an infinite source with exponential service times, the mean response time Rx of a process with service time x is given by Rx = x/(1 \u2013 r). (Hint: Review the basic queueing equations in Appendix H or Chapter 20. Then consider the number of items waiting, w, in the system upon arrival of the given process.)", "Consider a variant of the RR scheduling algorithm where the entries in the ready queue are pointers to the PCBs. What would be the effect of putting two pointers to the same process in the ready queue?", "Consider a variant of the RR scheduling algorithm where the entries in the ready queue are pointers to the PCBs. If we are to put two pointers to the same process in the ready queue,  what would be the major advantage of this scheme?", "Consider a variant of the RR scheduling algorithm where the entries in the ready queue are pointers to the PCBs. If we are to put two pointers to the same process in the ready queue. How could you modify the basic RR algorithm to achieve the same effect without the duplicate pointers?", "In a queueing system, new jobs must wait for a while before being served. While a job waits, its priority increases linearly with time from zero at a rate a. A job waits until its priority reaches the priority of the jobs in service; then, it begins to share the processor equally with other jobs in service using round robin while its priority continues to increase at a slower rate b. The algorithm is referred to as selfish round robin, because the jobs in service try (in vain) to monopolize the processor by increasing their priority continuously. Use Figure 9.19 to show that the mean response time Rx for a job of service time x is given by:  where Rx  s +x-s 1 - r 1 - r r ls r assuming that arrival and service times are exponentially distributed with means 1/  and s, respectively. (Hint: Consider the total system and the two subsystems separately.)", "An interactive system using round-robin scheduling and swapping tries to give guaranteed response to trivial requests as follows: After completing a round-robin cycle among all ready processes, the system determines the time slice to allocate to each ready process for the next cycle by dividing a maximum response time by the number of processes requiring service. Is this a reasonable policy?", "Which type of process is generally favored by a multilevel feedback queueing scheduler\u2014a processor-bound process or an I/O-bound process? Briefly explain why.", "In priority-based process scheduling, the scheduler only gives control to a particular process if no other process of higher priority is currently in the Ready state. Assume that no other information is used in making the process scheduling decision. Also assume that process priorities are established at process creation time and do not change. In a system operating with such assumptions, why would using Dekker\u2019s solution (see Section A.1) to the mutual exclusion problem be \u201cdangerous\u201d? Explain this by telling what undesired event could occur and how it could occur.", "Five batch jobs, A through E, arrive at a computer center at essentially the same time. They have an estimated running time of 15, 9, 3, 6, and 12 minutes, respectively. Their (externally defined) priorities are 6, 3, 7, 9, and 4, respectively, with a lower value corresponding to a higher priority. For each of the following scheduling algorithms, determine the turnaround time for each process and the average turnaround for all jobs. Ignore process switching overhead. Explain how you arrived at your answers. In the last three cases, assume that only one job at a time runs until it finishes and that all jobs are completely processor bound. a. round robin with a time quantum of 1 minute b. priority scheduling c. FCFS (run in order 15, 9, 3, 6, and 12) d. shortest job first", "Consider a set of three periodic tasks with the execution profiles of Table 10.6. Develop scheduling diagrams similar to those of Figure 10.5 for this set of tasks.", "Consider a set of five aperiodic tasks with the execution profiles of Table 10.7. Develop scheduling diagrams similar to those of Figure 10.6 for this set of tasks.", "Least laxity first (LLF) is a real-time scheduling algorithm for periodic tasks. Slack time, or laxity, is the amount of time between when a task would complete if it started now and its next deadline. This is the size of the available scheduling window. Laxity can be expressed as Laxity = (deadline time) - (current time) - (processor time needed) LLF selects the task with the minimum laxity to execute next. If two or more tasks have the same minimum laxity value, they are serviced on a FCFS basis. Suppose a task currently has a laxity of t. By how long may the scheduler delay starting this task and still meet its deadline?", "Least laxity first (LLF) is a real-time scheduling algorithm for periodic tasks. Slack time, or laxity, is the amount of time between when a task would complete if it started now and its next deadline. This is the size of the available scheduling window. Laxity can be expressed as Laxity = (deadline time) - (current time) - (processor time needed) LLF selects the task with the minimum laxity to execute next. If two or more tasks have the same minimum laxity value, they are serviced on a FCFS basis. Suppose a task currently has a laxity of 0. What does this mean? What does it mean if a task has negative laxity?", "Least laxity first (LLF) is a real-time scheduling algorithm for periodic tasks. Slack time, or laxity, is the amount of time between when a task would complete if it started now and its next deadline. This is the size of the available scheduling window. Laxity can be expressed as Laxity = (deadline time) - (current time) - (processor time needed) LLF selects the task with the minimum laxity to execute next. If two or more tasks have the same minimum laxity value, they are serviced on a FCFS basis. Consider a set of three periodic tasks with the execution profiles of Table 10.8a. Develop scheduling diagrams similar to those of Figure 10.4 for this set of tasks that compare rate monotonic, earliest deadline first, and LLF. Assume preemption may occur at 5-ms intervals. Comment on the results.", "Maximum urgency first (MUF) is a real-time scheduling algorithm for periodic tasks. Each task is assigned an urgency that is defined as a combination of two fixed priorities and one dynamic priority. One of the fixed priorities, the criticality, has precedence over the dynamic priority. Meanwhile, the dynamic priority has precedence over the other fixed priority, called the user priority. The dynamic priority is inversely proportional to the laxity of a task. MUF can be explained as follows. First, tasks are ordered from shortest to longest period. Define the critical task set as the first N tasks such that worst-case processor utilization does not exceed 100%. Among critical set tasks that are ready, the scheduler selects the task with the least laxity. If no critical set tasks are ready, the schedule chooses among the noncritical tasks the one with the least laxity. Ties are broken through an optional user priority and then by FCFS. Repeat Problem 10.3d, adding MUF to the diagrams. Assume that user-defined priorities are A highest, B next, C lowest. Comment on the results.", "Consider a program that accesses a single I/O device and compare unbuffered I/O to the use of a buffer. Show that the use of the buffer can reduce the running time by at most a factor of two.", "Consider a program that accesses n I/O devices and compare unbuffered I/O to the use of a buffer. Compare the running time with and without the use of the buffer.", "Consider a disk with N tracks numbered from 0 to (N - 1) and assume that requested sectors are distributed randomly and evenly over the disk. We want to calculate the average number of tracks traversed by a seek. Calculate the probability of a seek of length j when the head is currently positioned over track t. (Hint: This is a matter of determining the total number of combinations, recognizing that all track positions for the destination of the seek are equally likely.)", "Consider a disk with N tracks numbered from 0 to (N - 1) and assume that requested sectors are distributed randomly and evenly over the disk. We want to calculate the average number of tracks traversed by a seek. Calculate the probability of a seek of length K, for an arbitrary current position of the head. (Hint: This involves the summing over all possible combinations of movements of K tracks.)", "Consider a disk with N tracks numbered from 0 to (N - 1) and assume that requested sectors are distributed randomly and evenly over the disk. We want to calculate the average number of tracks traversed by a seek. Calculate the average number of tracks traversed by a seek, using the formula for expected value N-1 E[x]= ai* Pr[x=i] n Hint: Use the equalities a = i=0 n(n + 1) ; n n(n + 1)(2n + 1) ai2 = 6 . i=1  2", "The following equation was suggested both for cache memory and disk cache memory: TS =TC +M*TD Generalize this equation to a memory hierarchy with N levels instead of just 2.", "For the frequency-based replacement algorithm (Figure 11.9), define Fnew, Fmiddle, and Fold as the fraction of the cache that comprises the new, middle, and old sections, respectively. Clearly, Fnew + Fmiddle + Fold = 1. Characterize the policy when a. Fold =1-Fnew b. Fold = 1/(cache size)", "Calculate how much disk space (in sectors, tracks, and surfaces) will be required to store 300,000 120-byte logical records if the disk is fixed sector with 512 bytes/ sector, with 96 sectors/track, 110 tracks per surface, and 8 usable surfaces. Ignore any file header record(s) and track indexes, and assume that records cannot span two sectors.", "Consider the disk system described in Problem 11.7, and assume that the disk rotates at 360 rpm. A processor reads one sector from the disk using interrupt-driven I/O, with one interrupt per byte. If it takes 2.5 \u03bcs to process each interrupt, what percentage of the time will the processor spend handling I/O (disregard seek time)?", "A 32-bit computer has two selector channels and one multiplexor channel. Each selector channel supports two magnetic disk and two magnetic tape units. The multiplexor channel has two line printers, two card readers, and ten VDT terminals connected to it. Assume the following transfer rates: Disk drive 800 Kbytes/s Magnetic tape drive 200 Kbytes/s Line printer 6.6 Kbytes/s Card reader 1.2 Kbytes/s VDT 1 Kbyte/s. Estimate the maximum aggregate I/O transfer rate in this system.", "It should be clear that disk striping can improve the data transfer rate when the strip size is small compared to the I/O request size. It should also be clear that RAID 0 provides improved performance relative to a single large disk, because multiple I/O requests can be handled in parallel. However, in this latter case, is disk striping necessary? That is, does disk striping improve I/O request rate performance compared to a comparable disk array without striping?", "Consider a 4-drive, 200 GB-per-drive RAID array. What is the available data storage capacity for each of the RAID levels, 0, 1, 3, 4, 5, and 6?", "Define: B   block size, R   record size, P   size of block pointer, F   blocking factor;", "Give a formula for F for the three blocking methods depicted in Figure 12.8.", "One scheme to avoid the problem of preallocation versus waste or lack of contiguity is to allocate portions of increasing size as the file grows. For example, begin with a portion size of one block, and double the portion size for each allocation. Consider a file of n records with a blocking factor of F, and suppose that a simple one-level index is used as a file allocation table. Give an upper limit on the number of entries in the file allocation table as a function of F and n.", "One scheme to avoid the problem of preallocation versus waste or lack of contiguity is to allocate portions of increasing size as the file grows. For example, begin with a portion size of one block, and double the portion size for each allocation. Consider a file of n records with a blocking factor of F, and suppose that a simple one-level index is used as a file allocation table. What is the maximum amount of the allocated file space that is unused at any time?", "What file organization would you choose to maximize efficiency in terms of speed of access, use of storage space, and ease of updating (adding/deleting/modifying) when the data are a. updated infrequently and accessed frequently in random order? b. updated frequently and accessed in its entirety relatively frequently? c. updated frequently and accessed frequently in random order?", "For the B-tree in Figure 12.4c, show the result of inserting the key 97.", "An alternative algorithm for insertion into a B-tree is the following: As the insertion algorithm travels down the tree, each full node that is encountered is immediately split, even though it may turn out that the split was unnecessary. What is the advantage of this technique? What are the disadvantages?", "Both the search and the insertion time for a B-tree are a function of the height of the tree. We would like to develop a measure of the worst-case search or insertion time. Consider a B-tree of degree d that contains a total of n keys. Develop an inequality that shows an upper bound on the height h of the tree as a function of d and n.", "Ignoring overhead for directories and file descriptors, consider a file system in which files are stored in blocks of 16K bytes. For each of the following file sizes, calculate the percentage of wasted file space due to incomplete filling of the last block: 41,600 bytes; 640,000 bytes; 4.064,000 bytes.", "What are the advantages of using directories?", "Directories can be implemented either as \u201cspecial files\u201d that can only be accessed in limited ways or as ordinary data files. What are the advantages and disadvantages of each approach?", "Some operating systems have a tree\u2013structured file system but limit the depth of the tree to some small number of levels. What effect does this limit have on users? How does this simplify file system design (if it does)?", "Consider a hierarchical file system in which free disk space is kept in a free space list. Suppose the pointer to free space is lost. Can the system reconstruct the free space list?", "Consider a hierarchical file system in which free disk space is kept in a free space list. Suggest a scheme to ensure that the pointer is never lost as a result of a single memory failure.", "In UNIX System V, the length of a block is 1 Kbyte, and each block can hold a total of 256 block addresses. Using the inode scheme, what is the maximum size of a file?", "Consider the organization of a UNIX file as represented by the inode (Figure 12.16). Assume that there are 12 direct block pointers, and a singly, doubly, and triply indirect pointer in each inode. Further, assume that the system block size and the disk sector size are both 8K. If the disk block pointer is 32 bits, with 8 bits to identify the physical disk and 24 bits to identify the physical block, then what is the maximum file size supported by this system? What is the maximum file system partition supported by this system?", "Consider the organization of a UNIX file as represented by the inode (Figure 12.16). Assume that there are 12 direct block pointers, and a singly, doubly, and triply indirect pointer in each inode. Further, assume that the system block size and the disk sector size are both 8K. If the disk block pointer is 32 bits, with 8 bits to identify the physical disk and 24 bits to identify the physical block. Assuming no information other than that the file inode is already in main memory, how many disk accesses are required to access the byte in position 13,423,956?", "With reference to the device driver interface to the eCos kernel (Table 13.2), it is recommended that device drivers should use the _intsave() variants to claim and release spinlocks rather than the non-_intsave() variants. Explain why.", "In Table 13.2, it is recommended that cyg_drv_spinlock_spin should be used sparingly, and in situations where deadlocks/livelocks cannot occur. Explain why.", "In Table 13.2, what should be the limitations on the use of cyg_drv_spinlock_ destroy? Explain.", "In Table 13.2, what limitations should be placed in the use of cyg_drv_mutex_ destroy?", "Why does the eCos bitmap scheduler not support time slicing?", "The implementation of mutexes within the eCos kernel does not support recursive locks. If a thread has locked a mutex and then attempts to lock the mutex again, typically as a result of some recursive call in a complicated call graph, then either an assertion failure will be reported or the thread will deadlock. Suggest a reason for this policy.", "Figure 13.14 is a listing of code intended for use on the eCos kernel. Explain the operation of the code. Assume thread B begins execution first and thread A begins to execute after some event occurs.", "Figure 13.14 is a listing of code intended for use on the eCos kernel. What would happen if the mutex unlock and wait code execution in the call to cyg_cond_wait, on line 30, were not atomic?", "Figure 13.14 is a listing of code intended for use on the eCos kernel. Why is the while loop on line 26 needed?", "The discussion of eCos spinlocks included an example showing why spinlocks should not be used on a uniprocessor system if two threads of different priorities can compete for the same spinlock. Explain why the problem still exists even if only threads of the same priority can claim the same spinlock.", "TinyOS\u2019s scheduler serves tasks in FIFO order. Many other schedulers for TinyOS have been proposed, but none have caught on. What characteristics of the sensornet domain might cause a lack of need for more complex scheduling?", "The TinyOS Resource interface does not allow a component that already has a request in the queue for a resource to make a second request. Suggest a reason.", "The TinyOS Resource interface allows a component holding the resource lock to re-request the lock. This request is enqueued for a later grant. Suggest a reason for this policy. Hint: What might cause there to be latency between one component releasing a lock and the next requester being granted it?", "Consider an automated teller machine (ATM) in which users provide a personal identification number (PIN) and a card for account access. Give examples of confidentiality, integrity, and availability requirements associated with the system and, in each case, indicate the degree of importance of the requirement.", "Repeat the preceding problem for a telephone switching system that routes calls through a switching network based on the telephone number requested by the caller.", "Consider a desktop publishing system used to produce documents for various organizations. Give an example of a type of publication for which a. confidentiality of the stored data is the most important requirement b. data integrity is the most important requirement. c. system availability is the most important requirement.", "For each of the following assets, assign a low, moderate, or high impact level for the loss of confidentiality, availability, and integrity, respectively. Justify your answers. <EXAMPLES>", "Assume that passwords are selected from four-character combinations of 26 alphabetic characters. Assume that an adversary is able to attempt passwords at a rate of one per second.  What is the expected time to discover the correct password? a. Assuming no feedback to the adversary until each attempt has been completed, b. Assuming feedback to the adversary flagging an error as each incorrect character is entered", "The question arises as to whether it is possible to develop a program that can analyze a piece of software to determine if it is a virus. Consider that we have a program D that is supposed to be able to do that. That is, for any program P, if we run D(P), the result returned is TRUE (P is a virus) or FALSE (P is not a virus). Now consider the following program: <CODE> In the preceding program, infect-executable is a module that scans memory for executable programs and replicates itself in those programs. Determine if D can correctly decide whether CV is a virus.", "Consider the following fragment: <CODE> What type of malicious software is this?", "Consider the following fragment in an authentication program: <CODE> What type of malicious software is this?", "The following code fragments show a sequence of virus instructions and a polymorphic version of the virus. Describe the effect produced by the metamorphic code.", "Explain the suitability or unsuitability of the following passwords: a. YK 334 b. mfmitm (for \u201cmy favorite movie is tender mercies\u201d) c. Natalie1 d. Washington e. Aristotle f. tv9stove g. 12345678 h. dribgib", "An early attempt to force users to use less predictable passwords involved computer supplied passwords. The passwords were eight characters long and were taken from the character set consisting of lowercase letters and digits. They were generated by a pseudorandom number generator with 215 possible starting values. Using the technology of the time, the time required to search through all character strings of length 8 from a 36-character alphabet was 112 years. Unfortunately, this is not a true reflection of the actual security of the system. Explain the problem.", "Assume that passwords are selected from four-character combinations of 26 alphabetic characters. Assume that an adversary is able to attempt passwords at a rate of one per second. a. Assuming no feedback to the adversary until each attempt has been completed, what is the expected time to discover the correct password? b. Assuming feedback to the adversary flagging an error as each incorrect character is entered, what is the expected time to discover the correct password?", "Assume that source elements of length k are mapped in some uniform fashion into a target elements of length p. If each digit can take on one of r values, then the number of source elements is rk and the number of target elements is the smaller number rp. A particular source element xi is mapped to a particular target element yj. What is the probability that the correct source element can be selected by an adversary on one try? What is the probability that a different source element xk (xi =\u0338 xk) that results in the same target element, yj, could be produced by an adversary? What is the probability that the correct target element can be produced by an adversary on one try?", "Assume that passwords are limited to the use of the 95 printable ASCII characters and that all passwords are 10 characters in length. Assume a password cracker with an encryption rate of 6.4 million encryptions per second. How long will it take to test exhaustively all possible passwords on a UNIX system?", "Because of the known risks of the UNIX password system, the SunOS-4.0 documentation recommends that the password file be removed and replaced with a publicly readable file called /etc/publickey. An entry in the file for user A consists of a user\u2019s identifier IDA, the user\u2019s public key, PUa, and the corresponding private key, PRa. This private key is encrypted using DES with a key derived from the user\u2019s login password Pa. When A logs in, the system decrypts E(Pa, PRa) to obtain PRa. The system then verifies that Pa was correctly supplied. How?", "Because of the known risks of the UNIX password system, the SunOS-4.0 documentation recommends that the password file be removed and replaced with a publicly readable file called /etc/publickey. An entry in the file for user A consists of a user\u2019s identifier IDA, the user\u2019s public key, PUa, and the corresponding private key, PRa. This private key is encrypted using DES with a key derived from the user\u2019s login password Pa. When A logs in, the system decrypts E(Pa, PRa) to obtain PRa. How can an opponent attack this system?", "It was stated that the inclusion of the salt in the UNIX password scheme increases the difficulty of guessing by a factor of 4096. But the salt is stored in plaintext in the same entry as the corresponding ciphertext password. Therefore, those two characters are known to the attacker and need not be guessed. Why is it asserted that the salt increases security?", "Assuming that you have successfully answered the preceding problem and understand the significance of the salt, here is another question. Wouldn\u2019t it be possible to thwart completely all password crackers by dramatically increasing the salt size to, say, 24 or 48 bits?", "For the DAC model discussed in Section 15.2, an alternative representation of the protection state is a directed graph. Each subject and each object in the protection state is represented by a node (a single node is used for an entity that is both subject and object). A directed line from a subject to an object indicates an access right, and the label on the link defines the access right. Draw a directed graph that corresponds to the access matrix of Figure 12.15a.", "For the DAC model discussed in Section 15.2, an alternative representation of the protection state is a directed graph. Each subject and each object in the protection state is represented by a node (a single node is used for an entity that is both subject and object). A directed line from a subject to an object indicates an access right, and the label on the link defines the access right. Is there a one-to-one correspondence between the directed graph representation and the access matrix representation? Explain.", "UNIX treats file directories in the same fashion as files; that is, both are defined by the same type of data structure, called an inode. As with files, directories include a 9-bit protection string. If care is not taken, this can create access control problems. For example, consider a file with protection mode 644 (octal) contained in a directory with protection mode 730. How might the file be compromised in this case?", "In the traditional UNIX file access model, UNIX systems provide a default setting for newly created files and directories, which the owner may later change. The default is typically full access for the owner combined with one of the following: no access for group and other, read/execute access for group and none for other, or read/execute access for both group and other. Briefly discuss the advantages and disadvantages of each of these cases, including an example of a type of organization where each would be appropriate.", "Consider user accounts on a system with a Web server configured to provide access to user Web areas. In general, this scheme uses a standard directory name, such as public_ html, in a user\u2019s home directory. This acts as the user\u2019s Web area if it exists. However, to allow the Web server to access the pages in this directory, it must have at least search (execute) access to the user\u2019s home directory, read/execute access to the Web directory, and read access to any Web pages in it. Consider the interaction of this requirement with the cases you discussed for the preceding problem. What consequences does this requirement have? Note that a Web server typically executes as a special user, and in a group that is not shared with most users on the system. Are there some circumstances when running such a Web service is simply not appropriate? Explain.", "Assume a system with N job positions. For job position i, the number of individual users in that position is Ui and the number of permissions required for the job position is Pi. For a traditional DAC scheme, how many relationships between users and permissions must be defined? Repeat the same for an RBAC scheme.", "In the context of an IDS, we define a false positive to be an alarm generated by an IDS in which the IDS alerts to a condition that is actually benign. A false negative occurs when an IDS fails to generate an alarm when an alert-worthy condition is in effect. Using the following diagram, depict two curves that roughly indicate false positives and false negatives, respectively.", "Let be the percentage of program code that can be executed simultaneously by n computers in a cluster, each computer using a different set of parameters or initial conditions. Assume that the remaining code must be executed sequentially by a single processor. Each processor has an execution rate of x MIPS. Derive an expression for the effective MIPS rate when using the system for exclusive execution of this program, in terms of n,   , and x.", "Let be the percentage of program code that can be executed simultaneously by n computers in a cluster, each computer using a different set of parameters or initial conditions. Assume that the remaining code must be executed sequentially by a single processor. Each processor has an execution rate of x MIPS. If n   16 and x   4 MIPS, determine the value of that will yield a system performance of 40 MIPS.", "An application program is executed on a nine-computer cluster. A benchmark program takes time T on this cluster. Further, 25% of T is time in which the application is running simultaneously on all nine computers. The remaining time, the application has to run on a single computer. Calculate the effective speedup under the aforementioned condition as compared to executing the program on a single computer. Also calculate, the percentage of code that has been parallelized (programmed or compiled so as to use the cluster mode) in the preceding program.", "An application program is executed on a nine-computer cluster. A benchmark program takes time T on this cluster. Further, 25% of T is time in which the application is running simultaneously on all nine computers. The remaining time, the application has to run on a single computer. Suppose that we are able to effectively use 18 computers rather than 9 computers on the parallelized portion of the code. Calculate the effective speedup that is achieved.", "The following FORTRAN program is to be executed on a computer, and a parallel version is to be executed on a 32-computer cluster. <CODE> Suppose lines 2 and 4 each take two machine cycle times, including all processor and memory-access activities. What is the total execution time (in machine cycle times) of the program on a single computer?", "The following FORTRAN program is to be executed on a computer, and a parallel version is to be executed on a 32-computer cluster. <CODE> Suppose lines 2 and 4 each take two machine cycle times, including all processor and memory-access activities.  Divide the I-loop iterations among the 32 computers as follows: Computer 1 executes the first 32 iterations (I   1 to 32), processor 2 executes the next 32 iterations, and so on. What are the execution time and speedup factor compared with part (a)? (Note that the computational workload, dictated by the J-loop, is unbalanced among the computers.)", "The following FORTRAN program is to be executed on a computer, and a parallel version is to be executed on a 32-computer cluster. <CODE> Suppose lines 2 and 4 each take two machine cycle times, including all processor and memory-access activities. Explain how to modify the parallelizing to facilitate a balanced parallel execution of all the computational workload over 32 computers. A balanced load means an equal number of additions assigned to each computer with respect to both loops.", "The following FORTRAN program is to be executed on a computer, and a parallel version is to be executed on a 32-computer cluster. <CODE> Suppose lines 2 and 4 each take two machine cycle times, including all processor and memory-access activities. What is the minimum execution time resulting from the parallel execution on 32 computers? What is the resulting speedup over a single computer?"]
