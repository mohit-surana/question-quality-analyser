Summary
     The file system resides permanently on secondary storage, which is designed to
     hold a large amount of data permanently. The most common secondary-storage
     medium is the disk.
     Physical disks may be segmented into partitions to control media use
     and to allow multiple, possibly varying, file systems on a single spindle.
     These file systems are mounted onto a logical file system architecture to make
     them available for use. File systems are often implemented in a layered or
     modular structure. The lower levels deal with the physical properties of storage
     devices. Upper levels deal with symbolic file names and logical properties of
     files. Intermediate levels map the logical file concepts into physical device
     properties.
     Any file-system type can have different structures and algorithms. A VFS
     layer allows the upper layers to deal with each file-system type uniformly. Even
     remote file systems can be integrated into the system's directory structure and
     acted on by standard system calls via the VFS interface.
     The various files can be allocated space on the disk in three ways: through
     contiguous, linked, or indexed allocation. Contiguous allocation can suffer
     from   external  fragmentation.  Direct  access  is  very  inefficient  with  linked
     allocation. Indexed allocation may require substantial overhead for its index
     block. These algorithms can be optimized in many ways. Contiguous space
     can be enlarged through extents to increase flexibility and to decrease external
     fragmentation. Indexed allocation can be done in clusters of multiple blocks
     to increase throughput and to reduce the number of index entries needed.
     Indexing in large clusters is similar to contiguous allocation with extents.
     Free-space allocation methods also influence the efficiency of disk-space
     use, the performance of the file system, and the reliability of secondary storage.
     The methods used include bit vectors and linked lists. Optimizations include
     grouping, counting, and the FAT, which places the linked list in one contiguous
     area.
     Directory-management routines must consider efficiency, performance,
     and reliability. A hash table is a commonly used method, as it is fast and
     efficient. Unfortunately, damage to the table or a system crash can result
     in inconsistency between the directory information and the disk's contents.
     A consistency checker can be used to repair the damage. Operating-system
     backup tools allow disk data to be copied to tape, enabling the user to recover
     from data or even disk loss due to hardware failure, operating system bug, or
     user error.



                                                                Practice Exercises       581
Network file systems, such as NFS, use client­server methodology to
allow users to access files and directories from remote machines as if they
were  on  local  file  systems.       System  calls  on  the    client  are  translated  into
network protocols and retranslated into file-system operations on the server.
Networking and multiple-client access create challenges in the areas of data
consistency and performance.
Due to the fundamental role that file systems play in system operation,
their performance and reliability are crucial. Techniques such as log structures
and caching help improve performance, while log structures and RAID improve
reliability. The WAFL file system is an example of optimization of performance
to match a specific I/O load.
Practice Exercises
12.1  Consider a file currently consisting of 100 blocks. Assume that the file-
      control block (and the index block, in the case of indexed allocation)
      is already in memory. Calculate how many disk I/O operations are
      required for contiguous, linked, and indexed (single-level) allocation
      strategies,      if,  for  one  block,  the    following  conditions   hold.  In   the
      contiguous-allocation case, assume that there is no room to grow at
      the beginning but there is room to grow at the end. Also assume that
      the block information to be added is stored in memory.
          a.  The block is added at the beginning.
          b.  The block is added in the middle.
          c.  The block is added at the end.
          d.  The block is removed from the beginning.
          e.  The block is removed from the middle.
          f.  The block is removed from the end.
12.2  What problems could occur if a system allowed a file system to be
      mounted simultaneously at more than one location?
12.3  Why must the bit map for file allocation be kept on mass storage, rather
      than in main memory?
12.4  Consider a system that supports the strategies of contiguous, linked,
      and indexed allocation. What criteria should be used in deciding which
      strategy is best utilized for a particular file?
12.5  One problem with contiguous allocation is that the user must preallo-
      cate enough space for each file. If the file grows to be larger than the
      space allocated for it, special actions must be taken. One solution to this
      problem is to define a file structure consisting of an initial contiguous
      area (of a specified size). If this area is filled, the operating system
      automatically defines an overflow area that is linked to the initial
      contiguous area. If the overflow area is filled, another overflow area
      is allocated. Compare this implementation of a file with the standard
      contiguous and linked implementations.



582  Chapter 12  File-System Implementation
     12.6   How do caches help improve performance? Why do systems not use
            more or larger caches if they are so useful?
     12.7   Why is it advantageous to the user for an operating system to dynami-
            cally allocate its internal tables? What are the penalties to the operating
            system for doing so?
     12.8   Explain how the VFS layer allows an operating system to support
            multiple types of file systems easily.
Exercises
     12.9   Consider  a  file  system  that  uses   a    modifed   contiguous-allocation
            scheme with support for extents. A file is a collection of extents, with
            each extent corresponding to a contiguous set of blocks. A key issue in
            such systems is the degree of variability in the size of the extents. What
            are the advantages and disadvantages of the following schemes?
            a.   All extents are of the same size, and the size is predetermined.
            b.   Extents can be of any size and are allocated dynamically.
            c.   Extents can be of a few fixed sizes, and these sizes are predeter-
                 mined.
     12.10  Contrast the performance of the three techniques for allocating disk
            blocks  (contiguous,  linked,    and    indexed)  for  both  sequential  and
            random file access.
     12.11  What are the advantages of the variant of linked allocation that uses a
            FAT to chain together the blocks of a file?
     12.12  Consider a system where free space is kept in a free-space list.
            a.   Suppose that the pointer to the free-space list is lost. Can the
                 system reconstruct the free-space list? Explain your answer.
            b.   Consider a file system similar to the one used by UNIX with
                 indexed allocation. How many disk I/O operations might be
                 required to read the contents of a small local file at /a/b/c?
                 Assume that none of the disk blocks is currently being cached.
            c.   Suggest a scheme to ensure that the pointer is never lost as a result
                 of memory failure.
     12.13  Some file systems allow disk storage to be allocated at different levels
            of granularity. For instance, a file system could allocate 4 KB of disk
            space as a single 4-KB block or as eight 512-byte blocks. How could
            we take advantage of this flexibility to improve performance? What
            modifications would have to be made to the free-space management
            scheme in order to support this feature?
     12.14  Discuss how performance optimizations for file systems might result
            in difficulties in maintaining the consistency of the systems in the event
            of computer crashes.



                                               Programming Problems                 583
12.15  Consider a file system on a disk that has both logical and physical
       block sizes of 512 bytes. Assume that the information about each
       file is already in memory. For each of the three allocation strategies
       (contiguous, linked, and indexed), answer these questions:
       a.  How is the logical-to-physical address mapping accomplished
           in this system? (For the indexed allocation, assume that a file is
           always less than 512 blocks long.)
       b.  If we are currently at logical block 10 (the last block accessed was
           block 10) and want to access logical block 4, how many physical
           blocks must be read from the disk?
12.16  Consider a file system that uses inodes to represent files. Disk blocks
       are 8 KB in size, and a pointer to a disk block requires 4 bytes. This file
       system has 12 direct disk blocks, as well as single, double, and triple
       indirect disk blocks. What is the maximum size of a file that can be
       stored in this file system?
12.17  Fragmentation on a storage device can be eliminated by recompaction
       of the information. Typical disk devices do not have relocation or base
       registers (such as those used when memory is to be compacted), so
       how can we relocate files? Give three reasons why recompacting and
       relocation of files are often avoided.
12.18  Assume  that  in  a  particular    augmentation  of  a  remote-file-access
       protocol, each client maintains a name cache that caches translations
       from file names to corresponding file handles. What issues should we
       take into account in implementing the name cache?
12.19  Explain why logging metadata       updates  ensures     recovery  of  a      file
       system after a file-system crash.
12.20  Consider the following backup scheme:
       ·   Day 1. Copy to a backup medium all files from the disk.
       ·   Day 2. Copy to another medium all files changed since day 1.
       ·   Day 3. Copy to another medium all files changed since day 1.
       This differs from the schedule given in Section 12.7.4 by having all
       subsequent backups copy all files modified since the first full backup.
       What are the benefits of this system over the one in Section 12.7.4?
       What are the drawbacks? Are restore operations made easier or more
       difficult? Explain your answer.
Programming Problems
       The following exercise examines the relationship between files and
       inodes on a UNIX or Linux system. On these systems, files are repre-
       sented with inodes. That is, an inode is a file (and vice versa). You can
       complete this exercise on the Linux virtual machine that is provided
       with this text. You can also complete the exercise on any Linux, UNIX, or



584  Chapter 12  File-System Implementation
            Mac OS X system, but it will require creating two simple text files named
            file1.txt and file3.txt whose contents are unique sentences.
     12.21  In   the  source  code  available  with  this  text,  open  file1.txt  and
            examine its contents. Next, obtain the inode number of this file with
            the command
                 ls -li file1.txt
            This will produce output similar to the following:
                 16980 -rw-r--r-- 2 os os 22 Sep 14 16:13 file1.txt
            where the inode number is boldfaced. (The inode number of file1.txt
            is likely to be different on your system.)
            The UNIX ln command creates a link between a source and target file.
            This command works as follows:
                 ln    [-s]   <source  file>     <target   file>
                UNIX provides two types of links: (1) hard links and (2) soft links.
            A hard link creates a separate target file that has the same inode as the
            source file. Enter the following command to create a hard link between
            file1.txt and file2.txt:
                 ln file1.txt file2.txt
            What are the inode values of file1.txt and file2.txt? Are they
            the same or different? Do the two files have the same --or different--
            contents?
            Next, edit file2.txt and change its contents. After you have done
            so, examine the contents of file1.txt. Are the contents of file1.txt
            and file2.txt the same or different?
            Next, enter the following command which removes file1.txt:
                 rm file1.txt
            Does file2.txt still exist as well?
            Now examine the man pages for both the rm and unlink commands.
            Afterwards, remove file2.txt by entering the command
                 strace       rm  file2.txt
            The strace command traces the execution of system calls as the
            command rm        file2.txt is run. What system call is used for removing
            file2.txt?
                A soft link (or symbolic link) creates a new file that "points" to the
            name of the file it is linking to. In the source code available with this text,
            create a soft link to file3.txt by entering the following command:
                 ln    -s  file3.txt   file4.txt
            After you have done so, obtain the inode numbers of file3.txt and
            file4.txt using the command
                 ls -li file*.txt



                                                                       Bibliography             585
          Are the inodes the same, or is each unique? Next, edit the contents
          of file4.txt. Have the contents of file3.txt been altered as well?
          Last, delete file3.txt. After you have done so, explain what happens
          when you attempt to edit file4.txt.
Bibliographical Notes
The  MS-DOS       FAT   system   is    explained     in  [Norton  and        Wilton  (1988)].   The
internals     of  the   BSD  UNIX      system   are  covered  in       full  in  [McKusick      and
Neville-Neil (2005)]. Details concerning file systems for Linux can be found in
[Love (2010)]. The Google file system is described in [Ghemawat et al. (2003)].
FUSE can be found at http://fuse.sourceforge.net.
     Log-structured file organizations for enhancing both performance and
consistency are discussed in [Rosenblum and Ousterhout (1991)], [Seltzer
et  al.   (1993)],  and      [Seltzer  et  al.  (1995)].     Algorithms      such    as  balanced
trees (and much more) are covered by [Knuth (1998)] and [Cormen et al.
(2009)].   [Silvers     (2000)]  discusses      implementing      the        page    cache  in  the
NetBSD operating system. The ZFS source code for space maps can be found at
http://src.opensolaris.org/source/xref/onnv/onnv-gate/usr/src/uts/common/
fs/zfs/space map.c.
     The network file system (NFS) is discussed in [Callaghan (2000)]. NFS Ver-
sion 4 is a standard described at http://www.ietf.org/rfc/rfc3530.txt. [Ouster-
hout (1991)] discusses the role of distributed state in networked file systems.
Log-structured designs for networked file systems are proposed in [Hartman
and Ousterhout (1995)] and [Thekkath et al. (1997)]. NFS and the UNIX file
system (UFS) are described in [Vahalia (1996)] and [Mauro and McDougall
(2007)]. The NTFS file system is explained in [Solomon (1998)]. The Ext3 file
system used in Linux is described in [Mauerer (2008)] and the WAFL file
system is covered in [Hitz et al. (1995)]. ZFS documentation can be found
at http://www.opensolaris.org/os/community/ZFS/docs.
Bibliography
[Callaghan (2000)]       B. Callaghan, NFS Illustrated, Addison-Wesley (2000).
[Cormen et al. (2009)]       T. H. Cormen, C. E. Leiserson, R. L. Rivest, and C. Stein,
    Introduction to Algorithms, Third Edition, MIT Press (2009).
[Ghemawat et al. (2003)]         S.    Ghemawat,         H.  Gobioff,  and   S.-T.   Leung,     "The
    Google File System", Proceedings of the ACM Symposium on Operating Systems
    Principles (2003).
[Hartman and Ousterhout (1995)]                J. H. Hartman and J. K. Ousterhout, "The
    Zebra Striped Network File System", ACM Transactions on Computer Systems,
    Volume 13, Number 3 (1995), pages 274­310.
[Hitz et al. (1995)]     D. Hitz, J. Lau, and M. Malcolm, "File System Design for an
    NFS File Server Appliance", Technical report, NetApp (1995).



586  Chapter 12     File-System Implementation
     [Knuth (1998)]    D. E. Knuth, The Art of Computer Programming, Volume 3: Sorting
     and Searching, Second Edition, Addison-Wesley (1998).
     [Love (2010)]     R. Love, Linux Kernel Development, Third Edition, Developer's
     Library (2010).
     [Mauerer (2008)]         W. Mauerer, Professional Linux Kernel Architecture, John Wiley
     and Sons (2008).
     [Mauro and McDougall (2007)]            J. Mauro and R. McDougall, Solaris Internals:
     Core Kernel Architecture, Prentice Hall (2007).
     [McKusick and Neville-Neil (2005)]            M. K. McKusick and G. V. Neville-Neil,
     The Design and Implementation of the FreeBSD UNIX Operating System, Addison
     Wesley (2005).
     [Norton and Wilton (1988)]          P.  Norton    and     R.  Wilton,  The  New    Peter  Norton
     Programmer's Guide to the IBM PC & PS/2, Microsoft Press (1988).
     [Ousterhout (1991)]       J. Ousterhout.      "The Role of Distributed State".         In CMU
     Computer Science: a 25th Anniversary Commemorative, R. F. Rashid, Ed., Addison-
     Wesley (1991).
     [Rosenblum and Ousterhout (1991)]             M. Rosenblum and J. K. Ousterhout, "The
     Design and Implementation of a Log-Structured File System", Proceedings of the
     ACM Symposium on Operating Systems Principles (1991), pages 1­15.
     [Seltzer et al. (1993)]   M. I. Seltzer, K. Bostic, M. K. McKusick, and C. Staelin, "An
     Implementation of a Log-Structured File System for UNIX", USENIX Winter
     (1993), pages 307­326.
     [Seltzer et al. (1995)]   M.  I.    Seltzer,  K.  A.  Smith,   H.   Balakrishnan,  J.     Chang,
     S. McMains, and V. N. Padmanabhan, "File System Logging Versus Clustering:
     A Performance Comparison", USENIX Winter (1995), pages 249­264.
     [Silvers (2000)]  C. Silvers, "UBC: An Efficient Unified I/O and Memory Caching
     Subsystem for NetBSD", USENIX Annual Technical Conference -- FREENIX Track
     (2000).
     [Solomon (1998)]         D. A. Solomon, Inside Windows NT, Second Edition, Microsoft
     Press (1998).
     [Thekkath et al. (1997)]      C. A. Thekkath, T. Mann, and E. K. Lee, "Frangipani:
     A Scalable Distributed File System", Symposium on Operating Systems Principles
     (1997), pages 224­237.
     [Vahalia (1996)]     U.   Vahalia,  Unix      Internals:  The  New     Frontiers,  Prentice  Hall
     (1996).
