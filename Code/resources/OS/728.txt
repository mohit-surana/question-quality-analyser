Beowulf and Linux Clusters
      message to the entire cluster, causing all members to exchange messages to verify
      their view of current cluster membership. If a node manager does not respond, it is
      removed from the cluster and its active groups are transferred to one or more other
      active nodes in the cluster.
         The configuration database manager maintains the cluster configuration
      database. The database contains information about resources and groups and node
      ownership of groups. The database managers on each of the cluster nodes cooper-
      ate to maintain a consistent picture of configuration information. Fault-tolerant
      transaction software is used to assure that changes in the overall cluster configura-
      tion are performed consistently and correctly.
         The  resource  manager/failover  manager      makes   all  decisions  regarding
      resource groups and initiates appropriate actions such as startup, reset, and failover.
      When failover is required, the failover managers on the active node cooperate to
      negotiate a distribution of resource groups from the failed system to the remain-
      ing active systems. When a system restarts after a failure, the failover manager can
      decide to move some groups back to this system. In particular, any group may be
      configured with a preferred owner. If that owner fails and then restarts, the group is
      moved back to the node in a rollback operation.
         The event processor connects all of the components of the cluster serv-
      ice, handles common operations, and controls cluster service initialization. The
      communications manager manages message exchange with all other nodes of the
      cluster. The global update manager provides a service used by other components
      within the cluster service.
         Microsoft is continuing to ship their cluster product, but they have also devel-
      oped virtualization solutions based on efficient live migration of virtual machines
      between hypervisors running on different computer systems as part of Windows
      Server 2008 R2. For new applications, live migration offers many benefits over the
      cluster approach, such as simpler management, and improved flexibility.
16.7  BEOWULF AND LINUX CLUSTERS
      In 1994, the Beowulf project was initiated under the sponsorship of the NASA
      High Performance Computing and Communications (HPCC) project. Its goal was
      to investigate the potential of clustered PCs for performing important computa-
      tion tasks beyond the capabilities of contemporary workstations at minimum cost.
      Today, the Beowulf approach is widely implemented and is perhaps the most impor-
      tant cluster technology available.
      Beowulf Features
      Key features of Beowulf include the following [RIDG97]:
        Mass market commodity components
        Dedicated processors (rather than scavenging cycles from idle workstations)
        A dedicated, private network (LAN or WAN or internetted combination)
        No custom components

                                                                        Distributed
                                                                        shared storage
                                                                        Linux
                                                                        workstations
                         Ethernet or
                  interconnected ethernets
   Figure 16.18  Generic Beowulf Configuration
  Easy replication from multiple vendors
  Scalable I/O
  A freely available software base
  Use of freely available distribution computing tools with minimal changes
  Return of the design and improvements to the community
   Although elements of Beowulf software have been implemented on a
number of different platforms, the most obvious choice for a base is Linux,
and most Beowulf implementations use a cluster of Linux workstations and/or
PCs. Figure 16.18 depicts a representative configuration. The cluster consists of
a number of workstations, perhaps of differing hardware platforms, all running
the Linux operating system. Secondary storage at each workstation may be made
available for distributed access (for distributed file sharing, distributed virtual
memory, or other uses). The cluster nodes (the Linux systems) are interconnected
with a commodity networking approach, typically Ethernet. The Ethernet sup-
port may be in the form of a single Ethernet switch or an interconnected set of
switches. Commodity Ethernet products at the standard data rates (10 Mbps, 100
Mbps, 1 Gbps) are used.
Beowulf Software
The Beowulf software environment is implemented as an add-on to commercially
available, royalty-free base Linux distributions. The principal source of open-source
Beowulf software is the Beowulf site at www.beowulf.org, but numerous other
organizations also offer free Beowulf tools and utilities.
   Each node in the Beowulf cluster runs its own copy of the Linux kernel and
can function as an autonomous Linux system. To support the Beowulf cluster
concept, extensions are made to the Linux kernel to allow the individual nodes

     to participate in a number of global namespaces. The following are examples of
     Beowulf system software:
       Beowulf distributed process space (BPROC): This package allows a process
        ID space to span multiple nodes in a cluster environment and also provides
        mechanisms for starting processes on other nodes. The goal of this package is
        to provide key elements needed for a single system image on Beowulf cluster.
        BPROC provides a mechanism to start processes on remote nodes without
        ever logging into another node and by making all the remote processes visible
        in the process table of the cluster's front-end node.
       Beowulf Ethernet channel bonding: This is a mechanism that joins multiple
        low-cost networks into a single logical network with higher bandwidth. The
        only additional work over using single network interface is the computation-
        ally simple task of distributing the packets over the available device trans-
        mit queues. This approach allows load balancing over multiple Ethernets
        connected to Linux workstations.
       Pvmsync: This is a programming environment that provides synchronization
        mechanisms and shared data objects for processes in a Beowulf cluster.
       EnFuzion: EnFuzion consists of a set of tools for doing parametric computing,
        as described in Section 16.4. Parametric computing involves the execution of
        a program as a large number of jobs, each with different parameters or start-
        ing conditions. EnFusion emulates a set of robot users on a single root node
        machine, each of which will log into one of the many clients that form a clus-
        ter. Each job is set up to run with a unique, programmed scenario, with an
        appropriate set of starting conditions [KAPP00].
16.8 SUMMARY
     Client/server computing is the key to realizing the potential of information systems
     and networks to improve productivity significantly in organizations. With client/
     server computing, applications are distributed to users on single-user workstations
     and personal computers. At the same time, resources that can and should be shared
     are maintained on server systems that are available to all clients. Thus, the client/
     server architecture is a blend of decentralized and centralized computing.
        Typically, the client system provides a graphical user interface (GUI) that
     enables a user to exploit a variety of applications with minimal training and relative
     ease. Servers support shared utilities, such as database management systems. The
     actual application is divided between client and server in a way intended to optimize
     ease of use and performance.
        The key mechanism required in any distributed system is interprocess com-
     munication. Two techniques are in common use. A message-passing facility gener-
     alizes the use of messages within a single system. The same sorts of conventions and
     synchronization rules apply. Another approach is the use of the remote procedure
     call. This is a technique by which two programs on different machines interact using
     procedure call/return syntax and semantics. Both the called and calling program
     behave as if the partner program were running on the same machine.
