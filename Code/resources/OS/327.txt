Memory Management
                              CHAPTER
MEMORY MANAGEMENT
7.1  Memory Management Requirements
     Relocation
     Protection
     Sharing
     Logical Organization
     Physical Organization
7.2  Memory Partitioning
     Fixed Partitioning
     Dynamic Partitioning
     Buddy System
     Relocation
7.3  Paging
7.4  Segmentation
7.5  Security Issues
     Buffer Overflow Attacks
     Defending against Buffer Overflows
7.6  Summary
7.7  Recommended Reading
7.8  Key Terms, Review Questions, and Problems
APPENDIX 7A           Loading and Linking
                                                305

        I cannot guarantee that I carry all the facts in my mind. Intense mental
        concentration has a curious way of blotting out what has passed.
        Each of my cases displaces the last, and Mlle. Carère has blurred my
        recollection of Baskerville Hall. Tomorrow some other little problem
        may be submitted to my notice which will in turn dispossess the fair
        French lady and the infamous Upwood.
                                              --THE HOUND OF THE BASKERVILLES,
                                                             Arthur Conan Doyle.
     LEARNING OBJECTIVES
     After studying this chapter, you should be able to:
     ·  Discuss the principal requirements for memory management.
     ·  Understand the reason for memory partitioning and explain the  various
        techniques that are used.
     ·  Understand and explain the concept of paging.
     ·  Understand and explain the concept of segmentation.
     ·  Assess the relative advantages of paging and segmentation.
     ·  Summarize key security issues related to memory management.
     ·  Describe the concepts of loading and linking.
     In a uniprogramming system, main memory is divided into two parts: one part for
     the operating system (resident monitor, kernel) and one part for the program cur-
     rently being executed. In a multiprogramming system, the "user" part of memory
     must be further subdivided to accommodate multiple processes. The task of subdi-
     vision is carried out dynamically by the operating system and is known as memory
     management.
        Effective memory management is vital in a multiprogramming system. If only
     a few processes are in memory, then for much of the time all of the processes
     will be waiting for I/O and the processor will be idle. Thus memory needs to be
     allocated to ensure a reasonable supply of ready processes to consume available
     processor time.
        We begin with the requirements that memory management is intended to
     satisfy. Next, we discuss a variety of simple schemes that have been used for
     memory management
        Table 7.1 introduces some key terms for our discussion. A set of animations
     that illustrate concepts in this chapter is available online. Click on the rotating globe
     at WilliamStallings.com/OS/OS7e.html for access.

Table 7.1  Memory Management Terms
Frame      A fixed-length block of main memory.
Page       A fixed-length block of data that resides in secondary memory (such as disk). A page of data may
           temporarily be copied into a frame of main memory.
Segment    A variable-length block of data that resides in secondary memory. An entire segment may tempo-
           rarily be copied into an available region of main memory (segmentation) or the segment may be
           divided into pages which can be individually copied into main memory (combined segmentation
           and paging).
7.1        MEMORY MANAGEMENT REQUIREMENTS
           While surveying the various mechanisms and policies associated with memory man-
           agement, it is helpful to keep in mind the requirements that memory management is
           intended to satisfy. These requirements include the following:
           ·  Relocation
           ·  Protection
           ·  Sharing
           ·  Logical organization
           ·  Physical organization
           Relocation
           In a multiprogramming system, the available main memory is generally shared
           among a number of processes. Typically, it is not possible for the programmer to
           know in advance which other programs will be resident in main memory at the time
           of execution of his or her program. In addition, we would like to be able to swap
           active processes in and out of main memory to maximize processor utilization by
           providing a large pool of ready processes to execute. Once a program is swapped
           out to disk, it would be quite limiting to specify that when it is next swapped back in,
           it must be placed in the same main memory region as before. Instead, we may need
           to relocate the process to a different area of memory.
              Thus, we cannot know ahead of time where a program will be placed, and we
           must allow for the possibility that the program may be moved about in main memory
           due to swapping. These facts raise some technical concerns related to addressing,
           as illustrated in Figure 7.1. The figure depicts a process image. For simplicity, let
           us assume that the process image occupies a contiguous region of main memory.
           Clearly, the operating system will need to know the location of process control
           information and of the execution stack, as well as the entry point to begin execution
           of the program for this process. Because the operating system is managing mem-
           ory and is responsible for bringing this process into main memory, these addresses
           are easy to come by. In addition, however, the processor must deal with memory
