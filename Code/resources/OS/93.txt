Developments Leading to Modern Operating Systems

     Over the years, there has been a gradual evolution of OS structure and capabilities.
     However, in recent years a number of new design elements have been introduced
     into both new operating systems and new releases of existing operating systems that
     create a major change in the nature of operating systems. These modern operating
     systems respond to new developments in hardware, new applications, and new secu-
     rity threats. Among the key hardware drivers are multiprocessor systems, greatly
     increased processor speed, high-speed network attachments, and increasing size
     and variety of memory storage devices. In the application arena, multimedia appli-
     cations, Internet and Web access, and client/server computing have influenced OS
     design. With respect to security, Internet access to computers has greatly increased
     the potential threat and increasingly sophisticated attacks, such as viruses, worms,
     and hacking techniques, have had a profound impact on OS design.
        The rate of change in the demands on operating systems requires not just
     modifications and enhancements to existing architectures but new ways of organ-
     izing the OS. A wide range of different approaches and design elements has been
     tried in both experimental and commercial operating systems, but much of the work
     fits into the following categories:
     ·  Microkernel architecture
     ·  Multithreading
     ·  Symmetric multiprocessing
     ·  Distributed operating systems
     ·  Object-oriented design
        Most operating systems, until recently, featured a large monolithic kernel.
     Most of what is thought of as OS functionality is provided in these large kernels,
     including scheduling, file system, networking, device drivers, memory management,
     and more. Typically, a monolithic kernel is implemented as a single process, with
     all elements sharing the same address space. A microkernel architecture assigns
     only a few essential functions to the kernel, including address spaces, interproc-
     ess communication (IPC), and basic scheduling. Other OS services are provided by
     processes, sometimes called servers, that run in user mode and are treated like any
     other application by the microkernel. This approach decouples kernel and server
     development. Servers may be customized to specific application or environment
     requirements. The microkernel approach simplifies implementation, provides flex-
     ibility, and is well suited to a distributed environment. In essence, a microkernel
     interacts with local and remote server processes in the same way, facilitating con-
     struction of distributed systems.
        Multithreading is a technique in which a process, executing an application, is
     divided into threads that can run concurrently. We can make the following distinction:
     · Thread: A dispatchable unit of work. It includes a processor context (which
        includes the program counter and stack pointer) and its own data area for a

       stack (to enable subroutine branching). A thread executes sequentially and is
       interruptable so that the processor can turn to another thread.
    ·  Process: A collection of one or more threads and associated system resources
       (such as memory containing both code and data, open files, and devices). This
       corresponds closely to the concept of a program in execution. By breaking
       a single application into multiple threads, the programmer has great control
       over the modularity of the application and the timing of application-related
       events.
       Multithreading is useful for applications that perform a number of essentially
    independent tasks that do not need to be serialized. An example is a database server
    that listens for and processes numerous client requests. With multiple threads run-
    ning within the same process, switching back and forth among threads involves
    less processor overhead than a major process switch between different processes.
    Threads are also useful for structuring processes that are part of the OS kernel as
    described in subsequent chapters.
       Symmetric multiprocessing (SMP) is a term that refers to a computer hard-
    ware architecture (described in Chapter 1) and also to the OS behavior that exploits
    that architecture. The OS of an SMP schedules processes or threads across all of the
    processors. SMP has a number of potential advantages over uniprocessor architec-
    ture, including the following:
    ·  Performance: If the work to be done by a computer can be organized so that
       some portions of the work can be done in parallel, then a system with multiple
       processors will yield greater performance than one with a single processor of
       the same type. This is illustrated in Figure 2.12. With multiprogramming, only
       one process can execute at a time; meanwhile all other processes are waiting
       for the processor. With multiprocessing, more than one process can be run-
       ning simultaneously, each on a different processor.
    ·  Availability: In a symmetric multiprocessor, because all processors can per-
       form the same functions, the failure of a single processor does not halt the
       system. Instead, the system can continue to function at reduced performance.
    ·  Incremental growth: A user can enhance the performance of a system by add-
       ing an additional processor.
    ·  Scaling: Vendors can offer a range of products with different price and per-
       formance characteristics based on the number of processors configured in the
       system.
    It is important to note that these are potential, rather than guaranteed, benefits. The
    OS must provide tools and functions to exploit the parallelism in an SMP system.
       Multithreading and SMP are often discussed together, but the two are
    independent facilities. Even on a uniprocessor system, multithreading is useful for
    structuring applications and kernel processes. An SMP system is useful even for
    nonthreaded processes, because several processes can run in parallel. However, the
    two facilities complement each other and can be used effectively together.
       An attractive feature of an SMP is that the existence of multiple processors is
    transparent to the user. The OS takes care of scheduling of threads or processes on

             Time
Process 1
Process 2
Process 3
                      (a) Interleaving (multiprogramming; one processor)
Process 1
Process 2
Process 3
                      (b) Interleaving and overlapping (multiprocessing; two processors)
Blocked               Running
Figure 2.12  Multiprogramming and Multiprocessing
individual processors and of synchronization among processors. This book discusses
the scheduling and synchronization mechanisms used to provide the single-system
appearance to the user. A different problem is to provide the appearance of a sin-
gle system for a cluster of separate computers--a multicomputer system. In this
case, we are dealing with a collection of entities (computers), each with its own
main memory, secondary memory, and other I/O modules. A distributed operating
system provides the illusion of a single main memory space and a single secondary
memory space, plus other unified access facilities, such as a distributed file system.
Although clusters are becoming increasingly popular, and there are many cluster
products on the market, the state of the art for distributed operating systems lags
that of uniprocessor and SMP operating systems. We examine such systems in
Part Eight.
             Another innovation in OS design is the use of object-oriented technologies.
Object-oriented design lends discipline to the process of adding modular extensions
to a small kernel. At the OS level, an object-based structure enables programmers
to customize an OS without disrupting system integrity. Object orientation also
eases the development of distributed tools and full-blown distributed operating
systems.

